{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c06b4f-b1e4-4c59-8c3d-fbf51a652aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합 완료! merged_train.csv로 저장됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "train_path = r\"C:\\Users\\user\\Downloads\\open (1)\\train.csv\"\n",
    "building_info_path = r\"C:\\Users\\user\\Downloads\\open (1)\\building_info.csv\"\n",
    "\n",
    "# CSV 불러오기\n",
    "train_df = pd.read_csv(train_path)\n",
    "building_info_df = pd.read_csv(building_info_path)\n",
    "\n",
    "# 병합 (건물번호 기준)\n",
    "merged_df = pd.merge(train_df, building_info_df, on='건물번호', how='left')\n",
    "\n",
    "# 결과 저장\n",
    "merged_df.to_csv(r\"C:\\Users\\user\\Downloads\\open (1)\\merged_train.csv\", index=False, encoding = 'cp949')\n",
    "\n",
    "print(\"병합 완료! merged_train.csv로 저장됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0df8ba4-14a4-41b8-8d2b-61ef686b6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_smart(path):\n",
    "    import pandas as pd\n",
    "    for enc in ['cp949', 'utf-8-sig', 'utf-8', 'euc-kr']:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    # 최후의 보루: 깨지는 글자는 � 로 대체\n",
    "    return pd.read_csv(path, encoding='utf-8', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ffaff9-a16e-4dd6-a92e-e47e0ef61da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            일시         날짜  시간\n",
      "0  20240601 00 2024-06-01   0\n",
      "1  20240601 01 2024-06-01   1\n",
      "2  20240601 02 2024-06-01   2\n",
      "3  20240601 03 2024-06-01   3\n",
      "4  20240601 04 2024-06-01   4\n"
     ]
    }
   ],
   "source": [
    "# CSV 불러오기 (예시)\n",
    "df = read_csv_smart(\"C:\\\\Users\\\\user\\\\Downloads\\\\open (1)\\\\merged_train.csv\")\n",
    "\n",
    "\n",
    "# '일시'를 문자열로 변환 후 날짜와 시간 분리\n",
    "df['일시'] = df['일시'].astype(str)\n",
    "\n",
    "# 날짜(YYYYMMDD)와 시간(HH) 분리\n",
    "df['날짜'] = df['일시'].str.slice(0, 8)     # 앞 8자리 → 날짜\n",
    "df['시간'] = df['일시'].str.slice(9, 11)    # 9~10번째 자리 → 시간\n",
    "\n",
    "# 날짜를 datetime 형식으로 변환\n",
    "df['날짜'] = pd.to_datetime(df['날짜'], format='%Y%m%d')\n",
    "df['시간'] = df['시간'].astype(int)\n",
    "\n",
    "# 확인\n",
    "print(df[['일시', '날짜', '시간']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36cc6a8-0547-428e-958d-32a375333aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>건물번호</th>\n",
       "      <th>일시</th>\n",
       "      <th>기온(°C)</th>\n",
       "      <th>강수량(mm)</th>\n",
       "      <th>풍속(m/s)</th>\n",
       "      <th>습도(%)</th>\n",
       "      <th>일조(hr)</th>\n",
       "      <th>일사(MJ/m2)</th>\n",
       "      <th>전력소비량(kWh)</th>\n",
       "      <th>건물유형</th>\n",
       "      <th>연면적(m2)</th>\n",
       "      <th>냉방면적(m2)</th>\n",
       "      <th>태양광용량(kW)</th>\n",
       "      <th>ESS저장용량(kWh)</th>\n",
       "      <th>PCS용량(kW)</th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5794.80</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5591.85</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 02</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5338.17</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4554.42</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 04</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3602.25</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203995</th>\n",
       "      <td>100_20240824 19</td>\n",
       "      <td>100</td>\n",
       "      <td>20240824 19</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3276.00</td>\n",
       "      <td>호텔</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>152943.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203996</th>\n",
       "      <td>100_20240824 20</td>\n",
       "      <td>100</td>\n",
       "      <td>20240824 20</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3197.52</td>\n",
       "      <td>호텔</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>152943.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203997</th>\n",
       "      <td>100_20240824 21</td>\n",
       "      <td>100</td>\n",
       "      <td>20240824 21</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3006.60</td>\n",
       "      <td>호텔</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>152943.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203998</th>\n",
       "      <td>100_20240824 22</td>\n",
       "      <td>100</td>\n",
       "      <td>20240824 22</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2649.72</td>\n",
       "      <td>호텔</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>152943.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203999</th>\n",
       "      <td>100_20240824 23</td>\n",
       "      <td>100</td>\n",
       "      <td>20240824 23</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2929.32</td>\n",
       "      <td>호텔</td>\n",
       "      <td>162070.24</td>\n",
       "      <td>152943.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_date_time  건물번호           일시  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  \\\n",
       "0         1_20240601 00     1  20240601 00    18.3      0.0      2.6   82.0   \n",
       "1         1_20240601 01     1  20240601 01    18.3      0.0      2.7   82.0   \n",
       "2         1_20240601 02     1  20240601 02    18.1      0.0      2.6   80.0   \n",
       "3         1_20240601 03     1  20240601 03    18.0      0.0      2.6   81.0   \n",
       "4         1_20240601 04     1  20240601 04    17.8      0.0      1.3   81.0   \n",
       "...                 ...   ...          ...     ...      ...      ...    ...   \n",
       "203995  100_20240824 19   100  20240824 19    29.1      0.0      4.4   76.0   \n",
       "203996  100_20240824 20   100  20240824 20    28.6      0.0      3.7   74.0   \n",
       "203997  100_20240824 21   100  20240824 21    28.3      0.0      2.9   74.0   \n",
       "203998  100_20240824 22   100  20240824 22    28.0      0.0      1.7   76.0   \n",
       "203999  100_20240824 23   100  20240824 23    28.0      0.0      2.1   75.0   \n",
       "\n",
       "        일조(hr)  일사(MJ/m2)  전력소비량(kWh) 건물유형    연면적(m2)  냉방면적(m2) 태양광용량(kW)  \\\n",
       "0          0.0       0.00     5794.80   호텔   82912.71   77586.0         -   \n",
       "1          0.0       0.00     5591.85   호텔   82912.71   77586.0         -   \n",
       "2          0.0       0.00     5338.17   호텔   82912.71   77586.0         -   \n",
       "3          0.0       0.00     4554.42   호텔   82912.71   77586.0         -   \n",
       "4          0.0       0.00     3602.25   호텔   82912.71   77586.0         -   \n",
       "...        ...        ...         ...  ...        ...       ...       ...   \n",
       "203995     0.4       0.18     3276.00   호텔  162070.24  152943.0         -   \n",
       "203996     0.0       0.00     3197.52   호텔  162070.24  152943.0         -   \n",
       "203997     0.0       0.00     3006.60   호텔  162070.24  152943.0         -   \n",
       "203998     0.0       0.00     2649.72   호텔  162070.24  152943.0         -   \n",
       "203999     0.0       0.00     2929.32   호텔  162070.24  152943.0         -   \n",
       "\n",
       "       ESS저장용량(kWh) PCS용량(kW)         날짜  시간  \n",
       "0                 -         - 2024-06-01   0  \n",
       "1                 -         - 2024-06-01   1  \n",
       "2                 -         - 2024-06-01   2  \n",
       "3                 -         - 2024-06-01   3  \n",
       "4                 -         - 2024-06-01   4  \n",
       "...             ...       ...        ...  ..  \n",
       "203995            -         - 2024-08-24  19  \n",
       "203996            -         - 2024-08-24  20  \n",
       "203997            -         - 2024-08-24  21  \n",
       "203998            -         - 2024-08-24  22  \n",
       "203999            -         - 2024-08-24  23  \n",
       "\n",
       "[204000 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bae45f3-a91e-4565-875e-fd288783f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 대체할 컬럼 목록\n",
    "cols = ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']\n",
    "\n",
    "# '-'를 0으로 바꾸고 숫자형으로 변환\n",
    "for col in cols:\n",
    "    df[col] = df[col].replace('-', 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217e50e1-22ea-4604-b35e-1d81d9159c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['num_date_time', '일시'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20ba33f-8d72-4347-9553-0f986dffdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['건물유형'] = le.fit_transform(df['건물유형'])\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e97aec1-f316-432b-8324-8ff9ae39c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 0) 기본 정렬 & datetime 만들기\n",
    "    #    (이미 df['날짜']와 df['시간']이 있다면 그대로 쓰되, 한 줄짜리 datetime을 만들어두면 편함)\n",
    "    df = df.copy()\n",
    "    df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "    df['dt'] = df['날짜'] + pd.to_timedelta(df['시간'], unit='h')\n",
    "    df = df.sort_values(['건물번호', 'dt']).reset_index(drop=True)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1) 최근 24시간 평균, 최근 7일(같은 시각) 평균  → 전부 \"과거만\" 보도록 shift 사용\n",
    "    # -------------------------------------------------------\n",
    "    grp = df.groupby('건물번호', group_keys=False)\n",
    "\n",
    "    # (a) 최근 24시간 평균 (전력소비량 기준)\n",
    "    #  - window=24, past-only를 위해 shift(1) 후 rolling\n",
    "    df['cons_lag1'] = grp['전력소비량(kWh)'].shift(1)\n",
    "    df['cons_mean_24h'] = grp['cons_lag1'].rolling(window=24, min_periods=1).mean()\n",
    "\n",
    "    # (b) 최근 7일 같은 시각 평균 (24시간 간격으로 7개)\n",
    "    #  - 1일 전 같은 시각부터 7일 전 같은 시각까지 평균\n",
    "    same_hour_lag = grp['전력소비량(kWh)'].shift(24)\n",
    "    df['cons_samehour_mean_7d'] = same_hour_lag.rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "    # 참고로 모델에 바로 쓰진 않아도 되는 추가 라그들(원하면 활성화)\n",
    "    df['cons_lag_24h'] = grp['전력소비량(kWh)'].shift(24)\n",
    "    df['cons_lag_48h'] = grp['전력소비량(kWh)'].shift(48)\n",
    "    df['cons_lag_72h'] = grp['전력소비량(kWh)'].shift(72)\n",
    "    df['cons_lag_168h'] = grp['전력소비량(kWh)'].shift(168)  # 7일 전 같은 시각\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2) 기온·일사 기반 냉방 수요 지표 (CDD류)\n",
    "    # -------------------------------------------------------\n",
    "    # 한국 여름 기준 base temp 24°C 가합리(필요시 23~26으로 튜닝)\n",
    "    base_temp = 24.0\n",
    "    # ‘냉방도수’(Cooling Degree) 시간 단위\n",
    "    df['CDD'] = (df['기온(°C)'] - base_temp).clip(lower=0)\n",
    "\n",
    "    # 일사량(MJ/m2)과의 상호작용: 햇볕이 강할수록 체감 부하↑\n",
    "    # 일사량이 0~상위 99퍼센타일 사이로 정규화(robust)\n",
    "    q99 = df['일사(MJ/m2)'].quantile(0.99)\n",
    "    rad_norm = (df['일사(MJ/m2)'].clip(upper=q99) / (q99 + 1e-6))\n",
    "    df['CDD_x_rad'] = df['CDD'] * rad_norm\n",
    "\n",
    "    # 습도(%)와의 상호작용: 습도가 높으면 동일 온도에서도 냉방 부하↑\n",
    "    # 간단히 (1 + 습도/100*알파) 가중. 알파=0.3 정도로 시작(튜닝 가능)\n",
    "    alpha = 0.3\n",
    "    df['CDD_humid_adj'] = df['CDD'] * (1 + alpha * (df['습도(%)'] / 100.0))\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 3) 주말/평일, 공휴일\n",
    "    # -------------------------------------------------------\n",
    "    df['weekday'] = df['dt'].dt.weekday  # 월=0 ... 일=6\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "\n",
    "    # 2024-06~08 사이 한국 공휴일: 현충일(6/6), 광복절(8/15)\n",
    "    kr_holidays = {\n",
    "        pd.Timestamp(2024, 6, 6),  # 현충일\n",
    "        pd.Timestamp(2024, 8, 15), # 광복절\n",
    "    }\n",
    "    df['is_holiday'] = df['날짜'].isin(kr_holidays).astype(int)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 4) 태양광·ESS·PCS 용량 대비 “동작 가능성” 지표\n",
    "    #    (실제 제어 로그가 없으니 ‘가능성/잠재력’을 피처로 넣는다)\n",
    "    # -------------------------------------------------------\n",
    "    # 설비 유무 이진\n",
    "    df['has_pv'] = (df['태양광용량(kW)'] > 0).astype(int)\n",
    "    df['has_ess'] = (df['ESS저장용량(kWh)'] > 0).astype(int)\n",
    "    df['has_pcs'] = (df['PCS용량(kW)'] > 0).astype(int)\n",
    "\n",
    "    # 낮/밤 플래그 (대략 일사량>0이면 주간으로 간주)\n",
    "    df['is_daylight'] = (df['일사(MJ/m2)'] > 0).astype(int)\n",
    "\n",
    "    # 태양광 ‘동작 가능성’ (설비 있고 + 주간/일사>0)\n",
    "    df['pv_active_potential'] = ((df['has_pv'] == 1) & (df['is_daylight'] == 1)).astype(int)\n",
    "\n",
    "    # 피크/오프피크 (현실 요금제와 다를 수 있지만 합리적 초기값)\n",
    "    df['is_offpeak'] = df['시간'].isin([0,1,2,3,4,5,6,23]).astype(int)\n",
    "    df['is_peak']    = df['시간'].isin([13,14,15,16,17]).astype(int)\n",
    "\n",
    "    # ESS 충방전 ‘가능성’ 피처\n",
    "    df['ess_charge_potential']   = ((df['has_ess']==1) & (df['is_offpeak']==1)).astype(int)\n",
    "    df['ess_discharge_potential'] = ((df['has_ess']==1) & (df['is_peak']==1)).astype(int)\n",
    "\n",
    "    # 용량 스케일 자체도 피처로 사용(로그 스케일로 완만화; 0은 0으로 유지)\n",
    "    for c in ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']:\n",
    "        df[f'log1p_{c}'] = np.log1p(df[c])\n",
    "\n",
    "    # 누설 방지: 타깃 기반 비율은 과거 라그로만 계산\n",
    "    # ESS 대비 부하 비율(전일 같은 시각 소비량 사용)\n",
    "    df['ess_to_load_lag_ratio'] = np.where(\n",
    "        df['cons_lag_24h'].notna(),\n",
    "        df['ESS저장용량(kWh)'] / (df['cons_lag_24h'] + 1e-6),\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 5) 기타 유틸리티 파생\n",
    "    # -------------------------------------------------------\n",
    "    df['month'] = df['dt'].dt.month\n",
    "    df['hour']  = df['시간']  # 가독성용 복사\n",
    "    df['dayofyear'] = df['dt'].dt.dayofyear\n",
    "\n",
    "    # 모델 입력 전에 의미 없는 원본(또는 중복) 컬럼 정리 원하면 아래 사용\n",
    "    # drop_cols = ['dt']  # 학습 시 굳이 안 써도 되면 제거\n",
    "    # df = df.drop(columns=drop_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 사용 예시:\n",
    "# df_feat = make_features(df)\n",
    "# df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e42062-9149-4821-a4de-71cf27598b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0. 라이브러리 & 경로 설정\n",
    "# =========================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pip install lightgbm 먼저 (처음 1번만)\n",
    "# pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\user\\Downloads\\open (1)\"\n",
    "TRAIN_MERGED_PATH = os.path.join(DATA_DIR, \"merged_train.csv\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "BUILD_PATH = os.path.join(DATA_DIR, \"building_info.csv\")\n",
    "SAMPLE_SUB = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "OUT_SUB    = os.path.join(DATA_DIR, \"baseline_lgbm_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfde07e-bd40-4c7b-87a9-8aabf725a997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3382916.py:10: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttrain's rmse: 173.366\tvalid's rmse: 230.791\n",
      "[400]\ttrain's rmse: 154.914\tvalid's rmse: 221.188\n",
      "[600]\ttrain's rmse: 143.383\tvalid's rmse: 216.656\n",
      "[800]\ttrain's rmse: 134.649\tvalid's rmse: 214.773\n",
      "[1000]\ttrain's rmse: 127.614\tvalid's rmse: 213.857\n",
      "[1200]\ttrain's rmse: 121.745\tvalid's rmse: 213.28\n",
      "[1400]\ttrain's rmse: 116.665\tvalid's rmse: 213.123\n",
      "[1600]\ttrain's rmse: 112.139\tvalid's rmse: 212.795\n",
      "[1800]\ttrain's rmse: 108.081\tvalid's rmse: 212.451\n",
      "Early stopping, best iteration is:\n",
      "[1739]\ttrain's rmse: 109.199\tvalid's rmse: 212.38\n",
      "VALID RMSE: 212.38019335781\n",
      "VALID MAE : 101.67560328341894\n"
     ]
    }
   ],
   "source": [
    "# ===== IMPORTS (필요시 중복 있어도 무방) =====\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "# ===== 피처 선택 헬퍼: 숫자/카테고리만 남기기 + 불필요 컬럼 드롭 =====\n",
    "def get_feature_cols(df: pd.DataFrame) -> list:\n",
    "    base_drop = ['전력소비량(kWh)', 'dt', '날짜', '시간', '일시', 'num_date_time']\n",
    "    cols = [c for c in df.columns if c not in base_drop]\n",
    "    cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n",
    "    return cols\n",
    "\n",
    "# =========================\n",
    "# 1. 유틸 함수들\n",
    "# =========================\n",
    "def ensure_datetime_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"일시 → 날짜/시간 분리(또는 이미 분리돼 있으면 그대로) + dt 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    if '날짜' not in df.columns or '시간' not in df.columns:\n",
    "        if '일시' in df.columns:\n",
    "            s = df['일시'].astype(str)\n",
    "            df['날짜'] = pd.to_datetime(s.str.slice(0, 8), format='%Y%m%d')\n",
    "            df['시간'] = s.str.slice(9, 11).astype(int)\n",
    "        else:\n",
    "            raise ValueError(\"날짜/시간 정보가 없습니다. ('일시' 또는 '날짜','시간' 필요)\")\n",
    "    else:\n",
    "        df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "        df['시간'] = df['시간'].astype(int)\n",
    "    df['dt'] = df['날짜'] + pd.to_timedelta(df['시간'], unit='h')\n",
    "    return df\n",
    "\n",
    "def clean_capacity_fields(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"설비 용량에 '-'가 있으면 0으로 치환 후 float 변환\"\"\"\n",
    "    df = df.copy()\n",
    "    cols = ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].replace('-', 0).astype(float)\n",
    "    return df\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# =========================\n",
    "# 2. 특징 엔지니어링(수정 버전)\n",
    "# =========================\n",
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - 미래정보 누설 방지: 전부 shift/rolling(=transform)로 과거만 사용\n",
    "    - groupby().rolling() 대신 groupby().transform(...) 사용\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 일사/일조 안전 처리(테스트에 없을 수 있음)\n",
    "    if '일사(MJ/m2)' not in df.columns:\n",
    "        df['일사(MJ/m2)'] = 0.0\n",
    "    if '일조(hr)' not in df.columns:\n",
    "        df['일조(hr)'] = 0.0\n",
    "\n",
    "    # 정렬\n",
    "    df = df.sort_values(['건물번호', 'dt']).reset_index(drop=True)\n",
    "\n",
    "    # 그룹 객체\n",
    "    grp = df.groupby('건물번호', sort=False)\n",
    "\n",
    "    # ---------- 타깃 라그 ----------\n",
    "    if '전력소비량(kWh)' in df.columns:\n",
    "        df['cons_lag1']     = grp['전력소비량(kWh)'].shift(1)\n",
    "        df['cons_lag_24h']  = grp['전력소비량(kWh)'].shift(24)\n",
    "        df['cons_lag_48h']  = grp['전력소비량(kWh)'].shift(48)\n",
    "        df['cons_lag_72h']  = grp['전력소비량(kWh)'].shift(72)\n",
    "        df['cons_lag_168h'] = grp['전력소비량(kWh)'].shift(168)  # 7일 전\n",
    "        # 최근 24시간 평균 (과거만 참고)\n",
    "        df['cons_mean_24h'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(1).rolling(window=24, min_periods=1).mean())\n",
    "        # 최근 7일 같은 시각 평균\n",
    "        df['cons_samehour_mean_7d'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(24).rolling(window=7, min_periods=1).mean())\n",
    "    else:\n",
    "        for c in ['cons_lag1','cons_lag_24h','cons_lag_48h','cons_lag_72h','cons_lag_168h',\n",
    "                  'cons_mean_24h','cons_samehour_mean_7d']:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    # ---------- 냉방 수요 지표 ----------\n",
    "    base_temp = 24.0\n",
    "    df['CDD'] = (df['기온(°C)'] - base_temp).clip(lower=0)\n",
    "\n",
    "    q99 = df['일사(MJ/m2)'].quantile(0.99) + 1e-6\n",
    "    rad_norm = (df['일사(MJ/m2)'].clip(upper=q99) / q99)\n",
    "    df['CDD_x_rad'] = df['CDD'] * rad_norm\n",
    "\n",
    "    alpha = 0.3\n",
    "    df['CDD_humid_adj'] = df['CDD'] * (1 + alpha * (df['습도(%)'] / 100.0))\n",
    "\n",
    "    # ---------- 달력 피처 ----------\n",
    "    df['weekday']    = df['dt'].dt.weekday\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "    kr_holidays = {pd.Timestamp(2024,6,6), pd.Timestamp(2024,8,15)}\n",
    "    df['is_holiday'] = df['날짜'].isin(kr_holidays).astype(int)\n",
    "\n",
    "    # ---------- 설비 가능성 피처 ----------\n",
    "    df['has_pv']  = (df['태양광용량(kW)']  > 0).astype(int)\n",
    "    df['has_ess'] = (df['ESS저장용량(kWh)'] > 0).astype(int)\n",
    "    df['has_pcs'] = (df['PCS용량(kW)']    > 0).astype(int)\n",
    "    df['is_daylight'] = (df['일사(MJ/m2)'] > 0).astype(int)\n",
    "\n",
    "    df['is_offpeak'] = df['시간'].isin([0,1,2,3,4,5,6,23]).astype(int)\n",
    "    df['is_peak']    = df['시간'].isin([13,14,15,16,17]).astype(int)\n",
    "\n",
    "    df['ess_charge_potential']    = ((df['has_ess']==1) & (df['is_offpeak']==1)).astype(int)\n",
    "    df['ess_discharge_potential'] = ((df['has_ess']==1) & (df['is_peak']==1)).astype(int)\n",
    "\n",
    "    for c in ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']:\n",
    "        df[f'log1p_{c}'] = np.log1p(df[c])\n",
    "\n",
    "    df['ess_to_load_lag_ratio'] = np.where(\n",
    "        df.get('cons_lag_24h', pd.Series(index=df.index)).notna(),\n",
    "        df['ESS저장용량(kWh)'] / (df['cons_lag_24h'] + 1e-6),\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # ---------- 기타 ----------\n",
    "    df['month'] = df['dt'].dt.month\n",
    "    df['hour']  = df['시간']\n",
    "    df['dayofyear'] = df['dt'].dt.dayofyear\n",
    "\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# 3. 학습 데이터 로드 & 피처 생성\n",
    "# =========================\n",
    "train_df = read_csv_smart(TRAIN_MERGED_PATH)\n",
    "train_df = clean_capacity_fields(train_df)\n",
    "train_df = ensure_datetime_cols(train_df)\n",
    "train_feat = make_features(train_df)\n",
    "\n",
    "# =========================\n",
    "# 4. 시계열 검증 분할 (2024-08-17 ~ 2024-08-24)\n",
    "# =========================\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# === 피처 선택 (object/문자열 배제) ===\n",
    "features = get_feature_cols(train_feat)\n",
    "target_col = '전력소비량(kWh)'\n",
    "\n",
    "# 카테고리 지정(피처에 포함된 컬럼만)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr, y_tr = train_part[features], train_part[target_col]\n",
    "X_va, y_va = valid_part[features], valid_part[target_col]\n",
    "\n",
    "# =========================\n",
    "# 5. LightGBM 학습 & 검증 (콜백 방식 조기종료)\n",
    "# =========================\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va, categorical_feature=cat_cols or None)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=200),\n",
    "    lgb.log_evaluation(period=200)\n",
    "]\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "pred_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "print(\"VALID RMSE:\", rmse(y_va, pred_va))\n",
    "print(\"VALID MAE :\", mean_absolute_error(y_va, pred_va))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060ab07e-197a-4cc9-8ad4-973bcffd8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_solar_by_time(all_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # dt/시간 보장\n",
    "    if 'dt' not in all_df.columns:\n",
    "        raise ValueError(\"dt 없으면 ensure_datetime_cols 먼저 호출\")\n",
    "    all_df = all_df.copy()\n",
    "    all_df['month'] = all_df['dt'].dt.month\n",
    "    all_df['hour']  = all_df['시간']\n",
    "\n",
    "    # train/test 구분: 타깃 존재 여부로 판별\n",
    "    is_train = all_df['전력소비량(kWh)'].notna() if '전력소비량(kWh)' in all_df.columns else pd.Series(False, index=all_df.index)\n",
    "\n",
    "    # 기준 통계 (train에서만)\n",
    "    rad_ref = all_df.loc[is_train].groupby(['month','hour'])['일사(MJ/m2)'].median()\n",
    "    sun_ref = all_df.loc[is_train].groupby(['month','hour'])['일조(hr)'].median()\n",
    "\n",
    "    # index 매칭해서 test 행만 채움\n",
    "    idx = pd.MultiIndex.from_frame(all_df[['month','hour']])\n",
    "    fill_rad = rad_ref.reindex(idx).values\n",
    "    fill_sun = sun_ref.reindex(idx).values\n",
    "\n",
    "    need_fill_rad = (~is_train) & (all_df['일사(MJ/m2)'].isna() | (all_df['일사(MJ/m2)'] == 0))\n",
    "    need_fill_sun = (~is_train) & (all_df['일조(hr)'].isna()     | (all_df['일조(hr)'] == 0))\n",
    "\n",
    "    all_df.loc[need_fill_rad, '일사(MJ/m2)'] = fill_rad[need_fill_rad.values]\n",
    "    all_df.loc[need_fill_sun, '일조(hr)']    = fill_sun[need_fill_sun.values]\n",
    "\n",
    "    # 혹시라도 남은 결측은 0으로\n",
    "    all_df['일사(MJ/m2)'] = all_df['일사(MJ/m2)'].fillna(0)\n",
    "    all_df['일조(hr)']    = all_df['일조(hr)'].fillna(0)\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bdf3f-45d2-41a1-8381-5cdc397ec9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9cfa6fe-1aa4-496b-9b7e-1dbbd032e74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train + test concat\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m all_df = pd.concat([train_df, \u001b[43mtest_df\u001b[49m], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m all_df = clean_capacity_fields(all_df)\n\u001b[32m      4\u001b[39m all_df = ensure_datetime_cols(all_df)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# train + test concat\n",
    "all_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "all_df = clean_capacity_fields(all_df)\n",
    "all_df = ensure_datetime_cols(all_df)\n",
    "\n",
    "# ★ 추가\n",
    "all_df = backfill_solar_by_time(all_df)\n",
    "\n",
    "# 그 다음 피처 생성\n",
    "all_feat = make_features(all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d301bc87-5bc8-4aaf-805c-7ed92579fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_features() 끝부분에 추가\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['시간']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['시간']/24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89501477-9c9f-4706-bc84-ebd15a9e5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - 미래정보 누설 방지: shift/rolling 모두 과거만 사용\n",
    "    - groupby().transform(...) 으로 인덱스 정렬 유지\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 일사/일조 안전 처리(테스트에 없을 수 있음)\n",
    "    if '일사(MJ/m2)' not in df.columns:\n",
    "        df['일사(MJ/m2)'] = 0.0\n",
    "    if '일조(hr)' not in df.columns:\n",
    "        df['일조(hr)'] = 0.0\n",
    "\n",
    "    # 정렬 후 그룹 객체 생성\n",
    "    df = df.sort_values(['건물번호', 'dt']).reset_index(drop=True)\n",
    "    grp = df.groupby('건물번호', sort=False)  # ← 여기서 grp 정의\n",
    "\n",
    "    # ---------- 타깃 라그 & 롤링 ----------\n",
    "    if '전력소비량(kWh)' in df.columns:\n",
    "        df['cons_lag1']     = grp['전력소비량(kWh)'].shift(1)\n",
    "        df['cons_lag_24h']  = grp['전력소비량(kWh)'].shift(24)\n",
    "        df['cons_lag_48h']  = grp['전력소비량(kWh)'].shift(48)\n",
    "        df['cons_lag_72h']  = grp['전력소비량(kWh)'].shift(72)\n",
    "        df['cons_lag_168h'] = grp['전력소비량(kWh)'].shift(168)  # 7일 전\n",
    "\n",
    "        # 최근 24시간 평균(과거만; shift(1) 후 rolling)\n",
    "        df['cons_mean_24h'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(1).rolling(window=24, min_periods=1).mean())\n",
    "\n",
    "        # 최근 7일 같은 시각 평균(24시간 간격 7개)\n",
    "        df['cons_samehour_mean_7d'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(24).rolling(window=7, min_periods=1).mean())\n",
    "\n",
    "        # ✅ 최근 24시간 표준편차(변동성) — cons_lag1(과거값) 기반\n",
    "        df['cons_std_24h'] = grp['cons_lag1'] \\\n",
    "            .transform(lambda s: s.rolling(window=24, min_periods=6).std())\n",
    "    else:\n",
    "        for c in ['cons_lag1','cons_lag_24h','cons_lag_48h','cons_lag_72h','cons_lag_168h',\n",
    "                  'cons_mean_24h','cons_samehour_mean_7d','cons_std_24h']:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    # ---------- 냉방 수요 지표 ----------\n",
    "    base_temp = 24.0\n",
    "    df['CDD'] = (df['기온(°C)'] - base_temp).clip(lower=0)\n",
    "\n",
    "    q99 = df['일사(MJ/m2)'].quantile(0.99) + 1e-6\n",
    "    rad_norm = (df['일사(MJ/m2)'].clip(upper=q99) / q99)\n",
    "    df['CDD_x_rad'] = df['CDD'] * rad_norm\n",
    "\n",
    "    alpha = 0.3\n",
    "    df['CDD_humid_adj'] = df['CDD'] * (1 + alpha * (df['습도(%)'] / 100.0))\n",
    "\n",
    "    # ---------- 달력 피처 ----------\n",
    "    df['weekday']    = df['dt'].dt.weekday\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "    kr_holidays = {pd.Timestamp(2024,6,6), pd.Timestamp(2024,8,15)}\n",
    "    df['is_holiday'] = df['날짜'].isin(kr_holidays).astype(int)\n",
    "\n",
    "    # ---------- 설비 가능성 피처 ----------\n",
    "    df['has_pv']  = (df['태양광용량(kW)']  > 0).astype(int)\n",
    "    df['has_ess'] = (df['ESS저장용량(kWh)'] > 0).astype(int)\n",
    "    df['has_pcs'] = (df['PCS용량(kW)']    > 0).astype(int)\n",
    "    df['is_daylight'] = (df['일사(MJ/m2)'] > 0).astype(int)\n",
    "    df['is_offpeak'] = df['시간'].isin([0,1,2,3,4,5,6,23]).astype(int)\n",
    "    df['is_peak']    = df['시간'].isin([13,14,15,16,17]).astype(int)\n",
    "    df['ess_charge_potential']    = ((df['has_ess']==1) & (df['is_offpeak']==1)).astype(int)\n",
    "    df['ess_discharge_potential'] = ((df['has_ess']==1) & (df['is_peak']==1)).astype(int)\n",
    "\n",
    "    for c in ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']:\n",
    "        df[f'log1p_{c}'] = np.log1p(df[c])\n",
    "\n",
    "    df['ess_to_load_lag_ratio'] = np.where(\n",
    "        df.get('cons_lag_24h', pd.Series(index=df.index)).notna(),\n",
    "        df['ESS저장용량(kWh)'] / (df['cons_lag_24h'] + 1e-6),\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # ---------- 기타 ----------\n",
    "    df['month'] = df['dt'].dt.month\n",
    "    df['hour']  = df['시간']\n",
    "    df['dayofyear'] = df['dt'].dt.dayofyear\n",
    "\n",
    "    # (옵션) 시간 사이클릭 인코딩 원하면 활성화\n",
    "    # df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "    # df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65439c9-850b-44c1-a451-17dd807f64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'tweedie',\n",
    "    'tweedie_variance_power': 1.4,  # 1.2~1.6 사이 튜닝\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3f2280-b543-4aae-b746-c922f6dacc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ABS = 1e12  # 과도한 값 하드 클립 임계\n",
    "\n",
    "def sanitize_matrix(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Inf 제거 + 과대값 클립 (LightGBM은 NaN은 허용, Inf는 불가)\"\"\"\n",
    "    X = X.copy()\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X[num_cols] = X[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    X[num_cols] = X[num_cols].clip(lower=-MAX_ABS, upper=MAX_ABS)\n",
    "    return X\n",
    "\n",
    "def safe_log1p_vec(a):\n",
    "    \"\"\"음수/비정상값 방지 후 log1p\"\"\"\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    # 비정상(y에 NaN/inf) → 0으로 대체 (혹은 np.nan 유지하고 마스킹하려면 전략 바꿔도 됨)\n",
    "    a = np.where(np.isfinite(a), a, 0.0)\n",
    "    a = np.clip(a, 0, None)  # -0 방지\n",
    "    return np.log1p(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa11bc-717b-441b-a5fd-9bd63dc929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5. LightGBM 학습 & 검증 (로그변환 + 입력 정화)\n",
    "# =========================\n",
    "# X 정화(Inf 제거/클립)\n",
    "X_tr = sanitize_matrix(X_tr)\n",
    "X_va = sanitize_matrix(X_va)\n",
    "\n",
    "# y 안전 로그변환\n",
    "y_tr_log = safe_log1p_vec(y_tr)\n",
    "y_va_log = safe_log1p_vec(y_va)\n",
    "\n",
    "# 안전 체크(디버그 용 — 문제 있으면 어떤 값인지 바로 알 수 있음)\n",
    "assert np.isfinite(y_tr_log).all(), \"y_tr_log에 비정상값이 있습니다.\"\n",
    "assert np.isfinite(y_va_log).all(), \"y_va_log에 비정상값이 있습니다.\"\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_log, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_log, categorical_feature=cat_cols or None)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(period=200)]\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 예측(로그→원복)\n",
    "pred_va_log = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "pred_va = np.expm1(pred_va_log)\n",
    "\n",
    "print(\"VALID RMSE:\", rmse(y_va, pred_va))\n",
    "print(\"VALID MAE :\", mean_absolute_error(y_va, pred_va))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eabfd54-6091-4fd8-8a0f-7fa83fab2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [\n",
    "    {'num_leaves': 48, 'min_data_in_leaf': 80, 'lambda_l2': 0.5},\n",
    "    {'num_leaves': 64, 'min_data_in_leaf': 60, 'lambda_l2': 1.0},\n",
    "    {'num_leaves': 96, 'min_data_in_leaf': 40, 'lambda_l2': 2.0},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f2a5f25-babd-4732-bad8-a92890462a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 by 건물번호:\n",
      " 건물번호\n",
      "10    975.309755\n",
      "3     919.754590\n",
      "79    525.064795\n",
      "45    501.634111\n",
      "1     425.058776\n",
      "23    393.314688\n",
      "54    366.046030\n",
      "43    329.434740\n",
      "34    325.694886\n",
      "64    316.445453\n",
      "Name: se, dtype: float64\n",
      "By 건물유형:\n",
      " 건물유형\n",
      "호텔          364.313067\n",
      "병원          322.632263\n",
      "백화점         240.597665\n",
      "IDC(전화국)    193.622124\n",
      "연구소         171.481702\n",
      "건물기타        144.326968\n",
      "학교          137.332301\n",
      "공공          128.527986\n",
      "상용          114.194073\n",
      "아파트          80.796247\n",
      "Name: se, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\1986457022.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(\"Top-10 by 건물번호:\\n\", va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
     ]
    }
   ],
   "source": [
    "va_err = valid_part[['건물번호','건물유형']].copy()\n",
    "va_err['se'] = (y_va.values - pred_va)**2\n",
    "print(\"Top-10 by 건물번호:\\n\", va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "print(\"By 건물유형:\\n\", va_err.groupby('건물유형')['se'].mean().pow(0.5).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60ab5875-9dd8-4000-8db3-572263e4aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline(df):\n",
    "    base = df['cons_samehour_mean_7d']\n",
    "    base = base.fillna(df['cons_mean_24h'])\n",
    "    base = base.fillna(df['cons_lag1'])\n",
    "    base = base.fillna(df['전력소비량(kWh)'].median() if '전력소비량(kWh)' in df.columns else 0)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f59eeae1-0165-4004-9863-2494249776ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttrain's rmse: 208.044\tvalid's rmse: 299.621\n",
      "[400]\ttrain's rmse: 173.802\tvalid's rmse: 278.029\n",
      "[600]\ttrain's rmse: 156.796\tvalid's rmse: 270.213\n",
      "[800]\ttrain's rmse: 145.22\tvalid's rmse: 266.311\n",
      "[1000]\ttrain's rmse: 136.718\tvalid's rmse: 263.252\n",
      "[1200]\ttrain's rmse: 129.734\tvalid's rmse: 262.155\n",
      "[1400]\ttrain's rmse: 123.945\tvalid's rmse: 260.827\n",
      "[1600]\ttrain's rmse: 118.758\tvalid's rmse: 260.395\n",
      "[1800]\ttrain's rmse: 114.191\tvalid's rmse: 259.365\n",
      "[2000]\ttrain's rmse: 110.226\tvalid's rmse: 259.047\n",
      "[2200]\ttrain's rmse: 106.599\tvalid's rmse: 258.916\n",
      "Early stopping, best iteration is:\n",
      "[2076]\ttrain's rmse: 108.802\tvalid's rmse: 258.512\n",
      "VALID RMSE: 258.5116251016002\n",
      "VALID MAE : 136.39708264373976\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5. LightGBM 학습 & 검증 (잔차 학습)\n",
    "# =========================\n",
    "# 베이스라인 생성 (누설 없음: 전부 shift/rolling 기반 피처)\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "\n",
    "# 잔차 타깃\n",
    "y_tr_resid = y_tr - baseline_tr.values\n",
    "y_va_resid = y_va - baseline_va.values\n",
    "\n",
    "# (안전) X에서 ±inf 제거\n",
    "X_tr = X_tr.replace([np.inf, -np.inf], np.nan)\n",
    "X_va = X_va.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',   # 나중에 tweedie/huber 시도 가능\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(period=200)]\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 잔차 예측 + 베이스라인 복원\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "pred_va = baseline_va.values + pred_va_resid\n",
    "\n",
    "print(\"VALID RMSE:\", rmse(y_va, pred_va))\n",
    "print(\"VALID MAE :\", mean_absolute_error(y_va, pred_va))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1afc56f8-12cf-4167-a7fb-d0af7d58224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료 → C:\\Users\\user\\Downloads\\open (1)\\baseline_lgbm_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6. 제출 파일 생성 (num_date_time 미사용 버전)\n",
    "# =========================\n",
    "sub = read_csv_smart(SAMPLE_SUB)  # 샘플 제출 양식 그대로 사용\n",
    "\n",
    "# 예측값 길이가 샘플과 달라도 안전하게 할당(인덱스 기준 정렬)\n",
    "# - 길이가 짧으면 남는 행은 NaN\n",
    "# - 길이가 길면 초과 분량은 자동으로 버려짐\n",
    "sub['answer'] = pd.Series(test_pred, index=sub.index)\n",
    "\n",
    "# 저장 (엑셀 호환 위해 utf-8-sig 권장)\n",
    "sub.to_csv(OUT_SUB, index=False, encoding='utf-8-sig')\n",
    "print(f\"저장 완료 → {OUT_SUB}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9397eff3-644a-4778-9453-88c6dcbb4242",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_tr_resid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m w_tr = np.ones(\u001b[38;5;28mlen\u001b[39m(train_part), dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m      6\u001b[39m w_tr[train_part[\u001b[33m'\u001b[39m\u001b[33m건물번호\u001b[39m\u001b[33m'\u001b[39m].isin(hard_blds).values] = \u001b[32m2.0\u001b[39m  \u001b[38;5;66;03m# 2~3배 시도\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m lgb_train = lgb.Dataset(X_tr, label=\u001b[43my_tr_resid\u001b[49m, weight=w_tr, categorical_feature=cat_cols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_tr_resid' is not defined"
     ]
    }
   ],
   "source": [
    "# 문제 빌딩 리스트 (네 출력 기준)\n",
    "hard_blds = {3, 10, 79, 45, 1, 23, 67, 57, 34, 64}\n",
    "\n",
    "# 5단계 학습 직전에 가중치 계산\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(hard_blds).values] = 2.0  # 2~3배 시도\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "557b07eb-aa71-49f8-9a29-4bc7d4c4205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    잔차 학습용 베이스라인:\n",
    "      1) cons_samehour_mean_7d\n",
    "      2) cons_mean_24h\n",
    "      3) cons_lag1\n",
    "      4) (최후) 학습 구간 타깃 중앙값\n",
    "    \"\"\"\n",
    "    base = df.get('cons_samehour_mean_7d')\n",
    "    if base is None: base = pd.Series(index=df.index, dtype=float)\n",
    "    base = base.fillna(df.get('cons_mean_24h'))\n",
    "    base = base.fillna(df.get('cons_lag1'))\n",
    "    if '전력소비량(kWh)' in df.columns:\n",
    "        base = base.fillna(df['전력소비량(kWh)'].median())\n",
    "    else:\n",
    "        base = base.fillna(0.0)\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316f26-78cf-46e4-ab7f-1503ec2afcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5R. LightGBM 학습 & 검증 (잔차 학습)\n",
    "# =========================\n",
    "\n",
    "# 피처 재선택(혹시 위에서 수정되었을 수 있으니 보강)\n",
    "features = get_feature_cols(train_feat)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr, y_tr = train_part[features], train_part['전력소비량(kWh)']\n",
    "X_va, y_va = valid_part[features], valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 베이스라인 생성(인덱스 정렬 유지)\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "\n",
    "# 잔차 타깃\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# (선택) 문제 유형 가중치 — 처음엔 False로 두고 결과 본 뒤 켜줘\n",
    "USE_TYPE_WEIGHTS = False\n",
    "TYPE_WEIGHT = {4: 2.0, 9: 2.0}  # 필요시 가중치 조정\n",
    "if USE_TYPE_WEIGHTS:\n",
    "    w_tr = np.ones(len(train_part), dtype=float)\n",
    "    mask = train_part['건물유형'].map(TYPE_WEIGHT).fillna(1.0).values\n",
    "    w_tr = w_tr * mask\n",
    "else:\n",
    "    w_tr = None\n",
    "\n",
    "# 안전 처리(±inf → NaN)\n",
    "X_tr = X_tr.replace([np.inf, -np.inf], np.nan)\n",
    "X_va = X_va.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',   # 잔차는 음수/양수 모두 가능 → 회귀(평균제곱오차)로\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1\n",
    "}\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(period=200)]\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 잔차 예측 + 베이스라인 복원\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "pred_va = baseline_va.values + pred_va_resid\n",
    "\n",
    "print(\"VALID RMSE (residual):\", rmse(y_va, pred_va))\n",
    "print(\"VALID MAE  (residual):\", mean_absolute_error(y_va, pred_va))\n",
    "\n",
    "# --- 에러 분석: 건물/유형별 RMSE ---\n",
    "va_err = valid_part[['건물번호','건물유형']].copy()\n",
    "va_err['se'] = (y_va.values - pred_va)**2\n",
    "print(\"Top-10 by 건물번호:\\n\",\n",
    "      va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "print(\"By 건물유형:\\n\",\n",
    "      va_err.groupby('건물유형')['se'].mean().pow(0.5).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9b4ebd7-4cc9-4db4-ac6c-1bdecd285c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "random.seed(42); np.random.seed(42)\n",
    "# LightGBM 쪽은 params['seed']=42, params['num_threads']=4 정도 권장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7ae828-3ed3-4542-acfe-127e48ded3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    df = df.copy()\n",
    "    for c in df.select_dtypes(include=['float64']).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast='float')\n",
    "    for c in df.select_dtypes(include=['int64']).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast='integer')\n",
    "    return df\n",
    "\n",
    "# train_df, test_df 읽은 직후 한 번씩:\n",
    "# train_df = downcast(train_df)\n",
    "# test_df  = downcast(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda0882e-1d44-4867-8a3e-89867e3063dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backfill_solar_by_time(all_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    all_df = all_df.copy()\n",
    "    if 'dt' not in all_df.columns:\n",
    "        raise ValueError(\"ensure_datetime_cols 먼저 호출해줘.\")\n",
    "    all_df['month'] = all_df['dt'].dt.month\n",
    "    all_df['hour']  = all_df['시간']\n",
    "    is_train = all_df['전력소비량(kWh)'].notna() if '전력소비량(kWh)' in all_df.columns else False\n",
    "\n",
    "    rad_ref = all_df[is_train].groupby(['month','hour'])['일사(MJ/m2)'].median()\n",
    "    sun_ref = all_df[is_train].groupby(['month','hour'])['일조(hr)'].median()\n",
    "\n",
    "    idx = pd.MultiIndex.from_frame(all_df[['month','hour']])\n",
    "    fill_rad = rad_ref.reindex(idx).values\n",
    "    fill_sun = sun_ref.reindex(idx).values\n",
    "\n",
    "    need_rad = (~is_train) & (all_df['일사(MJ/m2)'].isna() | (all_df['일사(MJ/m2)'] == 0))\n",
    "    need_sun = (~is_train) & (all_df['일조(hr)'].isna()     | (all_df['일조(hr)'] == 0))\n",
    "    all_df.loc[need_rad, '일사(MJ/m2)'] = fill_rad[need_rad.values]\n",
    "    all_df.loc[need_sun, '일조(hr)']    = fill_sun[need_sun.values]\n",
    "\n",
    "    all_df['일사(MJ/m2)'] = all_df['일사(MJ/m2)'].fillna(0)\n",
    "    all_df['일조(hr)']    = all_df['일조(hr)'].fillna(0)\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3770205-f644-442d-9cb4-506ffadf3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_baseline(df: pd.DataFrame) -> pd.Series:\n",
    "    base = df.get('cons_samehour_mean_7d')\n",
    "    if base is None:\n",
    "        base = pd.Series(index=df.index, dtype=float)\n",
    "    base = base.fillna(df.get('cons_mean_24h'))\n",
    "    base = base.fillna(df.get('cons_lag1'))\n",
    "    if '전력소비량(kWh)' in df.columns:\n",
    "        base = base.fillna(df['전력소비량(kWh)'].median())\n",
    "    else:\n",
    "        base = base.fillna(0.0)\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9572d486-466b-4af9-95a6-0c34587fbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "def get_feature_cols(df):\n",
    "    drop = ['전력소비량(kWh)','dt','날짜','시간','일시','num_date_time']\n",
    "    cols = [c for c in df.columns if c not in drop]\n",
    "    cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n",
    "    return cols\n",
    "\n",
    "# 검증 파트\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features)\n",
    "X_va = valid_part.reindex(columns=features)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0de9cb-5e1e-4d30-b350-c72c7791999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 173.802\tvalid's rmse: 278.029\n",
      "[800]\ttrain's rmse: 145.22\tvalid's rmse: 266.311\n",
      "[1200]\ttrain's rmse: 129.734\tvalid's rmse: 262.155\n",
      "[1600]\ttrain's rmse: 118.758\tvalid's rmse: 260.395\n",
      "[2000]\ttrain's rmse: 110.226\tvalid's rmse: 259.047\n",
      "Early stopping, best iteration is:\n",
      "[2076]\ttrain's rmse: 108.802\tvalid's rmse: 258.512\n",
      "VALID RMSE: 258.5116251016002\n",
      "VALID MAE : 136.39708264373976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\195317522.py:37: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  va_err_per_bld = va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False)\n"
     ]
    }
   ],
   "source": [
    "# 베이스라인 & 잔차\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# (옵션) 유형 가중치\n",
    "USE_TYPE_WEIGHTS = False\n",
    "TYPE_WEIGHT = {4:2.0, 9:2.0}\n",
    "w_tr = None\n",
    "if USE_TYPE_WEIGHTS and '건물유형' in train_part.columns:\n",
    "    w_tr = train_part['건물유형'].map(TYPE_WEIGHT).fillna(1.0).astype(float).values\n",
    "\n",
    "# LGBM 학습\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':64,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':50,'lambda_l2':1.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr.replace([np.inf,-np.inf], np.nan), label=y_tr_resid, weight=w_tr,\n",
    "                        categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va.replace([np.inf,-np.inf], np.nan), label=y_va_resid,\n",
    "                        categorical_feature=cat_cols or None)\n",
    "callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    "model = lgb.train(params, lgb_train, num_boost_round=5000,\n",
    "                  valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "# 복원해서 검증 점수\n",
    "pred_va = baseline_va.values + model.predict(X_va, num_iteration=model.best_iteration)\n",
    "print(\"VALID RMSE:\", rmse(y_va, pred_va))\n",
    "print(\"VALID MAE :\", mean_absolute_error(y_va, pred_va))\n",
    "\n",
    "# 에러 테이블 저장(재현성 위해 파일로 남겨)\n",
    "va_err = valid_part[['건물번호','건물유형']].copy()\n",
    "va_err['se'] = (y_va.values - pred_va)**2\n",
    "va_err_per_bld = va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False)\n",
    "va_err_per_type = va_err.groupby('건물유형')['se'].mean().pow(0.5).sort_values(ascending=False)\n",
    "va_err_per_bld.head(10).to_csv(\"val_top10_buildings.csv\", encoding='utf-8-sig')\n",
    "va_err_per_type.to_csv(\"val_by_type.csv\", encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52551c8b-7543-45fa-968e-26b22e41eaca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# all_df → ensure_datetime_cols → (옵션) backfill_solar_by_time → make_features 까지 완료됐다고 가정\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m all_feat_train = \u001b[43mall_feat\u001b[49m.iloc[:\u001b[38;5;28mlen\u001b[39m(train_df)].copy()\n\u001b[32m      3\u001b[39m all_feat_test  = all_feat.iloc[\u001b[38;5;28mlen\u001b[39m(train_df):].copy()\n\u001b[32m      5\u001b[39m features_full = get_feature_cols(all_feat_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'all_feat' is not defined"
     ]
    }
   ],
   "source": [
    "# all_df → ensure_datetime_cols → (옵션) backfill_solar_by_time → make_features 까지 완료됐다고 가정\n",
    "all_feat_train = all_feat.iloc[:len(train_df)].copy()\n",
    "all_feat_test  = all_feat.iloc[len(train_df):].copy()\n",
    "\n",
    "features_full = get_feature_cols(all_feat_train)\n",
    "cat_cols_full = [c for c in ['건물번호','건물유형'] if c in features_full]\n",
    "for c in cat_cols_full:\n",
    "    all_feat_train[c] = all_feat_train[c].astype('category')\n",
    "    all_feat_test[c]  = all_feat_test[c].astype('category')\n",
    "\n",
    "X_full = all_feat_train.reindex(columns=features_full).replace([np.inf,-np.inf], np.nan)\n",
    "y_full = all_feat_train['전력소비량(kWh)']\n",
    "baseline_full = build_baseline(all_feat_train)\n",
    "baseline_te   = build_baseline(all_feat_test)\n",
    "\n",
    "y_full_resid = (y_full - baseline_full).astype(float)\n",
    "lgb_full = lgb.Dataset(X_full, label=y_full_resid, categorical_feature=cat_cols_full or None)\n",
    "final_model = lgb.train(params, lgb_full, num_boost_round=(model.best_iteration or 2000))\n",
    "\n",
    "X_te = all_feat_test.reindex(columns=features_full).replace([np.inf,-np.inf], np.nan)\n",
    "test_pred = baseline_te.values + final_model.predict(X_te, num_iteration=final_model.best_iteration)\n",
    "\n",
    "sub = read_csv_smart(SAMPLE_SUB)\n",
    "sub['answer'] = pd.Series(test_pred, index=sub.index)\n",
    "sub.to_csv(OUT_SUB, index=False, encoding='utf-8-sig')\n",
    "print(f\"저장 완료 → {OUT_SUB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b16ae-a642-4661-8a97-742cd85bcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac8902-65b0-46bc-a6fb-864865915a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5R. LightGBM 학습 & 검증 (잔차 학습 + α 블렌딩)\n",
    "# =========================\n",
    "\n",
    "# 피처 재선택(안전하게 reindex)\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf, -np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf, -np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 베이스라인(누설 없음: shift/rolling 기반) → 잔차 타깃\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# (옵션) 유형 가중치 — 처음엔 꺼두고 결과 보고 켜자\n",
    "USE_TYPE_WEIGHTS = False\n",
    "TYPE_WEIGHT = {4: 2.0, 9: 2.0}\n",
    "w_tr = None\n",
    "if USE_TYPE_WEIGHTS and ('건물유형' in train_part.columns):\n",
    "    w_tr = train_part['건물유형'].map(TYPE_WEIGHT).fillna(1.0).astype(float).values\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'lambda_l2': 1.0,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1,\n",
    "    'num_threads': 4,\n",
    "}\n",
    "callbacks = [lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(period=400)]\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=['train','valid'],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ----- 블렌딩 α 계산 (최소제곱 닫힌형식) -----\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "\n",
    "base_rmse = rmse(y_va, baseline_va)\n",
    "base_mae  = mean_absolute_error(y_va, baseline_va)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "den = float(np.sum(pred_va_resid**2) + 1e-9)\n",
    "alpha = float(np.sum(true_resid_va * pred_va_resid) / den)   # 최적 α\n",
    "alpha = max(0.0, min(alpha, 1.5))  # 안정화 클립\n",
    "\n",
    "pred_va = baseline_va.values + alpha * pred_va_resid\n",
    "\n",
    "print(f\"[Blending] alpha={alpha:.3f}\")\n",
    "print(\"Baseline-only  RMSE:\", base_rmse, \"MAE:\", base_mae)\n",
    "print(\"Residual-only RMSE:\", rmse(true_resid_va, pred_va_resid))\n",
    "print(\"BLENDED       RMSE:\", rmse(y_va, pred_va), \"MAE:\", mean_absolute_error(y_va, pred_va))\n",
    "\n",
    "# 나중에 6R에서 재사용\n",
    "ALPHA_BEST = alpha\n",
    "\n",
    "# --- 에러 분석 (빌딩/유형별) ---\n",
    "va_err = valid_part[['건물번호','건물유형']].copy()\n",
    "va_err['se'] = (y_va.values - pred_va)**2\n",
    "print(\"Top-10 by 건물번호:\\n\",\n",
    "      va_err.groupby('건물번호')['se'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "print(\"By 건물유형:\\n\",\n",
    "      va_err.groupby('건물유형')['se'].mean().pow(0.5).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0796a-76ce-42c9-8014-5028b5e4bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 잔차 예측\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "\n",
    "# 베이스라인 점수\n",
    "base_rmse = np.sqrt(mean_squared_error(y_va, baseline_va))\n",
    "base_mae  = mean_absolute_error(y_va, baseline_va)\n",
    "base_r2   = r2_score(y_va, baseline_va)\n",
    "\n",
    "# 최적 α (닫힌형식) + 블렌딩 점수\n",
    "true_resid = (y_va - baseline_va).values\n",
    "den = float(np.sum(pred_va_resid**2) + 1e-9)\n",
    "alpha = float(np.sum(true_resid * pred_va_resid) / den)\n",
    "alpha = max(0.0, min(alpha, 1.5))\n",
    "pred_va = baseline_va.values + alpha * pred_va_resid\n",
    "\n",
    "blend_rmse = np.sqrt(mean_squared_error(y_va, pred_va))\n",
    "blend_mae  = mean_absolute_error(y_va, pred_va)\n",
    "blend_r2   = r2_score(y_va, pred_va)\n",
    "\n",
    "print(f\"alpha={alpha:.3f}\")\n",
    "print(f\"[Baseline] RMSE={base_rmse:.3f} MAE={base_mae:.3f} R2={base_r2:.4f}\")\n",
    "print(f\"[Blended ] RMSE={blend_rmse:.3f} MAE={blend_mae:.3f} R2={blend_r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ce248-7a9e-4ce1-8209-45f34a6408cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 기준 10분위로 나눠서 실제 평균과 비교\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_va})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b704ef9-ebb5-4668-8b09-3b387771ecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간대별 잔차통계:\n",
      "             mean         std  count\n",
      "hour                               \n",
      "0       3.266520  159.376064    800\n",
      "1       4.701862  147.683415    800\n",
      "2      11.871789  144.551729    800\n",
      "3       0.923770  150.067881    800\n",
      "4      -7.801033  179.145872    800\n",
      "5       2.412163  154.708147    800\n",
      "6       9.073931  174.606392    800\n",
      "7       3.414813  198.042050    800\n",
      "8     -19.215013  234.254688    800\n",
      "9     -30.409998  265.857782    800\n",
      "10    -47.461959  263.023307    800\n",
      "11   -110.690803  295.701160    800\n",
      "12   -127.299821  275.864882    800\n",
      "13   -141.238065  298.483692    800\n",
      "14   -138.442811  298.695544    800\n",
      "15   -144.973970  326.251247    800\n",
      "16   -127.934494  385.695565    800\n",
      "17   -110.095268  310.676355    800\n",
      "18   -101.066599  294.251119    800\n",
      "19    -82.120827  289.549671    800\n",
      "20    -32.730890  245.111192    800\n",
      "21    -29.842760  237.086742    800\n",
      "22    -32.564909  199.411701    800\n",
      "23    -15.306709  182.713965    800\n",
      "온도구간별 잔차통계:\n",
      "                 mean         std  count\n",
      "temp_bin                               \n",
      "20.0      -14.054313  197.582172   1022\n",
      "25.0      -27.609058  222.317766  12545\n",
      "30.0     -114.924976  311.438557   5500\n",
      "35.0     -135.476370  195.334267    133\n",
      "유형별 RMSE 비교(베이스라인→블렌딩):\n",
      "               base_se    blend_se  improve(%)\n",
      "건물유형                                         \n",
      "병원        1394.984423  366.833514   73.703397\n",
      "호텔         957.782817  362.816019   62.119176\n",
      "백화점       1735.558149  303.387312   82.519323\n",
      "학교         898.925299  295.651732   67.110534\n",
      "IDC(전화국)   525.816482  223.045287   57.581153\n",
      "연구소        696.267258  220.481307   68.333811\n",
      "건물기타       695.200326  207.186762   70.197545\n",
      "공공         563.987211  163.403797   71.027039\n",
      "상용         570.350033  152.364776   73.285743\n",
      "아파트        361.214086   73.255755   79.719574\n",
      "Top-10 by 건물번호 (블렌딩):\n",
      " 건물번호\n",
      "3     980.592600\n",
      "10    960.665798\n",
      "79    828.491256\n",
      "45    589.883378\n",
      "12    588.206425\n",
      "69    489.947304\n",
      "23    448.471126\n",
      "1     437.299306\n",
      "6     397.305285\n",
      "34    390.835509\n",
      "Name: se, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\2751347869.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  top_bld = tmp2.groupby(\"건물번호\")[\"se\"].mean().pow(0.5).sort_values(ascending=False).head(10)\n"
     ]
    }
   ],
   "source": [
    "res = valid_part[[\"건물번호\",\"건물유형\",\"hour\",\"기온(°C)\"]].copy()\n",
    "res[\"y\"] = y_va.values\n",
    "res[\"yhat\"] = pred_va\n",
    "res[\"resid\"] = res[\"y\"] - res[\"yhat\"]\n",
    "\n",
    "# 시간대별\n",
    "by_hour = res.groupby(\"hour\")[\"resid\"].agg([\"mean\",\"std\",\"count\"])\n",
    "print(\"시간대별 잔차통계:\\n\", by_hour)\n",
    "\n",
    "# 온도 구간별 (5°C 단위)\n",
    "res[\"temp_bin\"] = (res[\"기온(°C)\"]//5)*5\n",
    "by_temp = res.groupby(\"temp_bin\")[\"resid\"].agg([\"mean\",\"std\",\"count\"])\n",
    "print(\"온도구간별 잔차통계:\\n\", by_temp)\n",
    "\n",
    "# 건물유형별 RMSE (베이스라인 vs 블렌딩 비교)\n",
    "tmp = valid_part[[\"건물유형\"]].copy()\n",
    "tmp[\"base_se\"]   = (y_va.values - baseline_va.values)**2\n",
    "tmp[\"blend_se\"]  = (y_va.values - pred_va)**2\n",
    "cmp_type = tmp.groupby(\"건물유형\")[[\"base_se\",\"blend_se\"]].mean().pow(0.5).sort_values(\"blend_se\", ascending=False)\n",
    "cmp_type[\"improve(%)\"] = (1 - cmp_type[\"blend_se\"]/cmp_type[\"base_se\"])*100\n",
    "print(\"유형별 RMSE 비교(베이스라인→블렌딩):\\n\", cmp_type)\n",
    "\n",
    "# 상위 문제 빌딩 Top-10\n",
    "tmp2 = valid_part[[\"건물번호\"]].copy()\n",
    "tmp2[\"se\"] = (y_va.values - pred_va)**2\n",
    "top_bld = tmp2.groupby(\"건물번호\")[\"se\"].mean().pow(0.5).sort_values(ascending=False).head(10)\n",
    "print(\"Top-10 by 건물번호 (블렌딩):\\n\", top_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffade925-f30b-4725-be08-68fb38228708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\tvalid_0's l2: 77300.4\n",
      "[800]\tvalid_0's l2: 70921.3\n",
      "[1200]\tvalid_0's l2: 68725.4\n",
      "[1600]\tvalid_0's l2: 67805.4\n",
      "[2000]\tvalid_0's l2: 67105.4\n",
      "Early stopping, best iteration is:\n",
      "[2076]\tvalid_0's l2: 66828.3\n",
      "Permutation Importance Top-20:\n",
      "                     feature           imp           std\n",
      "18    cons_samehour_mean_7d  4.281631e+06  41895.011875\n",
      "12                cons_lag1  3.329261e+06  20791.980802\n",
      "0                      건물번호  4.462907e+05   8122.529034\n",
      "38                     hour  2.833475e+05   9824.810526\n",
      "13             cons_lag_24h  7.304677e+04    467.204158\n",
      "22                  weekday  5.557012e+04   4869.273276\n",
      "16            cons_lag_168h  4.519914e+04    601.363053\n",
      "6                 일사(MJ/m2)  3.699363e+04   1250.087403\n",
      "17            cons_mean_24h  2.257438e+04    454.303971\n",
      "14             cons_lag_48h  1.478527e+04    591.954276\n",
      "15             cons_lag_72h  8.798136e+03    311.344347\n",
      "7                   연면적(m2)  7.041060e+03    284.342898\n",
      "29               is_offpeak  5.217837e+03    605.476090\n",
      "30                  is_peak  4.861356e+03    553.297655\n",
      "4                     습도(%)  1.185311e+03    143.579432\n",
      "23               is_weekend  9.047333e+02    161.122589\n",
      "36    ess_to_load_lag_ratio  6.194302e+02     77.063834\n",
      "5                    일조(hr)  4.972164e+02    147.372489\n",
      "10             ESS저장용량(kWh)  1.600270e+02      8.275573\n",
      "32  ess_discharge_potential  1.383753e+02     26.702566\n",
      "LightGBM 중요도(Gain) Top-20:\n",
      "                                gain  split\n",
      "건물번호                   3.309208e+11  14201\n",
      "cons_samehour_mean_7d  2.487181e+11  10456\n",
      "hour                   1.952349e+11   7983\n",
      "cons_lag1              1.685351e+11  13209\n",
      "일사(MJ/m2)              6.535541e+10   5540\n",
      "cons_lag_168h          5.769169e+10   8697\n",
      "weekday                5.312988e+10   4256\n",
      "cons_lag_24h           3.686718e+10   7245\n",
      "연면적(m2)                3.437645e+10   1559\n",
      "cons_lag_48h           2.985749e+10   5858\n",
      "cons_lag_72h           1.689705e+10   6403\n",
      "cons_mean_24h          1.659607e+10   6627\n",
      "is_offpeak             1.464159e+10    357\n",
      "is_peak                1.245483e+10    569\n",
      "태양광용량(kW)              7.686703e+09    995\n",
      "dayofyear              6.803299e+09   6747\n",
      "is_holiday             5.547612e+09    365\n",
      "ess_to_load_lag_ratio  5.545954e+09   1567\n",
      "냉방면적(m2)               5.309046e+09   1267\n",
      "일조(hr)                 4.011859e+09   1684\n",
      "shap 미사용 → pred_contrib로 대체: No module named 'shap'\n",
      "Approx SHAP |value| Top-20:\n",
      " cons_samehour_mean_7d    571.415398\n",
      "cons_lag1                440.729984\n",
      "hour                     146.942311\n",
      "건물번호                     144.620425\n",
      "일사(MJ/m2)                 61.518285\n",
      "cons_lag_168h             39.757229\n",
      "weekday                   39.428802\n",
      "cons_lag_24h              37.054594\n",
      "dayofyear                 32.914400\n",
      "is_offpeak                23.002753\n",
      "CDD_humid_adj             22.603109\n",
      "cons_lag_48h              19.615993\n",
      "cons_mean_24h             18.516129\n",
      "cons_lag_72h              12.170403\n",
      "연면적(m2)                   10.943456\n",
      "is_weekend                 8.592415\n",
      "is_peak                    7.838009\n",
      "기온(°C)                     7.803530\n",
      "습도(%)                      7.670785\n",
      "일조(hr)                     5.886691\n",
      "dtype: float64\n",
      "[설명력 체크] Baseline RMSE=1008.062  Blended RMSE=258.370 (alpha=1.009)\n"
     ]
    }
   ],
   "source": [
    "# === 0) 스키러너블 모델로 재학습 (설명력용, 제출에 사용 안 함)\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) 우선 그대로 카테고리 dtype을 사용해서 학습 시도\n",
    "params_sklearn = dict(\n",
    "    objective='regression',\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    feature_fraction=0.85,\n",
    "    bagging_fraction=0.85,\n",
    "    bagging_freq=1,\n",
    "    min_child_samples=50,   # = min_data_in_leaf\n",
    "    reg_lambda=1.0,         # = lambda_l2\n",
    "    random_state=42,\n",
    "    n_estimators=5000,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "use_cat = True\n",
    "try:\n",
    "    model_perm = lgb.LGBMRegressor(**params_sklearn)\n",
    "    model_perm.fit(\n",
    "        X_tr, y_tr_resid,\n",
    "        eval_set=[(X_va, y_va_resid)],\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)],\n",
    "        categorical_feature=cat_cols or None  # pandas 'category' dtype이면 자동 인식\n",
    "    )\n",
    "except Exception as e:\n",
    "    # 2) 버전/환경에 따라 categorical_feature가 막힐 수 있어서 안전한 fallback: 카테고리 → 코드화\n",
    "    print(\"카테고리 직접 전달 실패 → 코드화하여 재시도:\", e)\n",
    "    use_cat = False\n",
    "    X_tr_enc = X_tr.copy()\n",
    "    X_va_enc = X_va.copy()\n",
    "    for c in (cat_cols or []):\n",
    "        X_tr_enc[c] = X_tr_enc[c].cat.codes\n",
    "        X_va_enc[c] = X_va_enc[c].cat.codes\n",
    "    model_perm = lgb.LGBMRegressor(**params_sklearn)\n",
    "    model_perm.fit(\n",
    "        X_tr_enc, y_tr_resid,\n",
    "        eval_set=[(X_va_enc, y_va_resid)],\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    "    )\n",
    "\n",
    "# === 1) Permutation Importance (검증셋 기준)\n",
    "X_pi = X_va if use_cat else X_va_enc\n",
    "pi = permutation_importance(\n",
    "    model_perm, X_pi, y_va_resid,\n",
    "    n_repeats=5, random_state=42, n_jobs=4,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "import pandas as pd, numpy as np\n",
    "pi_tbl = pd.DataFrame({\n",
    "    \"feature\": X_pi.columns,\n",
    "    \"imp\": pi.importances_mean,\n",
    "    \"std\": pi.importances_std\n",
    "}).sort_values(\"imp\", ascending=False)\n",
    "print(\"Permutation Importance Top-20:\\n\", pi_tbl.head(20))\n",
    "\n",
    "# === 2) LightGBM 내장 중요도 (gain/split)도 함께 보기\n",
    "gain = pd.Series(model_perm.booster_.feature_importance(importance_type='gain'),\n",
    "                 index=X_pi.columns).sort_values(ascending=False)\n",
    "split = pd.Series(model_perm.booster_.feature_importance(importance_type='split'),\n",
    "                  index=X_pi.columns).sort_values(ascending=False)\n",
    "imp_tbl = pd.DataFrame({\"gain\": gain, \"split\": split}).fillna(0).sort_values(\"gain\", ascending=False)\n",
    "print(\"LightGBM 중요도(Gain) Top-20:\\n\", imp_tbl.head(20))\n",
    "\n",
    "# === 3) SHAP 대체 (shap 미설치/버전 이슈 대비 → pred_contrib)\n",
    "try:\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(model_perm)\n",
    "    shap_vals = explainer.shap_values(X_pi)\n",
    "    shap_abs = np.abs(shap_vals).mean(axis=0)\n",
    "    shap_tbl = pd.Series(shap_abs, index=X_pi.columns).sort_values(ascending=False).head(20)\n",
    "    print(\"SHAP |value| Top-20:\\n\", shap_tbl)\n",
    "except Exception as e:\n",
    "    print(\"shap 미사용 → pred_contrib로 대체:\", e)\n",
    "    contrib = np.asarray(model_perm.predict(X_pi, pred_contrib=True))\n",
    "    # 마지막 열은 base value, 제외\n",
    "    shap_abs = np.abs(contrib[:, :-1]).mean(axis=0)\n",
    "    shap_tbl = pd.Series(shap_abs, index=X_pi.columns).sort_values(ascending=False).head(20)\n",
    "    print(\"Approx SHAP |value| Top-20:\\n\", shap_tbl)\n",
    "\n",
    "# === 4) 캘리브레이션/블렌딩 비교도 같이 수치로 확인 (설명력 품질 점검, 예측 저장 X)\n",
    "pred_va_resid_hat = model_perm.predict(X_pi, num_iteration=model_perm.best_iteration_)\n",
    "base_rmse = np.sqrt(mean_squared_error(y_va, baseline_va))\n",
    "true_resid = (y_va - baseline_va).values\n",
    "den = float(np.sum(pred_va_resid_hat**2) + 1e-9)\n",
    "alpha = float(np.sum(true_resid * pred_va_resid_hat) / den)\n",
    "alpha = max(0.0, min(alpha, 1.5))\n",
    "pred_va_blend = baseline_va.values + alpha * pred_va_resid_hat\n",
    "blend_rmse = np.sqrt(mean_squared_error(y_va, pred_va_blend))\n",
    "print(f\"[설명력 체크] Baseline RMSE={base_rmse:.3f}  Blended RMSE={blend_rmse:.3f} (alpha={alpha:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07a8c87c-62fc-4a0a-b245-d1f19d1e3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5R 블록에서 옵션만 켜기\n",
    "USE_TYPE_WEIGHTS = True\n",
    "TYPE_WEIGHT = {4: 2.0, 9: 2.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dfc7352-33d1-4bf5-a707-e9e371c4ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # 일사/일조 보정\n",
    "    if '일사(MJ/m2)' not in df.columns: df['일사(MJ/m2)'] = 0.0\n",
    "    if '일조(hr)'   not in df.columns: df['일조(hr)']   = 0.0\n",
    "\n",
    "    # 정렬 & 그룹\n",
    "    df = df.sort_values(['건물번호','dt']).reset_index(drop=True)\n",
    "    grp = df.groupby('건물번호', sort=False)\n",
    "\n",
    "    # ---------- 타깃 라그/롤링 ----------\n",
    "    if '전력소비량(kWh)' in df.columns:\n",
    "        df['cons_lag1']     = grp['전력소비량(kWh)'].shift(1)\n",
    "        df['cons_lag_24h']  = grp['전력소비량(kWh)'].shift(24)\n",
    "        df['cons_lag_48h']  = grp['전력소비량(kWh)'].shift(48)\n",
    "        df['cons_lag_72h']  = grp['전력소비량(kWh)'].shift(72)\n",
    "        df['cons_lag_168h'] = grp['전력소비량(kWh)'].shift(168)\n",
    "        df['cons_mean_24h'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(1).rolling(24, min_periods=1).mean())\n",
    "        df['cons_samehour_mean_7d'] = grp['전력소비량(kWh)'] \\\n",
    "            .transform(lambda s: s.shift(24).rolling(7, min_periods=1).mean())\n",
    "        df['cons_std_24h'] = grp['cons_lag1'] \\\n",
    "            .transform(lambda s: s.rolling(24, min_periods=6).std())\n",
    "    else:\n",
    "        for c in ['cons_lag1','cons_lag_24h','cons_lag_48h','cons_lag_72h',\n",
    "                  'cons_lag_168h','cons_mean_24h','cons_samehour_mean_7d','cons_std_24h']:\n",
    "            df[c] = np.nan\n",
    "    # --- 일중·주기 변화량(라그 이후 계산) ---\n",
    "    df['delta_1h'] = df['cons_lag1']    - df['cons_lag_24h']\n",
    "    df['delta_7d'] = df['cons_lag_24h'] - df['cons_lag_168h']\n",
    "    # ---------- 냉방 수요 지표 ----------\n",
    "    base_temp = 24.0\n",
    "    df['CDD'] = (df['기온(°C)'] - base_temp).clip(lower=0)\n",
    "    q99 = df['일사(MJ/m2)'].quantile(0.99) + 1e-6\n",
    "    rad_norm = (df['일사(MJ/m2)'].clip(upper=q99) / q99)\n",
    "    df['CDD_x_rad'] = df['CDD'] * rad_norm\n",
    "    df['CDD_humid_adj'] = df['CDD'] * (1 + 0.3 * (df['습도(%)'] / 100.0))\n",
    "\n",
    "    # ---------- 달력 & 설비 ----------\n",
    "    df['weekday']    = df['dt'].dt.weekday\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "    kr_holidays = {pd.Timestamp(2024,6,6), pd.Timestamp(2024,8,15)}\n",
    "    df['is_holiday'] = df['날짜'].isin(kr_holidays).astype(int)\n",
    "\n",
    "    df['has_pv']  = (df['태양광용량(kW)']  > 0).astype(int)\n",
    "    df['has_ess'] = (df['ESS저장용량(kWh)'] > 0).astype(int)\n",
    "    df['has_pcs'] = (df['PCS용량(kW)']    > 0).astype(int)\n",
    "    df['is_daylight'] = (df['일사(MJ/m2)'] > 0).astype(int)\n",
    "    df['is_offpeak'] = df['시간'].isin([0,1,2,3,4,5,6,23]).astype(int)\n",
    "    df['is_peak']    = df['시간'].isin([13,14,15,16,17]).astype(int)\n",
    "    df['ess_charge_potential']    = ((df['has_ess']==1) & (df['is_offpeak']==1)).astype(int)\n",
    "    df['ess_discharge_potential'] = ((df['has_ess']==1) & (df['is_peak']==1)).astype(int)\n",
    "    for c in ['태양광용량(kW)','ESS저장용량(kWh)','PCS용량(kW)']:\n",
    "        df[f'log1p_{c}'] = np.log1p(df[c])\n",
    "\n",
    "    df['ess_to_load_lag_ratio'] = np.where(\n",
    "        df.get('cons_lag_24h', pd.Series(index=df.index)).notna(),\n",
    "        df['ESS저장용량(kWh)'] / (df['cons_lag_24h'] + 1e-6),\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # ---------- 기타 ----------\n",
    "    df['month']     = df['dt'].dt.month\n",
    "    df['hour']      = df['시간']\n",
    "    df['dayofyear'] = df['dt'].dt.dayofyear\n",
    "    df['hour_sin']  = np.sin(2*np.pi*df['hour']/24)\n",
    "    df['hour_cos']  = np.cos(2*np.pi*df['hour']/24)\n",
    "\n",
    "    # ---------- 면적 정규화 (라그 생성 '뒤'에 계산) ----------\n",
    "    eps = 1e-6\n",
    "    if '연면적(m2)' in df.columns:\n",
    "        area = pd.to_numeric(df['연면적(m2)'], errors='coerce')\n",
    "        df['cons_lag1_per_m2']   = df['cons_lag1']    / (area + eps)\n",
    "        df['cons_mean24_per_m2'] = df['cons_mean_24h'] / (area + eps)\n",
    "        df['CDD_x_rad_area']     = df['CDD_x_rad'] * (area.fillna(0) / 1000.0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16adb2c3-c06f-4677-abed-cfb9fc3f1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour_sin'] = np.sin(2*np.pi*df['시간']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['시간']/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61fbd9a0-f296-4c38-a529-df6006f39327",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['min_data_in_leaf'] = 120   # 50 → 120\n",
    "params['lambda_l2'] = 2.0          # 1.0 → 2.0\n",
    "# (유지) learning_rate=0.05, num_leaves=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a4afcad-1b17-498a-a36b-918a10611d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5R 바로 앞에서 한 번만 실험(점수만 확인)\n",
    "features_abl = [c for c in features if c != '건물번호']\n",
    "X_tr_abl = train_part.reindex(columns=features_abl)\n",
    "X_va_abl = valid_part.reindex(columns=features_abl)\n",
    "# 같은 파라미터로 간단하게 1500부스트 정도만 재학습해서 RMSE 비교\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb227b13-47c9-488b-b378-1b5268f3428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = make_features(train_df)\n",
    "is_val = (train_feat['dt'] >= pd.Timestamp(2024,8,17)) & (train_feat['dt'] <= pd.Timestamp(2024,8,24,23))\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06b5210b-45cb-45e5-9352-e98db9d5a052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons_lag1': True, 'cons_mean_24h': True, 'cons_lag1_per_m2': True, 'cons_mean24_per_m2': True}\n"
     ]
    }
   ],
   "source": [
    "print({\n",
    "  'cons_lag1': 'cons_lag1' in train_feat.columns,\n",
    "  'cons_mean_24h': 'cons_mean_24h' in train_feat.columns,\n",
    "  'cons_lag1_per_m2': 'cons_lag1_per_m2' in train_feat.columns,\n",
    "  'cons_mean24_per_m2': 'cons_mean24_per_m2' in train_feat.columns\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8166baa-6cb8-48b8-9927-5f8f3ddce20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 177.313\tvalid's rmse: 252.158\n",
      "[800]\ttrain's rmse: 148.709\tvalid's rmse: 240.359\n",
      "[1200]\ttrain's rmse: 132.742\tvalid's rmse: 237.079\n",
      "[1600]\ttrain's rmse: 121.342\tvalid's rmse: 236.088\n",
      "[2000]\ttrain's rmse: 112.554\tvalid's rmse: 234.887\n",
      "Early stopping, best iteration is:\n",
      "[2063]\ttrain's rmse: 111.328\tvalid's rmse: 234.708\n",
      "alpha=1.014\n",
      "[Baseline] RMSE=1008.062  MAE=549.663  R2=0.9318\n",
      "[Blended ] RMSE=234.343  MAE=110.065  R2=0.9963\n",
      "\n",
      "[Calibration by decile]\n",
      "                                      y_mean     yhat_mean     n       bias\n",
      "bin                                                                       \n",
      "(-4.353000000000001, 778.966]    479.693812    471.795176  1920  -7.898637\n",
      "(778.966, 1160.635]              987.892026    983.979869  1920  -3.912157\n",
      "(1160.635, 1523.262]            1331.977807   1323.919429  1920  -8.058378\n",
      "(1523.262, 1818.994]            1691.171203   1681.548043  1920  -9.623160\n",
      "(1818.994, 2177.26]             1979.852432   1981.169189  1920   1.316757\n",
      "(2177.26, 2719.321]             2449.332807   2447.305888  1920  -2.026919\n",
      "(2719.321, 3487.903]            3084.805776   3098.379923  1920  13.574147\n",
      "(3487.903, 5052.746]            4176.036359   4210.405441  1920  34.369082\n",
      "(5052.746, 9549.052]            6673.971901   6731.312583  1920  57.340682\n",
      "(9549.052, 26847.557]          13257.138906  13292.760415  1920  35.621509\n",
      "평균 절대 바이어스: 17.37414271039803\n",
      "\n",
      "[유형별 RMSE 비교]\n",
      "               se_base    se_blend  improve_pct\n",
      "건물유형                                          \n",
      "호텔         957.782817  451.237539    52.887280\n",
      "병원        1394.984423  283.752871    79.659065\n",
      "백화점       1735.558149  278.170642    83.972266\n",
      "IDC(전화국)   525.816482  196.975915    62.539038\n",
      "연구소        696.267258  190.358424    72.660150\n",
      "건물기타       695.200326  161.128282    76.822755\n",
      "학교         898.925299  156.757611    82.561664\n",
      "공공         563.987211  129.083514    77.112333\n",
      "상용         570.350033  114.594093    79.908111\n",
      "아파트        361.214086   72.658734    79.884856\n",
      "\n",
      "[Top-10 by 건물번호]\n",
      " 건물번호\n",
      "10    1278.810629\n",
      "79     805.999243\n",
      "3      789.228502\n",
      "45     467.767270\n",
      "23     446.531202\n",
      "1      434.790990\n",
      "64     382.566276\n",
      "34     328.413109\n",
      "6      312.225107\n",
      "54     306.433501\n",
      "Name: se_blend, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3469888423.py:72: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3469888423.py:86: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
     ]
    }
   ],
   "source": [
    "# 0) 피처 다시 생성 & 검증 분할\n",
    "train_feat = make_features(train_df)\n",
    "\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# 1) 피처 선택(안전하게 reindex)\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 2) 베이스라인 생성 → 잔차 타깃\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# 3) 잔차 모델 학습(보수적 파라미터)\n",
    "import lightgbm as lgb\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':64,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':120,'lambda_l2':2.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "model = lgb.train(\n",
    "    params, lgb_train, num_boost_round=5000,\n",
    "    valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    ")\n",
    "\n",
    "# 4) 설명력/보정력 평가 (예측 저장 X)\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "\n",
    "# 베이스라인/블렌딩 지표\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "base_rmse = rmse(y_va, baseline_va)\n",
    "base_mae  = mean_absolute_error(y_va, baseline_va)\n",
    "base_r2   = r2_score(y_va, baseline_va)\n",
    "\n",
    "true_resid = (y_va - baseline_va).values\n",
    "den = float((pred_va_resid**2).sum() + 1e-9)\n",
    "alpha = float((true_resid * pred_va_resid).sum() / den)\n",
    "alpha = max(0.0, min(alpha, 1.5))  # 안정화\n",
    "pred_va_blend = baseline_va.values + alpha * pred_va_resid\n",
    "\n",
    "blend_rmse = rmse(y_va, pred_va_blend)\n",
    "blend_mae  = mean_absolute_error(y_va, pred_va_blend)\n",
    "blend_r2   = r2_score(y_va, pred_va_blend)\n",
    "\n",
    "print(f\"alpha={alpha:.3f}\")\n",
    "print(f\"[Baseline] RMSE={base_rmse:.3f}  MAE={base_mae:.3f}  R2={base_r2:.4f}\")\n",
    "print(f\"[Blended ] RMSE={blend_rmse:.3f}  MAE={blend_mae:.3f}  R2={blend_r2:.4f}\")\n",
    "\n",
    "# 5) 캘리브레이션(10분위) & 유형/빌딩별 진단\n",
    "import pandas as pd, numpy as np\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_va_blend})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(\"\\n[Calibration by decile]\\n\", cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())\n",
    "\n",
    "va_err = valid_part[['건물번호','건물유형']].copy()\n",
    "va_err['se_base']  = (y_va.values - baseline_va.values)**2\n",
    "va_err['se_blend'] = (y_va.values - pred_va_blend)**2\n",
    "print(\"\\n[유형별 RMSE 비교]\\n\",\n",
    "      va_err.groupby('건물유형')[['se_base','se_blend']].mean().pow(0.5).assign(\n",
    "          improve_pct=lambda d: (1 - d['se_blend']/d['se_base'])*100\n",
    "      ).sort_values('se_blend', ascending=False))\n",
    "\n",
    "print(\"\\n[Top-10 by 건물번호]\\n\",\n",
    "      va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ce77c13-0511-4daf-91f3-d3fbed87993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Blending] a=1.013, b=-11.078\n",
      "Baseline-only  RMSE: 1008.0623627048025 MAE: 549.6628074404762\n",
      "BLENDED       RMSE: 234.0812015762596 MAE: 110.94799522778526\n"
     ]
    }
   ],
   "source": [
    "# ----- a, b 동시 추정(최소제곱) -----\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "A = np.column_stack([pred_va_resid, np.ones_like(pred_va_resid)])\n",
    "a, b = np.linalg.lstsq(A, true_resid_va, rcond=None)[0]\n",
    "a = float(np.clip(a, 0.0, 1.5))  # 안정화\n",
    "b = float(b)\n",
    "\n",
    "pred_va = baseline_va.values + a * pred_va_resid + b\n",
    "\n",
    "print(f\"[Blending] a={a:.3f}, b={b:.3f}\")\n",
    "print(\"Baseline-only  RMSE:\", rmse(y_va, baseline_va), \"MAE:\", mean_absolute_error(y_va, baseline_va))\n",
    "print(\"BLENDED       RMSE:\", rmse(y_va, pred_va), \"MAE:\", mean_absolute_error(y_va, pred_va))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b8f6f66-92fe-4814-a884-d4dc27d9979d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 잔차 예측\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_pred_resid = \u001b[43mfinal_model\u001b[49m.predict(X_te, num_iteration=final_model.best_iteration)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 검증에서 구한 a,b로 복원\u001b[39;00m\n\u001b[32m      5\u001b[39m a_use = a \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1.0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 잔차 예측\n",
    "test_pred_resid = final_model.predict(X_te, num_iteration=final_model.best_iteration)\n",
    "\n",
    "# 검증에서 구한 a,b로 복원\n",
    "a_use = a if 'a' in globals() else 1.0\n",
    "b_use = b if 'b' in globals() else 0.0\n",
    "test_pred = baseline_te.values + a_use * test_pred_resid + b_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3a9b591-0ea2-466a-9133-70f6fd47967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(HARD_BLD).values] = 1.8  # 1.5~2.0 사이 시도\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83ac206a-8e4c-40bd-8369-83c3eec78f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons_lag1': True, 'cons_lag_24h': True, 'cons_lag_168h': True, 'delta_1h': True, 'delta_7d': True}\n"
     ]
    }
   ],
   "source": [
    "# 1) make_features() 셀(패치 포함) 실행\n",
    "\n",
    "# 2) 피처 다시 생성\n",
    "train_feat = make_features(train_df)\n",
    "\n",
    "# 3) 확인\n",
    "print({\n",
    "  'cons_lag1': 'cons_lag1' in train_feat.columns,\n",
    "  'cons_lag_24h': 'cons_lag_24h' in train_feat.columns,\n",
    "  'cons_lag_168h': 'cons_lag_168h' in train_feat.columns,\n",
    "  'delta_1h': 'delta_1h' in train_feat.columns,\n",
    "  'delta_7d': 'delta_7d' in train_feat.columns\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85d4cc43-75f5-4356-90d0-0466b431d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['min_data_in_leaf'] = 150   # 120 → 150\n",
    "params['lambda_l2'] = 3.0          # 2.0 → 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5190c9b-f5cf-49d8-a3d0-4eb73dd84d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 191.932\tvalid's rmse: 250.611\n",
      "[800]\ttrain's rmse: 158.815\tvalid's rmse: 239.59\n",
      "[1200]\ttrain's rmse: 140.375\tvalid's rmse: 234.776\n",
      "[1600]\ttrain's rmse: 127.489\tvalid's rmse: 232.896\n",
      "[2000]\ttrain's rmse: 117.524\tvalid's rmse: 232.333\n",
      "Early stopping, best iteration is:\n",
      "[2090]\ttrain's rmse: 115.572\tvalid's rmse: 231.904\n",
      "[Blending] a=1.015, b=-12.297\n",
      "[Baseline] RMSE=1008.062  MAE=549.663\n",
      "[Blended ] RMSE=231.127  MAE=111.847  R2=0.9964\n",
      "\n",
      "[Calibration by decile]\n",
      "                              y_mean     yhat_mean     n       bias\n",
      "bin                                                               \n",
      "(-13.572, 767.288]       479.966969    460.802462  1920 -19.164507\n",
      "(767.288, 1143.73]       988.190281    972.225393  1920 -15.964888\n",
      "(1143.73, 1509.149]     1331.591286   1312.078026  1920 -19.513260\n",
      "(1509.149, 1809.44]     1693.329979   1672.495501  1920 -20.834479\n",
      "(1809.44, 2173.781]     1980.010083   1969.816649  1920 -10.193434\n",
      "(2173.781, 2716.859]    2445.573036   2437.976825  1920  -7.596212\n",
      "(2716.859, 3481.808]    3085.987286   3093.031781  1920   7.044494\n",
      "(3481.808, 5025.716]    4173.033953   4200.615854  1920  27.581901\n",
      "(5025.716, 9537.871]    6673.471510   6714.199294  1920  40.727783\n",
      "(9537.871, 26676.814]  13260.718646  13278.631247  1920  17.912601\n",
      "평균 절대 바이어스: 18.653355879694296\n",
      "\n",
      "[Top-10 by 건물번호]\n",
      " 건물번호\n",
      "10    1245.150180\n",
      "3      788.150837\n",
      "79     740.148135\n",
      "23     474.506869\n",
      "45     460.317408\n",
      "1      438.530124\n",
      "64     380.167810\n",
      "6      328.070494\n",
      "34     317.247930\n",
      "54     297.029990\n",
      "Name: se_blend, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3408295359.py:76: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3408295359.py:85: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5R. 잔차 학습 + (a,b) 블렌딩 + 하드 빌딩 가중치\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    y, yhat = np.asarray(y), np.asarray(yhat)\n",
    "    return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "# --- 검증 분할(재확인) ---\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# --- 피처 선택 (안전하게 reindex) ---\n",
    "features = get_feature_cols(train_part)  # 기존 함수 사용\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# --- 베이스라인 → 잔차 타깃 ---\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# --- 하드 빌딩 가중치 (Top-10 위주) ---\n",
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}  # 필요시 수정\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(HARD_BLD).values] = 1.8  # 1.5~2.0 사이 시도\n",
    "\n",
    "# --- LightGBM 학습 (보수적 규제) ---\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':64,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':120,'lambda_l2':2.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "\n",
    "model = lgb.train(\n",
    "    params, lgb_train, num_boost_round=5000,\n",
    "    valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    ")\n",
    "\n",
    "# --- (a,b) 블렌딩: y ≈ base + a*resid_pred + b ---\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "A = np.column_stack([pred_va_resid, np.ones_like(pred_va_resid)])\n",
    "a, b = np.linalg.lstsq(A, true_resid_va, rcond=None)[0]\n",
    "a = float(np.clip(a, 0.0, 1.5))   # 안정화\n",
    "b = float(b)\n",
    "\n",
    "pred_va = baseline_va.values + a * pred_va_resid + b\n",
    "\n",
    "print(f\"[Blending] a={a:.3f}, b={b:.3f}\")\n",
    "print(f\"[Baseline] RMSE={rmse(y_va, baseline_va):.3f}  MAE={mean_absolute_error(y_va, baseline_va):.3f}\")\n",
    "print(f\"[Blended ] RMSE={rmse(y_va, pred_va):.3f}  MAE={mean_absolute_error(y_va, pred_va):.3f}  R2={r2_score(y_va, pred_va):.4f}\")\n",
    "\n",
    "# --- 디사일 캘리브레이션 ---\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_va})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(\"\\n[Calibration by decile]\\n\", cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())\n",
    "\n",
    "# --- Top-10 by 건물번호 (블렌딩 기준) ---\n",
    "va_err = valid_part[['건물번호']].copy()\n",
    "va_err['se_blend'] = (y_va.values - pred_va)**2\n",
    "print(\"\\n[Top-10 by 건물번호]\\n\",\n",
    "      va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "\n",
    "# 다음 단계에서 6R에서 재사용할 수 있게 보관\n",
    "AB_BLEND = (a, b)\n",
    "BEST_NUM_BOOST = int(model.best_iteration or 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c3e566a-5d70-49af-b8a0-2b9c7e16c45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제출 생략: DO_SUBMIT=False (모델만 재학습 완료)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6R. 최종 재학습 (a,b 블렌딩 적용)  *제출은 옵션*\n",
    "# =========================\n",
    "DO_SUBMIT = False  # ← 기본은 예측/저장 비활성화. 필요할 때만 True로.\n",
    "\n",
    "# all_feat이 이미 만들어져 있다면 재사용, 아니면 생성\n",
    "try:\n",
    "    _ = all_feat  # 존재 체크\n",
    "except NameError:\n",
    "    # test_orig/build_df/read_csv_smart/clean_capacity/ensure_datetime_cols 등이 준비되어 있어야 함\n",
    "    test_orig = read_csv_smart(TEST_PATH)\n",
    "    build_df  = read_csv_smart(BUILD_PATH)\n",
    "    test_df = pd.merge(test_orig, build_df, on='건물번호', how='left')\n",
    "    test_df = clean_capacity_fields(test_df)\n",
    "    test_df = ensure_datetime_cols(test_df)\n",
    "    all_df  = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    # (옵션) 일사/일조 백필을 썼다면 여기서 호출\n",
    "    # all_df = backfill_solar_by_time(all_df)\n",
    "    all_feat = make_features(all_df)\n",
    "\n",
    "all_feat_train = all_feat.iloc[:len(train_df)].copy()\n",
    "all_feat_test  = all_feat.iloc[len(train_df):].copy()\n",
    "\n",
    "features_full = get_feature_cols(all_feat_train)\n",
    "cat_cols_full = [c for c in ['건물번호','건물유형'] if c in features_full]\n",
    "for c in cat_cols_full:\n",
    "    all_feat_train[c] = all_feat_train[c].astype('category')\n",
    "    all_feat_test[c]  = all_feat_test[c].astype('category')\n",
    "\n",
    "X_full = all_feat_train.reindex(columns=features_full).replace([np.inf,-np.inf], np.nan)\n",
    "y_full = all_feat_train['전력소비량(kWh)']\n",
    "\n",
    "baseline_full = build_baseline(all_feat_train)\n",
    "baseline_te   = build_baseline(all_feat_test)\n",
    "\n",
    "y_full_resid = (y_full - baseline_full).astype(float)\n",
    "lgb_full = lgb.Dataset(X_full, label=y_full_resid, categorical_feature=cat_cols_full or None)\n",
    "\n",
    "# 검증에서 쓴 하이퍼파라미터/부스트 수 재사용\n",
    "params_full = params.copy()\n",
    "final_model = lgb.train(params_full, lgb_full, num_boost_round=BEST_NUM_BOOST)\n",
    "\n",
    "# 테스트 잔차 예측 + (a,b) 블렌딩 복원\n",
    "if DO_SUBMIT:\n",
    "    X_te = all_feat_test.reindex(columns=features_full).replace([np.inf,-np.inf], np.nan)\n",
    "    test_pred_resid = final_model.predict(X_te, num_iteration=final_model.best_iteration)\n",
    "    a_use, b_use = AB_BLEND if 'AB_BLEND' in globals() else (1.0, 0.0)\n",
    "    test_pred = baseline_te.values + a_use * test_pred_resid + b_use\n",
    "\n",
    "    sub = read_csv_smart(SAMPLE_SUB)\n",
    "    sub['answer'] = pd.Series(test_pred, index=sub.index)\n",
    "    sub.to_csv(OUT_SUB, index=False, encoding='utf-8-sig')\n",
    "    print(f\"저장 완료 → {OUT_SUB}\")\n",
    "else:\n",
    "    print(\"제출 생략: DO_SUBMIT=False (모델만 재학습 완료)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2234c4b-4125-425e-9fd4-ab2871c348de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 191.932\tvalid's rmse: 250.611\n",
      "[800]\ttrain's rmse: 158.815\tvalid's rmse: 239.59\n",
      "[1200]\ttrain's rmse: 140.375\tvalid's rmse: 234.776\n",
      "[1600]\ttrain's rmse: 127.489\tvalid's rmse: 232.896\n",
      "[2000]\ttrain's rmse: 117.524\tvalid's rmse: 232.333\n",
      "Early stopping, best iteration is:\n",
      "[2090]\ttrain's rmse: 115.572\tvalid's rmse: 231.904\n",
      "[Calibration] best=ISO  RMSE=222.850  MAE=109.444  R2=0.9967\n",
      "  - AB scores : RMSE=231.127, ISO : 222.850, ISO+BLD : 224.497\n",
      "  - gamma=- (ISO 객체 저장됨)\n",
      "\n",
      "[Calibration by decile]\n",
      "                              y_mean     yhat_mean     n       bias\n",
      "bin                                                               \n",
      "(-0.19, 773.573]         480.713370    468.545060  1920 -12.168310\n",
      "(773.573, 1150.179]      987.890062    977.938907  1920  -9.951155\n",
      "(1150.179, 1514.157]    1330.305422   1317.805263  1920 -12.500158\n",
      "(1514.157, 1813.01]     1695.009984   1676.481321  1920 -18.528663\n",
      "(1813.01, 2166.778]     1978.414776   1971.116705  1920  -7.298072\n",
      "(2166.778, 2716.93]     2446.801193   2438.128436  1920  -8.672757\n",
      "(2716.93, 3475.745]     3084.663719   3088.982605  1920   4.318886\n",
      "(3475.745, 5019.16]     4173.895224   4191.226796  1920  17.331572\n",
      "(5019.16, 9543.025]     6672.127302   6703.155317  1920  31.028015\n",
      "(9543.025, 26511.584]  13262.051979  13278.492620  1920  16.440641\n",
      "평균 절대 바이어스: 13.823822948397458\n",
      "\n",
      "[Top-10 by 건물번호]\n",
      " 건물번호\n",
      "10    1194.262170\n",
      "3      747.718111\n",
      "79     663.340683\n",
      "23     452.758038\n",
      "45     443.607067\n",
      "1      441.260521\n",
      "64     372.202845\n",
      "6      318.893252\n",
      "34     310.974561\n",
      "54     295.968165\n",
      "Name: se_blend, dtype: float64\n",
      "\n",
      "[Saved] CALIB_MODE, CALIB_PARAMS, BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3847393014.py:123: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3847393014.py:131: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5R. Residual + Hard-Building Weights + Calibration Selection\n",
    "# =========================\n",
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def RMSE(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "# 0) 피처 새로고침(위 셀에서 train_feat 이미 있으면 재사용)\n",
    "try:\n",
    "    _ = train_feat\n",
    "except NameError:\n",
    "    train_feat = make_features(train_df)\n",
    "\n",
    "# 1) 검증 분할\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# 2) 피처 선택 + 카테고리\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 3) 베이스라인 → 잔차 타깃\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# 4) 하드 빌딩 가중치 (필요시 수정)\n",
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(HARD_BLD).values] = 1.8  # 1.5~2.0 사이 튠\n",
    "\n",
    "# 5) LGB 학습(보수적 규제)\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':64,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':120,'lambda_l2':2.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "model = lgb.train(\n",
    "    params, lgb_train, num_boost_round=5000,\n",
    "    valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    ")\n",
    "\n",
    "# 6) 보정 후보 계산\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "# (A) 선형(a,b): y ≈ base + a*pred + b\n",
    "A = np.column_stack([pred_va_resid, np.ones_like(pred_va_resid)])\n",
    "a, b = np.linalg.lstsq(A, true_resid_va, rcond=None)[0]\n",
    "a = float(np.clip(a, 0.0, 1.5)); b = float(b)\n",
    "pred_ab = baseline_va.values + a * pred_va_resid + b\n",
    "sc_ab = (RMSE(y_va, pred_ab), mean_absolute_error(y_va, pred_ab), r2_score(y_va, pred_ab))\n",
    "\n",
    "# (B) Isotonic: y ≈ base + g(pred)\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(pred_va_resid, true_resid_va)\n",
    "pred_iso = baseline_va.values + iso.transform(pred_va_resid)\n",
    "sc_iso = (RMSE(y_va, pred_iso), mean_absolute_error(y_va, pred_iso), r2_score(y_va, pred_iso))\n",
    "\n",
    "# (B+) Isotonic + 빌딩 평균 잔차 보정(γ)\n",
    "# (B+) Isotonic + 빌딩 평균 잔차 보정(γ)\n",
    "gamma = 0.5  # 0.3~0.7 시도 가능\n",
    "\n",
    "train_resid = (y_tr - baseline_tr).values\n",
    "\n",
    "# 빌딩별 train 잔차 평균 (observed=False로 경고 제거)\n",
    "bld_bias_map = (\n",
    "    pd.Series(train_resid, index=train_part.index)\n",
    "      .groupby(train_part['건물번호'], observed=False)\n",
    "      .mean()\n",
    ")\n",
    "\n",
    "# 인덱스 타입 통일(int)\n",
    "if isinstance(getattr(bld_bias_map.index, 'dtype', None), pd.CategoricalDtype):\n",
    "    bld_bias_map.index = bld_bias_map.index.astype('int64')\n",
    "\n",
    "# valid 건물번호도 int로 변환 후 dict 매핑 → float → NaN을 0.0으로\n",
    "bld_bias_dict = bld_bias_map.to_dict()\n",
    "bld_codes_va = valid_part['건물번호'].astype('int64')\n",
    "bias_va = bld_codes_va.map(bld_bias_dict).astype('float64').fillna(0.0).to_numpy()\n",
    "\n",
    "pred_iso_bias = pred_iso + gamma * bias_va\n",
    "sc_iso_bias = (RMSE(y_va, pred_iso_bias), mean_absolute_error(y_va, pred_iso_bias), r2_score(y_va, pred_iso_bias))\n",
    "\n",
    "\n",
    "# 7) 베스트 보정 선택\n",
    "cands = {\n",
    "    \"AB\":        (pred_ab,       sc_ab,       {\"a\":a,\"b\":b}),\n",
    "    \"ISO\":       (pred_iso,      sc_iso,      {\"iso\":iso}),\n",
    "    \"ISO+BLD\":   (pred_iso_bias, sc_iso_bias, {\"iso\":iso,\"gamma\":gamma,\"bld_bias_map\":bld_bias_map}),\n",
    "}\n",
    "best_name, (pred_best, (rmse_best, mae_best, r2_best), params_best) = min(\n",
    "    cands.items(), key=lambda kv: kv[1][1][0]\n",
    ")\n",
    "\n",
    "print(f\"[Calibration] best={best_name}  RMSE={rmse_best:.3f}  MAE={mae_best:.3f}  R2={r2_best:.4f}\")\n",
    "print(f\"  - AB scores : RMSE={sc_ab[0]:.3f}, ISO : {sc_iso[0]:.3f}, ISO+BLD : {sc_iso_bias[0]:.3f}\")\n",
    "if best_name == \"AB\":\n",
    "    print(f\"  - a={params_best['a']:.3f}, b={params_best['b']:.3f}\")\n",
    "elif best_name.startswith(\"ISO\"):\n",
    "    print(f\"  - gamma={params_best.get('gamma','-')} (ISO 객체 저장됨)\")\n",
    "\n",
    "# 8) 디사일 캘리브레이션 & Top-10\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_best})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(\"\\n[Calibration by decile]\\n\", cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())\n",
    "\n",
    "va_err = valid_part[['건물번호']].copy()\n",
    "va_err['se_blend'] = (y_va.values - pred_best)**2\n",
    "print(\"\\n[Top-10 by 건물번호]\\n\",\n",
    "      va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "\n",
    "# 9) 6단계에서 재사용할 아티팩트 저장(전역)\n",
    "CALIB_MODE   = best_name\n",
    "CALIB_PARAMS = params_best\n",
    "BEST_NUM_BOOST = int(model.best_iteration or 2000)\n",
    "FEATURE_LIST = features\n",
    "CAT_COLS     = cat_cols\n",
    "LGBM_PARAMS  = params\n",
    "print(\"\\n[Saved] CALIB_MODE, CALIB_PARAMS, BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bf44040-c015-4b87-99cf-f5d5723478b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 205.222\tvalid's rmse: 252.457\n",
      "[800]\ttrain's rmse: 172.089\tvalid's rmse: 238.118\n",
      "[1200]\ttrain's rmse: 153.767\tvalid's rmse: 233.093\n",
      "[1600]\ttrain's rmse: 141.129\tvalid's rmse: 230.623\n",
      "[2000]\ttrain's rmse: 131.572\tvalid's rmse: 229.91\n",
      "[2400]\ttrain's rmse: 123.665\tvalid's rmse: 229.166\n",
      "[2800]\ttrain's rmse: 117.054\tvalid's rmse: 228.757\n",
      "Early stopping, best iteration is:\n",
      "[2774]\ttrain's rmse: 117.47\tvalid's rmse: 228.635\n",
      "[Calibration] best=ISO  RMSE=220.547  MAE=107.776  R2=0.9967\n",
      "  - AB scores : RMSE=228.022, ISO : 220.547, ISO+BLD : 222.327\n",
      "  - gamma=- (ISO 객체 저장됨)\n",
      "\n",
      "[Calibration by decile]\n",
      "                              y_mean     yhat_mean     n       bias\n",
      "bin                                                               \n",
      "(-4.404, 773.014]        480.723703    470.111125  1920 -10.612578\n",
      "(773.014, 1153.43]       987.781547    979.375712  1920  -8.405835\n",
      "(1153.43, 1516.8]       1330.462797   1320.860218  1920  -9.602579\n",
      "(1516.8, 1815.118]      1693.607271   1678.639426  1920 -14.967845\n",
      "(1815.118, 2170.767]    1979.965000   1973.989299  1920  -5.975701\n",
      "(2170.767, 2713.563]    2447.061458   2436.112233  1920 -10.949225\n",
      "(2713.563, 3478.424]    3084.082062   3086.689142  1920   2.607079\n",
      "(3478.424, 5018.672]    4175.044172   4182.674368  1920   7.630196\n",
      "(5018.672, 9534.887]    6675.039703   6693.286681  1920  18.246978\n",
      "(9534.887, 26580.532]  13258.105318  13290.134827  1920  32.029509\n",
      "평균 절대 바이어스: 12.102752481088379\n",
      "\n",
      "[Top-10 by 건물번호]\n",
      " 건물번호\n",
      "10    1175.601330\n",
      "79     700.496335\n",
      "3      688.151077\n",
      "45     487.309977\n",
      "1      442.831821\n",
      "23     425.293143\n",
      "64     367.301869\n",
      "6      319.888326\n",
      "34     305.715202\n",
      "54     305.611514\n",
      "Name: se_blend, dtype: float64\n",
      "\n",
      "[Saved] CALIB_MODE, CALIB_PARAMS, BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\353758683.py:123: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\353758683.py:131: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5R. Residual + Hard-Building Weights + Calibration Selection\n",
    "# =========================\n",
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def RMSE(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "# 0) 피처 새로고침(위 셀에서 train_feat 이미 있으면 재사용)\n",
    "try:\n",
    "    _ = train_feat\n",
    "except NameError:\n",
    "    train_feat = make_features(train_df)\n",
    "\n",
    "# 1) 검증 분할\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# 2) 피처 선택 + 카테고리\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 3) 베이스라인 → 잔차 타깃\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# 4) 하드 빌딩 가중치 (필요시 수정)\n",
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(HARD_BLD).values] = 1.8  # 1.5~2.0 사이 튠\n",
    "\n",
    "# 5) LGB 학습(보수적 규제)\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':48,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':150,'lambda_l2':3.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "model = lgb.train(\n",
    "    params, lgb_train, num_boost_round=5000,\n",
    "    valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    ")\n",
    "\n",
    "# 6) 보정 후보 계산\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "# (A) 선형(a,b): y ≈ base + a*pred + b\n",
    "A = np.column_stack([pred_va_resid, np.ones_like(pred_va_resid)])\n",
    "a, b = np.linalg.lstsq(A, true_resid_va, rcond=None)[0]\n",
    "a = float(np.clip(a, 0.0, 1.5)); b = float(b)\n",
    "pred_ab = baseline_va.values + a * pred_va_resid + b\n",
    "sc_ab = (RMSE(y_va, pred_ab), mean_absolute_error(y_va, pred_ab), r2_score(y_va, pred_ab))\n",
    "\n",
    "# (B) Isotonic: y ≈ base + g(pred)\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(pred_va_resid, true_resid_va)\n",
    "pred_iso = baseline_va.values + iso.transform(pred_va_resid)\n",
    "sc_iso = (RMSE(y_va, pred_iso), mean_absolute_error(y_va, pred_iso), r2_score(y_va, pred_iso))\n",
    "\n",
    "# (B+) Isotonic + 빌딩 평균 잔차 보정(γ)\n",
    "# (B+) Isotonic + 빌딩 평균 잔차 보정(γ)\n",
    "gamma = 0.5  # 0.3~0.7 시도 가능\n",
    "\n",
    "train_resid = (y_tr - baseline_tr).values\n",
    "\n",
    "# 빌딩별 train 잔차 평균 (observed=False로 경고 제거)\n",
    "bld_bias_map = (\n",
    "    pd.Series(train_resid, index=train_part.index)\n",
    "      .groupby(train_part['건물번호'], observed=False)\n",
    "      .mean()\n",
    ")\n",
    "\n",
    "# 인덱스 타입 통일(int)\n",
    "if isinstance(getattr(bld_bias_map.index, 'dtype', None), pd.CategoricalDtype):\n",
    "    bld_bias_map.index = bld_bias_map.index.astype('int64')\n",
    "\n",
    "# valid 건물번호도 int로 변환 후 dict 매핑 → float → NaN을 0.0으로\n",
    "bld_bias_dict = bld_bias_map.to_dict()\n",
    "bld_codes_va = valid_part['건물번호'].astype('int64')\n",
    "bias_va = bld_codes_va.map(bld_bias_dict).astype('float64').fillna(0.0).to_numpy()\n",
    "\n",
    "pred_iso_bias = pred_iso + gamma * bias_va\n",
    "sc_iso_bias = (RMSE(y_va, pred_iso_bias), mean_absolute_error(y_va, pred_iso_bias), r2_score(y_va, pred_iso_bias))\n",
    "\n",
    "\n",
    "# 7) 베스트 보정 선택\n",
    "cands = {\n",
    "    \"AB\":        (pred_ab,       sc_ab,       {\"a\":a,\"b\":b}),\n",
    "    \"ISO\":       (pred_iso,      sc_iso,      {\"iso\":iso}),\n",
    "    \"ISO+BLD\":   (pred_iso_bias, sc_iso_bias, {\"iso\":iso,\"gamma\":gamma,\"bld_bias_map\":bld_bias_map}),\n",
    "}\n",
    "best_name, (pred_best, (rmse_best, mae_best, r2_best), params_best) = min(\n",
    "    cands.items(), key=lambda kv: kv[1][1][0]\n",
    ")\n",
    "\n",
    "print(f\"[Calibration] best={best_name}  RMSE={rmse_best:.3f}  MAE={mae_best:.3f}  R2={r2_best:.4f}\")\n",
    "print(f\"  - AB scores : RMSE={sc_ab[0]:.3f}, ISO : {sc_iso[0]:.3f}, ISO+BLD : {sc_iso_bias[0]:.3f}\")\n",
    "if best_name == \"AB\":\n",
    "    print(f\"  - a={params_best['a']:.3f}, b={params_best['b']:.3f}\")\n",
    "elif best_name.startswith(\"ISO\"):\n",
    "    print(f\"  - gamma={params_best.get('gamma','-')} (ISO 객체 저장됨)\")\n",
    "\n",
    "# 8) 디사일 캘리브레이션 & Top-10\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_best})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(\"\\n[Calibration by decile]\\n\", cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())\n",
    "\n",
    "va_err = valid_part[['건물번호']].copy()\n",
    "va_err['se_blend'] = (y_va.values - pred_best)**2\n",
    "print(\"\\n[Top-10 by 건물번호]\\n\",\n",
    "      va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10))\n",
    "\n",
    "# 9) 6단계에서 재사용할 아티팩트 저장(전역)\n",
    "CALIB_MODE   = best_name\n",
    "CALIB_PARAMS = params_best\n",
    "BEST_NUM_BOOST = int(model.best_iteration or 2000)\n",
    "FEATURE_LIST = features\n",
    "CAT_COLS     = cat_cols\n",
    "LGBM_PARAMS  = params\n",
    "print(\"\\n[Saved] CALIB_MODE, CALIB_PARAMS, BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39d2bf5e-fd6c-4b7d-9a52-df246aec6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3594476892.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cols = [c for c in cols if is_numeric_dtype(df[c]) or is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[400]\ttrain's rmse: 205.222\tvalid's rmse: 252.457\n",
      "[800]\ttrain's rmse: 172.089\tvalid's rmse: 238.118\n",
      "[1200]\ttrain's rmse: 153.767\tvalid's rmse: 233.093\n",
      "[1600]\ttrain's rmse: 141.129\tvalid's rmse: 230.623\n",
      "[2000]\ttrain's rmse: 131.572\tvalid's rmse: 229.91\n",
      "[2400]\ttrain's rmse: 123.665\tvalid's rmse: 229.166\n",
      "[2800]\ttrain's rmse: 117.054\tvalid's rmse: 228.757\n",
      "Early stopping, best iteration is:\n",
      "[2774]\ttrain's rmse: 117.47\tvalid's rmse: 228.635\n",
      "[Calibration] forced=ISO  RMSE=220.547  MAE=107.776  R2=0.9967\n",
      "  - AB RMSE=228.022 | ISO RMSE=220.547\n",
      "\n",
      "[Calibration by decile]\n",
      "                              y_mean     yhat_mean     n       bias\n",
      "bin                                                               \n",
      "(-4.404, 773.014]        480.723703    470.111125  1920 -10.612578\n",
      "(773.014, 1153.43]       987.781547    979.375712  1920  -8.405835\n",
      "(1153.43, 1516.8]       1330.462797   1320.860218  1920  -9.602579\n",
      "(1516.8, 1815.118]      1693.607271   1678.639426  1920 -14.967845\n",
      "(1815.118, 2170.767]    1979.965000   1973.989299  1920  -5.975701\n",
      "(2170.767, 2713.563]    2447.061458   2436.112233  1920 -10.949225\n",
      "(2713.563, 3478.424]    3084.082062   3086.689142  1920   2.607079\n",
      "(3478.424, 5018.672]    4175.044172   4182.674368  1920   7.630196\n",
      "(5018.672, 9534.887]    6675.039703   6693.286681  1920  18.246978\n",
      "(9534.887, 26580.532]  13258.105318  13290.134827  1920  32.029509\n",
      "평균 절대 바이어스: 12.102752481088379\n",
      "\n",
      "[Top-10 by 건물번호]\n",
      " 건물번호\n",
      "10    1175.601330\n",
      "79     700.496335\n",
      "3      688.151077\n",
      "45     487.309977\n",
      "1      442.831821\n",
      "23     425.293143\n",
      "64     367.301869\n",
      "6      319.888326\n",
      "34     305.715202\n",
      "54     305.611514\n",
      "Name: se_blend, dtype: float64\n",
      "\n",
      "[Saved] CALIB_MODE=ISO (plain), BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3535248107.py:100: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7072\\3535248107.py:107: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  top10 = va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5R. Residual + Hard-Building Weights + Calibration Selection\n",
    "# =========================\n",
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def RMSE(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "# 0) 피처 새로고침(위 셀에서 train_feat 이미 있으면 재사용)\n",
    "try:\n",
    "    _ = train_feat\n",
    "except NameError:\n",
    "    train_feat = make_features(train_df)\n",
    "\n",
    "# 1) 검증 분할\n",
    "VAL_START = pd.Timestamp(2024,8,17,0)\n",
    "VAL_END   = pd.Timestamp(2024,8,24,23)\n",
    "is_val = (train_feat['dt'] >= VAL_START) & (train_feat['dt'] <= VAL_END)\n",
    "train_part = train_feat[~is_val].copy()\n",
    "valid_part = train_feat[ is_val].copy()\n",
    "\n",
    "# 2) 피처 선택 + 카테고리\n",
    "features = get_feature_cols(train_part)\n",
    "cat_cols = [c for c in ['건물번호','건물유형'] if c in features]\n",
    "for c in cat_cols:\n",
    "    train_part[c] = train_part[c].astype('category')\n",
    "    valid_part[c] = valid_part[c].astype('category')\n",
    "\n",
    "X_tr = train_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "X_va = valid_part.reindex(columns=features).replace([np.inf,-np.inf], np.nan)\n",
    "y_tr = train_part['전력소비량(kWh)']\n",
    "y_va = valid_part['전력소비량(kWh)']\n",
    "\n",
    "# 3) 베이스라인 → 잔차 타깃\n",
    "baseline_tr = build_baseline(train_part)\n",
    "baseline_va = build_baseline(valid_part)\n",
    "y_tr_resid = (y_tr - baseline_tr).astype(float)\n",
    "y_va_resid = (y_va - baseline_va).astype(float)\n",
    "\n",
    "# 4) 하드 빌딩 가중치 (필요시 수정)\n",
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}\n",
    "w_tr = np.ones(len(train_part), dtype=float)\n",
    "w_tr[train_part['건물번호'].isin(HARD_BLD).values] = 1.8  # 1.5~2.0 사이 튠\n",
    "\n",
    "# 5) LGB 학습(보수적 규제)\n",
    "params = {\n",
    "    'objective':'regression','metric':'rmse','learning_rate':0.05,\n",
    "    'num_leaves':48,'feature_fraction':0.85,'bagging_fraction':0.85,'bagging_freq':1,\n",
    "    'min_data_in_leaf':150,'lambda_l2':3.0,'seed':42,'verbosity':-1,'num_threads':4\n",
    "}\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr_resid, weight=w_tr, categorical_feature=cat_cols or None)\n",
    "lgb_valid = lgb.Dataset(X_va, label=y_va_resid, categorical_feature=cat_cols or None)\n",
    "model = lgb.train(\n",
    "    params, lgb_train, num_boost_round=5000,\n",
    "    valid_sets=[lgb_train,lgb_valid], valid_names=['train','valid'],\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(400)]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 6)~9) 보정/선택/리포트 (롤백/고정 버전)\n",
    "# =========================\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def RMSE(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "# --- (옵션) 하드 빌딩 가중치 '고정'\n",
    "HARD_BLD = {10,79,3,45,23,1,12,69,64,34}  # 이전에 잘 나왔던 셋으로 고정\n",
    "# w_tr은 위 학습 셀에서 이미 이 셋 기준으로 적용된 상태면 그대로 두면 됨\n",
    "\n",
    "pred_va_resid = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "true_resid_va = (y_va - baseline_va).values\n",
    "\n",
    "# (A) 선형 보정: y ≈ base + a*pred + b  (참고용)\n",
    "A = np.column_stack([pred_va_resid, np.ones_like(pred_va_resid)])\n",
    "a, b = np.linalg.lstsq(A, true_resid_va, rcond=None)[0]\n",
    "a = float(np.clip(a, 0.0, 1.5)); b = float(b)\n",
    "pred_ab = baseline_va.values + a * pred_va_resid + b\n",
    "sc_ab = (RMSE(y_va, pred_ab), mean_absolute_error(y_va, pred_ab), r2_score(y_va, pred_ab))\n",
    "\n",
    "# (B) ISO(플레인): 잔차 그대로로 적합(클리핑/바이어스 보정 없음)\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(pred_va_resid, true_resid_va)\n",
    "pred_iso = baseline_va.values + iso.transform(pred_va_resid)\n",
    "sc_iso = (RMSE(y_va, pred_iso), mean_absolute_error(y_va, pred_iso), r2_score(y_va, pred_iso))\n",
    "\n",
    "# --- 강제 선택: ISO(플레인)\n",
    "best_name = \"ISO\"\n",
    "pred_best = pred_iso\n",
    "rmse_best, mae_best, r2_best = sc_iso\n",
    "params_best = {\"iso\": iso}\n",
    "\n",
    "print(f\"[Calibration] forced={best_name}  RMSE={rmse_best:.3f}  MAE={mae_best:.3f}  R2={r2_best:.4f}\")\n",
    "print(f\"  - AB RMSE={sc_ab[0]:.3f} | ISO RMSE={sc_iso[0]:.3f}\")\n",
    "\n",
    "# --- 디사일 캘리브레이션 & Top-10\n",
    "df_cal = pd.DataFrame({\"y\": y_va.values, \"yhat\": pred_best})\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"yhat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\"), n=(\"y\",\"size\"))\n",
    "cal[\"bias\"] = cal[\"yhat_mean\"] - cal[\"y_mean\"]\n",
    "print(\"\\n[Calibration by decile]\\n\", cal)\n",
    "print(\"평균 절대 바이어스:\", cal[\"bias\"].abs().mean())\n",
    "\n",
    "va_err = valid_part[['건물번호']].copy()\n",
    "va_err['se_blend'] = (y_va.values - pred_best)**2\n",
    "top10 = va_err.groupby('건물번호')['se_blend'].mean().pow(0.5).sort_values(ascending=False).head(10)\n",
    "print(\"\\n[Top-10 by 건물번호]\\n\", top10)\n",
    "\n",
    "# --- 다음 런용 HARD_BLD '자동 갱신 끄기' (그대로 유지)\n",
    "# (아무 것도 갱신하지 않음)\n",
    "\n",
    "# --- 6R용 아티팩트 저장\n",
    "CALIB_MODE     = best_name\n",
    "CALIB_PARAMS   = params_best\n",
    "BEST_NUM_BOOST = int(model.best_iteration or 2000)\n",
    "FEATURE_LIST   = features\n",
    "CAT_COLS       = cat_cols\n",
    "LGBM_PARAMS    = params\n",
    "print(\"\\n[Saved] CALIB_MODE=ISO (plain), BEST_NUM_BOOST, FEATURE_LIST, CAT_COLS, LGBM_PARAMS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53dbb37c-46b7-455b-b16d-81df6c18de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features (train/test): 48 / 48\n",
      "저장 완료 → C:\\Users\\user\\Downloads\\open (1)\\baseline_lgbm_submission.csv  (rows=16800)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6R. Full Retrain & Submit (feature alignment fix)\n",
    "# =========================\n",
    "DO_SUBMIT = True  # 필요시 False\n",
    "\n",
    "# 0) all_feat 준비(있으면 재사용)\n",
    "try:\n",
    "    _ = all_feat\n",
    "except NameError:\n",
    "    test_orig = read_csv_smart(TEST_PATH)\n",
    "    build_df  = read_csv_smart(BUILD_PATH)\n",
    "    test_df = pd.merge(test_orig, build_df, on='건물번호', how='left')\n",
    "    test_df = clean_capacity_fields(test_df)\n",
    "    test_df = ensure_datetime_cols(test_df)\n",
    "    all_df  = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    all_feat = make_features(all_df)\n",
    "\n",
    "all_feat_train = all_feat.iloc[:len(train_df)].copy()\n",
    "all_feat_test  = all_feat.iloc[len(train_df):].copy()\n",
    "\n",
    "# === 핵심: 5R에서 저장한 FEATURE_LIST/CAT_COLS를 반드시 사용 ===\n",
    "# (혹시 변수 없으면 5R의 model에서 가져오고 교집합만 사용)\n",
    "if 'FEATURE_LIST' not in globals():\n",
    "    FEATURE_LIST = list(model.feature_name())\n",
    "if 'CAT_COLS' not in globals():\n",
    "    CAT_COLS = [c for c in ['건물번호','건물유형'] if c in FEATURE_LIST]\n",
    "\n",
    "# 안전: train/test에 없는 컬럼 제거 (교집합 유지)\n",
    "common_feats = [c for c in FEATURE_LIST if c in all_feat_train.columns and c in all_feat_test.columns]\n",
    "if len(common_feats) != len(FEATURE_LIST):\n",
    "    missing = set(FEATURE_LIST) - set(common_feats)\n",
    "    print(\"⚠️ 다음 피처가 test/train에 없어 제외됨:\", sorted(list(missing)))\n",
    "FEATURE_LIST = common_feats\n",
    "CAT_COLS = [c for c in CAT_COLS if c in FEATURE_LIST]\n",
    "\n",
    "# 정렬/결측 처리 유틸\n",
    "def align_for_lgb(df_train, df_test, feature_list, cat_cols):\n",
    "    X_tr = df_train.reindex(columns=feature_list)\n",
    "    X_te = df_test.reindex(columns=feature_list)\n",
    "\n",
    "    # 카테고리 먼저 맞춰주기\n",
    "    for c in (cat_cols or []):\n",
    "        X_tr[c] = X_tr[c].astype('category')\n",
    "        X_te[c] = X_te[c].astype('category')\n",
    "        cats = X_tr[c].cat.categories\n",
    "        X_te[c] = X_te[c].cat.set_categories(cats)\n",
    "\n",
    "    # 수치 컬럼 결측/inf 처리\n",
    "    num_cols = [c for c in feature_list if c not in (cat_cols or [])]\n",
    "    X_tr[num_cols] = (X_tr[num_cols]\n",
    "                      .replace([np.inf, -np.inf], np.nan)\n",
    "                      .astype(float)\n",
    "                      .fillna(0.0))\n",
    "    X_te[num_cols] = (X_te[num_cols]\n",
    "                      .replace([np.inf, -np.inf], np.nan)\n",
    "                      .astype(float)\n",
    "                      .fillna(0.0))\n",
    "    return X_tr, X_te\n",
    "\n",
    "# 1) 정렬된 학습/예측 행렬 만들기\n",
    "features_full = FEATURE_LIST\n",
    "cat_cols_full = CAT_COLS\n",
    "X_full, X_te = align_for_lgb(all_feat_train, all_feat_test, features_full, cat_cols_full)\n",
    "\n",
    "# 안전 체크\n",
    "assert list(X_full.columns) == list(X_te.columns), \"train/test 피처 순서 불일치\"\n",
    "print(f\"n_features (train/test): {X_full.shape[1]} / {X_te.shape[1]}\")\n",
    "\n",
    "# 2) 전체 재학습(잔차 타깃)\n",
    "y_full = all_feat_train['전력소비량(kWh)']\n",
    "baseline_full = build_baseline(all_feat_train)\n",
    "baseline_te   = build_baseline(all_feat_test)\n",
    "\n",
    "w_full = np.ones(len(all_feat_train), dtype=float)\n",
    "try:\n",
    "    # 5R에서 썼던 HARD_BLD 그대로 있으면 재적용\n",
    "    w_full[all_feat_train['건물번호'].isin(HARD_BLD).values] = 1.8\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "lgb_full = lgb.Dataset(\n",
    "    X_full,\n",
    "    label=(y_full - baseline_full).astype(float),\n",
    "    weight=w_full,\n",
    "    categorical_feature=cat_cols_full or None\n",
    ")\n",
    "\n",
    "final_model = lgb.train(LGBM_PARAMS, lgb_full, num_boost_round=BEST_NUM_BOOST)\n",
    "\n",
    "# 3) 테스트 잔차 예측 + 5R에서 선택된 보정 적용\n",
    "resid_te = final_model.predict(X_te, num_iteration=final_model.best_iteration)\n",
    "\n",
    "if CALIB_MODE == \"ISO\":\n",
    "    iso = CALIB_PARAMS[\"iso\"]\n",
    "    test_pred = baseline_te.values + iso.transform(resid_te)\n",
    "elif CALIB_MODE == \"AB\":\n",
    "    a, b = CALIB_PARAMS[\"a\"], CALIB_PARAMS[\"b\"]\n",
    "    test_pred = baseline_te.values + a * resid_te + b\n",
    "elif CALIB_MODE == \"ISO+BLD\":\n",
    "    iso   = CALIB_PARAMS[\"iso\"]\n",
    "    gamma = CALIB_PARAMS[\"gamma\"]\n",
    "    bmap  = CALIB_PARAMS[\"bld_bias_map\"]\n",
    "    if isinstance(getattr(bmap.index, 'dtype', None), pd.CategoricalDtype):\n",
    "        bmap.index = bmap.index.astype('int64')\n",
    "    bias_te = all_feat_test['건물번호'].astype('int64').map(bmap.to_dict()).astype('float64').fillna(0.0).to_numpy()\n",
    "    test_pred = baseline_te.values + iso.transform(resid_te) + gamma * bias_te\n",
    "else:\n",
    "    test_pred = baseline_te.values + resid_te  # fallback\n",
    "\n",
    "# 안전 클램프\n",
    "test_pred = np.clip(test_pred, 0, None)\n",
    "\n",
    "if DO_SUBMIT:\n",
    "    sub = read_csv_smart(SAMPLE_SUB)\n",
    "    sub['answer'] = pd.Series(test_pred, index=sub.index)\n",
    "    sub.to_csv(OUT_SUB, index=False, encoding='utf-8-sig')\n",
    "    print(f\"저장 완료 → {OUT_SUB}  (rows={len(sub)})\")\n",
    "else:\n",
    "    print(\"제출 생략(DO_SUBMIT=False): 예측만 계산 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa1e6ccb-fbb4-41b8-a087-4b3bcbe7bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 저장: C:\\Users\\user\\Downloads\\open (1)\\merged_test.csv  rows=16800  cols=15\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# test 전처리: train과 '완전히 동일' 스키마/타입으로 맞추기\n",
    "#  - building_info 병합\n",
    "#  - 설비 용량 '-' → 0 (float)\n",
    "#  - '일시' → '날짜','시간','dt' 생성\n",
    "#  - 일사/일조 없으면 0.0 컬럼 추가\n",
    "#  - train(merged_train.csv)를 기준으로 컬럼/순서/카테고리 일치\n",
    "#  - 저장: merged_test.csv\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 경로\n",
    "TRAIN_MERGED_PATH = r\"C:\\Users\\user\\Downloads\\open (1)\\merged_train.csv\"  # 앞에서 저장한 train 전처리 결과\n",
    "TEST_PATH         = r\"C:\\Users\\user\\Downloads\\open (1)\\test.csv\"\n",
    "BUILD_PATH        = r\"C:\\Users\\user\\Downloads\\open (1)\\building_info.csv\"\n",
    "OUT_TEST_PATH     = r\"C:\\Users\\user\\Downloads\\open (1)\\merged_test.csv\"\n",
    "\n",
    "# ----- 유틸 -----\n",
    "def read_csv_smart(path, **kwargs):\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=kwargs.get('encoding', 'utf-8-sig'))\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding='cp949')\n",
    "\n",
    "def clean_capacity_fields(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c].replace('-', 0), errors='coerce').fillna(0.0).astype(float)\n",
    "    return df\n",
    "\n",
    "def ensure_datetime_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if '날짜' not in df.columns or '시간' not in df.columns:\n",
    "        if '일시' in df.columns:\n",
    "            s = df['일시'].astype(str)\n",
    "            df['날짜'] = pd.to_datetime(s.str.slice(0, 8), format='%Y%m%d')\n",
    "            df['시간'] = s.str.slice(9, 11).astype(int)\n",
    "        else:\n",
    "            raise ValueError(\"날짜/시간 정보가 없습니다. ('일시' 또는 '날짜','시간' 필요)\")\n",
    "    else:\n",
    "        df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "        df['시간'] = df['시간'].astype(int)\n",
    "    df['dt'] = df['날짜'] + pd.to_timedelta(df['시간'], unit='h')\n",
    "    return df\n",
    "\n",
    "# ----- 1) 기준(train 전처리 결과) 스키마 로드 -----\n",
    "train_ref = read_csv_smart(TRAIN_MERGED_PATH)\n",
    "# 카테고리 정보가 있으면 유지 (건물번호/건물유형은 우리가 카테고리로 저장했을 가능성 큼)\n",
    "for c in ['건물번호','건물유형']:\n",
    "    if c in train_ref.columns:\n",
    "        try:\n",
    "            train_ref[c] = train_ref[c].astype('category')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# ----- 2) test 로드 & train과 동일 전처리 -----\n",
    "test = read_csv_smart(TEST_PATH)\n",
    "build = read_csv_smart(BUILD_PATH)\n",
    "\n",
    "test_merged = pd.merge(test, build, on='건물번호', how='left')\n",
    "test_merged = clean_capacity_fields(test_merged)\n",
    "test_merged = ensure_datetime_cols(test_merged)\n",
    "\n",
    "# 일사/일조 없으면 0으로 생성(학습 일관성)\n",
    "if '일사(MJ/m2)' not in test_merged.columns:\n",
    "    test_merged['일사(MJ/m2)'] = 0.0\n",
    "if '일조(hr)' not in test_merged.columns:\n",
    "    test_merged['일조(hr)'] = 0.0\n",
    "\n",
    "# ----- 3) 컬럼/순서/타입을 train에 '맞춰서' 정렬 -----\n",
    "# target은 test에 없으므로 ref에서 제거\n",
    "ref_cols = [c for c in train_ref.columns if c != '전력소비량(kWh)']\n",
    "\n",
    "# ref에 있는데 test에 없는 컬럼은 dtype에 따라 기본값으로 생성\n",
    "for c in ref_cols:\n",
    "    if c not in test_merged.columns:\n",
    "        ref_dtype = train_ref[c].dtype\n",
    "        if np.issubdtype(ref_dtype, np.number):\n",
    "            test_merged[c] = 0.0\n",
    "        elif np.issubdtype(ref_dtype, np.datetime64):\n",
    "            test_merged[c] = pd.NaT\n",
    "        else:\n",
    "            test_merged[c] = pd.Series([pd.NA]*len(test_merged), dtype=\"object\")\n",
    "\n",
    "# 반대로, test에만 있는 컬럼은 그대로 두되 저장/모델링 때는 ref_cols 순서만 사용\n",
    "# 카테고리 일치(라벨 매칭)\n",
    "for c in ['건물번호','건물유형']:\n",
    "    if c in ref_cols and c in test_merged.columns:\n",
    "        # train_ref 쪽 카테고리 있으면 세팅\n",
    "        if str(train_ref[c].dtype) == 'category':\n",
    "            cats = train_ref[c].astype('category').cat.categories\n",
    "            test_merged[c] = test_merged[c].astype('category').cat.set_categories(cats)\n",
    "        else:\n",
    "            # 아닌 경우에도 최소한 dtype 통일\n",
    "            test_merged[c] = test_merged[c].astype(train_ref[c].dtype)\n",
    "\n",
    "# 최종 컬럼 순서 train 기준으로 정렬\n",
    "test_aligned = test_merged.reindex(columns=ref_cols)\n",
    "\n",
    "# ----- 4) 저장 -----\n",
    "test_aligned.to_csv(OUT_TEST_PATH, index=False, encoding='utf-8-sig')\n",
    "print(f\"[OK] 저장: {OUT_TEST_PATH}  rows={len(test_aligned)}  cols={len(test_aligned.columns)}\")\n",
    "# (선택) sanity check\n",
    "missing_after = [c for c in ref_cols if c not in test_aligned.columns]\n",
    "if missing_after:\n",
    "    print(\"⚠️ 아직 없는 컬럼:\", missing_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf04ec99-1c9d-4bfd-a3a2-bd9fb06fe48b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# --- 2) train+test 합쳐 동일 피처 생성 ---\u001b[39;00m\n\u001b[32m     52\u001b[39m all_df   = pd.concat([train_df, test_df], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m all_feat = \u001b[43mmake_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_df\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 이제 .dt 접근 OK\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# --- 3) 피처 목록: 5R에서 저장한 FEATURE_LIST 우선, 없으면 생성 ---\u001b[39;00m\n\u001b[32m     56\u001b[39m EXCLUDE = {\u001b[33m'\u001b[39m\u001b[33m전력소비량(kWh)\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdt\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m날짜\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m시간\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m일시\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mnum_date_time\u001b[39m\u001b[33m'\u001b[39m}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mmake_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     42\u001b[39m kr_holidays = {pd.Timestamp(\u001b[32m2024\u001b[39m,\u001b[32m6\u001b[39m,\u001b[32m6\u001b[39m), pd.Timestamp(\u001b[32m2024\u001b[39m,\u001b[32m8\u001b[39m,\u001b[32m15\u001b[39m)}\n\u001b[32m     43\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mis_holiday\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33m날짜\u001b[39m\u001b[33m'\u001b[39m].isin(kr_holidays).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mhas_pv\u001b[39m\u001b[33m'\u001b[39m]  = (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m태양광용량(kW)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     46\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mhas_ess\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mESS저장용량(kWh)\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     47\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mhas_pcs\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mPCS용량(kW)\u001b[39m\u001b[33m'\u001b[39m]    > \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[39m, in \u001b[36mOpsMixin.__gt__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:129\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    127\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mops.pyx:107\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_compare\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Test 예측 (train과 동일 파이프라인, num_date_time 제외, factor 처리)\n",
    "# =========================================\n",
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "\n",
    "# --- 경로 (필요시 수정) ---\n",
    "TRAIN_MERGED_PATH = r\"C:\\Users\\user\\Downloads\\open (1)\\merged_train.csv\"\n",
    "TEST_PATH         = r\"C:\\Users\\user\\Downloads\\open (1)\\merged_test.csv\"\n",
    "BUILD_PATH        = r\"C:\\Users\\user\\Downloads\\open (1)\\building_info.csv\"\n",
    "SAMPLE_SUB        = r\"C:\\Users\\user\\Downloads\\open (1)\\sample_submission.csv\"\n",
    "OUT_SUB           = r\"C:\\Users\\user\\Downloads\\open (1)\\submission.csv\"\n",
    "\n",
    "# --- 유틸 ---\n",
    "def read_csv_smart(path, **kwargs):\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=kwargs.get('encoding', 'utf-8-sig'))\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding='cp949')\n",
    "\n",
    "def align_for_lgb(df_tr, df_te, feature_list, cat_cols):\n",
    "    \"\"\"train/test를 같은 컬럼·순서·dtype으로 정렬\"\"\"\n",
    "    X_tr = df_tr.reindex(columns=feature_list).copy()\n",
    "    X_te = df_te.reindex(columns=feature_list).copy()\n",
    "    # 카테고리 맞춤\n",
    "    for c in (cat_cols or []):\n",
    "        X_tr[c] = X_tr[c].astype('category')\n",
    "        X_te[c] = X_te[c].astype('category').cat.set_categories(X_tr[c].cat.categories)\n",
    "    # 수치 결측/inf 처리\n",
    "    num_cols = [c for c in feature_list if c not in (cat_cols or [])]\n",
    "    X_tr[num_cols] = (X_tr[num_cols].replace([np.inf, -np.inf], np.nan).astype(float).fillna(0.0))\n",
    "    X_te[num_cols] = (X_te[num_cols].replace([np.inf, -np.inf], np.nan).astype(float).fillna(0.0))\n",
    "    return X_tr, X_te\n",
    "\n",
    "# --- 0) 데이터 로드 (train 전처리 결과 + test 전처리본) ---\n",
    "train_df = read_csv_smart(TRAIN_MERGED_PATH)\n",
    "test_raw = read_csv_smart(TEST_PATH)   # merged_test.csv (이미 병합된 파일)\n",
    "\n",
    "# ✅ 둘 다 날짜/시간/dt를 '확실히' datetime으로 보정\n",
    "train_df = ensure_datetime_cols(train_df)\n",
    "test_df  = test_raw.copy()\n",
    "test_df  = clean_capacity_fields(test_df)\n",
    "test_df  = ensure_datetime_cols(test_df)\n",
    "\n",
    "# (강화 가드: dt가 여전히 object면 한 번 더 강제 변환)\n",
    "for df_ in (train_df, test_df):\n",
    "    if 'dt' in df_.columns and not np.issubdtype(df_['dt'].dtype, np.datetime64):\n",
    "        df_['날짜'] = pd.to_datetime(df_['날짜'])\n",
    "        df_['시간'] = df_['시간'].astype(int)\n",
    "        df_['dt']  = df_['날짜'] + pd.to_timedelta(df_['시간'], unit='h')\n",
    "\n",
    "# --- 2) train+test 합쳐 동일 피처 생성 ---\n",
    "all_df   = pd.concat([train_df, test_df], ignore_index=True)\n",
    "all_feat = make_features(all_df)  # 이제 .dt 접근 OK\n",
    "\n",
    "# --- 3) 피처 목록: 5R에서 저장한 FEATURE_LIST 우선, 없으면 생성 ---\n",
    "EXCLUDE = {'전력소비량(kWh)','dt','날짜','시간','일시','num_date_time'}\n",
    "if 'FEATURE_LIST' not in globals():\n",
    "    from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "    FEATURE_LIST = [c for c in all_feat_train.columns if c not in EXCLUDE\n",
    "                    and (is_numeric_dtype(all_feat_train[c]) or str(all_feat_train[c].dtype)=='category')]\n",
    "else:\n",
    "    # num_date_time 등 제외 보장\n",
    "    FEATURE_LIST = [c for c in FEATURE_LIST if c not in EXCLUDE]\n",
    "\n",
    "# 카테고리 지정(요구: 건물번호/건물유형 factor)\n",
    "if 'CAT_COLS' not in globals():\n",
    "    CAT_COLS = [c for c in ['건물번호','건물유형'] if c in FEATURE_LIST]\n",
    "else:\n",
    "    CAT_COLS = [c for c in CAT_COLS if c in FEATURE_LIST]\n",
    "\n",
    "# 공통 피처만 사용 (학습/예측 모두 존재)\n",
    "common_feats = [c for c in FEATURE_LIST if c in all_feat_train.columns and c in all_feat_test.columns]\n",
    "if len(common_feats) != len(FEATURE_LIST):\n",
    "    removed = sorted(set(FEATURE_LIST) - set(common_feats))\n",
    "    print(\"⚠️ 제외된 피처:\", removed)\n",
    "FEATURE_LIST = common_feats\n",
    "CAT_COLS     = [c for c in CAT_COLS if c in FEATURE_LIST]\n",
    "\n",
    "# --- 4) 행렬 정렬 & 카테고리(factor) 일치 ---\n",
    "X_full, X_te = align_for_lgb(all_feat_train, all_feat_test, FEATURE_LIST, CAT_COLS)\n",
    "y_full = all_feat_train['전력소비량(kWh)']\n",
    "\n",
    "# --- 5) 베이스라인 계산 (train/test)\n",
    "baseline_full = build_baseline(all_feat_train)\n",
    "baseline_te   = build_baseline(all_feat_test)\n",
    "\n",
    "# --- 6) 전체 재학습(잔차 타깃) ---\n",
    "# 5R에서 저장한 파라미터/반복수 우선 사용, 없으면 안전 기본값\n",
    "if 'LGBM_PARAMS' not in globals():\n",
    "    LGBM_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 48,          # ← 64 → 48\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 150,   # ← 120 → 150\n",
    "    'lambda_l2': 3.0,          # ← 2.0 → 3.0\n",
    "    'seed': 42,\n",
    "    'verbosity': -1,\n",
    "    'num_threads': 4\n",
    "}\n",
    "    # 5R에서 사용할 params도 이걸 그대로 참조하게\n",
    "params = LGBM_PARAMS.copy()\n",
    "\n",
    "print(\"[LGBM PARAMS in use]\")\n",
    "for k, v in LGBM_PARAMS.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "    \n",
    "if 'BEST_NUM_BOOST' not in globals():\n",
    "    BEST_NUM_BOOST = 2000\n",
    "\n",
    "# 하드 빌딩 가중치(있으면 적용)\n",
    "w_full = np.ones(len(all_feat_train), dtype=float)\n",
    "if 'HARD_BLD' in globals():\n",
    "    w_full[all_feat_train['건물번호'].isin(HARD_BLD).values] = 1.8\n",
    "\n",
    "lgb_full = lgb.Dataset(\n",
    "    X_full,\n",
    "    label=(y_full - baseline_full).astype(float),\n",
    "    weight=w_full,\n",
    "    categorical_feature=CAT_COLS or None\n",
    ")\n",
    "final_model = lgb.train(LGBM_PARAMS, lgb_full, num_boost_round=BEST_NUM_BOOST)\n",
    "\n",
    "# --- 7) 테스트 잔차 예측 + 5R 보정 적용 (ISO / AB / ISO+BLD) ---\n",
    "resid_te = final_model.predict(X_te, num_iteration=final_model.best_iteration)\n",
    "\n",
    "if 'CALIB_MODE' in globals() and CALIB_MODE == \"ISO\":\n",
    "    iso = CALIB_PARAMS[\"iso\"]\n",
    "    test_pred = baseline_te.values + iso.transform(resid_te)\n",
    "elif 'CALIB_MODE' in globals() and CALIB_MODE == \"AB\":\n",
    "    a, b = CALIB_PARAMS[\"a\"], CALIB_PARAMS[\"b\"]\n",
    "    test_pred = baseline_te.values + a * resid_te + b\n",
    "elif 'CALIB_MODE' in globals() and CALIB_MODE == \"ISO+BLD\":\n",
    "    iso   = CALIB_PARAMS[\"iso\"]\n",
    "    gamma = CALIB_PARAMS[\"gamma\"]\n",
    "    bmap  = CALIB_PARAMS[\"bld_bias_map\"]\n",
    "    # 빌딩 바이어스 매핑\n",
    "    try:\n",
    "        from pandas.api.types import CategoricalDtype\n",
    "        if isinstance(getattr(bmap.index, 'dtype', None), CategoricalDtype):\n",
    "            bmap.index = bmap.index.astype('int64')\n",
    "    except Exception:\n",
    "        pass\n",
    "    bias_te = all_feat_test['건물번호'].astype('int64').map(bmap.to_dict()).astype('float64').fillna(0.0).to_numpy()\n",
    "    test_pred = baseline_te.values + iso.transform(resid_te) + gamma * bias_te\n",
    "else:\n",
    "    # 보정 정보 없으면 기본 복원\n",
    "    test_pred = baseline_te.values + resid_te\n",
    "\n",
    "# 음수 방지\n",
    "test_pred = np.clip(test_pred, 0, None)\n",
    "\n",
    "# --- 8) 저장 (num_date_time은 제출을 위한 ID로만 사용; 피처에는 미사용) ---\n",
    "sub = read_csv_smart(SAMPLE_SUB)\n",
    "sub['answer'] = pd.Series(test_pred, index=sub.index)\n",
    "sub.to_csv(OUT_SUB, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"[DONE] 예측 저장 → {OUT_SUB}\")\n",
    "print(\"n_features(train/test):\", X_full.shape[1], \"/\", X_te.shape[1])\n",
    "print(\"neg_rate:\", float((test_pred < 0).mean()), \" nan_rate:\", float(np.isnan(test_pred).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9dc01-00ea-4833-98cc-cf8e7aaef0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b1a1c39-bbed-407d-b297-539f6856ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:19: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "CFG = dict(\n",
    "    id_col=\"건물번호\",\n",
    "    time_col=\"timestamp\",\n",
    "    y_col=\"전력소비량(kWh)\",\n",
    "    lags=[1,2,3,24,48,168],\n",
    "    roll_mean=[3,6,12,24,168],\n",
    "    roll_std=[24,168],\n",
    ")\n",
    "\n",
    "def add_calendar_feats(df, time_col):\n",
    "    t = pd.to_datetime(df[time_col])\n",
    "    df[\"hour\"] = t.dt.hour\n",
    "    df[\"dow\"] = t.dt.dayofweek\n",
    "    df[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(int)\n",
    "    df[\"month\"] = t.dt.month\n",
    "    return df\n",
    "\n",
    "def build_features_train(df, cfg=CFG):\n",
    "    df = df.sort_values([cfg[\"id_col\"], cfg[\"time_col\"]]).copy()\n",
    "    df = add_calendar_feats(df, cfg[\"time_col\"])\n",
    "    # 그룹별 시계열 피처\n",
    "    def _per_group(g):\n",
    "        y = g[cfg[\"y_col\"]]\n",
    "        # lag\n",
    "        for L in cfg[\"lags\"]:\n",
    "            g[f\"lag_{L}\"] = y.shift(L)\n",
    "        # rolling (shift 후)\n",
    "        y_prev = y.shift(1)\n",
    "        for w in cfg[\"roll_mean\"]:\n",
    "            g[f\"rmean_{w}\"] = y_prev.rolling(w, min_periods=1).mean()\n",
    "        for w in cfg[\"roll_std\"]:\n",
    "            g[f\"rstd_{w}\"] = y_prev.rolling(w, min_periods=1).std()\n",
    "        # diff\n",
    "        g[\"diff_1\"] = y.diff(1)\n",
    "        g[\"diff_24\"] = y.diff(24)\n",
    "        return g\n",
    "    df = df.groupby(cfg[\"id_col\"], group_keys=False).apply(_per_group)\n",
    "    # 학습 행 필터: lag/rolling로 인해 NaN 생긴 초반부 제거\n",
    "    feat_cols = [c for c in df.columns if c not in [cfg[\"y_col\"]]]\n",
    "    X = df.dropna(subset=[f\"lag_{max(cfg['lags'])}\"])[feat_cols]\n",
    "    y = df.loc[X.index, cfg[\"y_col\"]]\n",
    "    return X, y, feat_cols\n",
    "\n",
    "def make_cv_splits(df, n_splits=5):\n",
    "    \"\"\"\n",
    "    df는 전체 학습 df (정렬된 상태 가정).\n",
    "    시간 순서만 고려한 단순 TSSplit. (건물별 누수는 위에서 피처 생성시 방지됨)\n",
    "    \"\"\"\n",
    "    tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "    idx = np.arange(len(df))\n",
    "    return list(tss.split(idx))\n",
    "\n",
    "def train_hgb(X, y):\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        loss=\"squared_error\",  # 타깃이 항상 양수면 \"poisson\"도 실험해봐\n",
    "        learning_rate=0.06,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=31,\n",
    "        min_samples_leaf=25,\n",
    "        max_bins=255,\n",
    "        l2_regularization=0.0,\n",
    "        early_stopping=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def predict_autoreg(test_df, model, hist_df, cfg=CFG):\n",
    "    \"\"\"\n",
    "    test_df: 예측할 구간 (id, timestamp만 있어도 됨 + 외생변수)\n",
    "    hist_df: test 시작 직전까지의 '학습 구간 원본'(target 포함). 여기서 버퍼 초기화\n",
    "    \"\"\"\n",
    "    feat_cols = None\n",
    "    out = []\n",
    "    for bid, te in test_df.sort_values([cfg[\"id_col\"], cfg[\"time_col\"]]).groupby(cfg[\"id_col\"]):\n",
    "        hist = hist_df[hist_df[cfg[\"id_col\"]] == bid].sort_values(cfg[\"time_col\"]).copy()\n",
    "        te = te.sort_values(cfg[\"time_col\"]).copy()\n",
    "        # 버퍼: hist + te(예측 채워넣기용)\n",
    "        buf = pd.concat([hist, te], ignore_index=True)\n",
    "        buf = add_calendar_feats(buf, cfg[\"time_col\"])\n",
    "        for i, row in te.iterrows():\n",
    "            # 현재 시점 인덱스\n",
    "            t_idx = buf.index[ buf.index >= i ].min()  # i는 원래 te의 인덱스일 수 있어, 안전하게 재계산을 권장\n",
    "            # 안전하게 현재 시점의 실제 loc 찾기\n",
    "        # 간단/안전 버전: 한 번 더 정렬/리셋로 robust하게\n",
    "        buf = buf.sort_values(cfg[\"time_col\"]).reset_index(drop=True)\n",
    "        te = te.sort_values(cfg[\"time_col\"]).reset_index(drop=True)\n",
    "\n",
    "        for t in te.index:\n",
    "            # 최신 버퍼에서 시계열 피처 갱신\n",
    "            g = buf.copy()\n",
    "            y = g[cfg[\"y_col\"]] if cfg[\"y_col\"] in g.columns else pd.Series(index=g.index, dtype=float)\n",
    "            # groupby 없이 단일 건물 버퍼라 직접 생성\n",
    "            for L in cfg[\"lags\"]:\n",
    "                g[f\"lag_{L}\"] = y.shift(L)\n",
    "            y_prev = y.shift(1)\n",
    "            for w in cfg[\"roll_mean\"]:\n",
    "                g[f\"rmean_{w}\"] = y_prev.rolling(w, min_periods=1).mean()\n",
    "            for w in cfg[\"roll_std\"]:\n",
    "                g[f\"rstd_{w}\"] = y_prev.rolling(w, min_periods=1).std()\n",
    "            g[\"diff_1\"] = y.diff(1)\n",
    "            g[\"diff_24\"] = y.diff(24)\n",
    "\n",
    "            feat_cols = [c for c in g.columns if c not in [cfg[\"y_col\"]]]\n",
    "            x_now = g.iloc[len(hist)+t][feat_cols]  # 현재 시점 피처\n",
    "            yhat = model.predict(pd.DataFrame([x_now]))[0]\n",
    "\n",
    "            # 예측값을 버퍼의 현재 시점에 기록 → 다음 시점 피처에 사용됨\n",
    "            if cfg[\"y_col\"] not in buf.columns:\n",
    "                buf[cfg[\"y_col\"]] = np.nan\n",
    "            buf.loc[len(hist)+t, cfg[\"y_col\"]] = yhat\n",
    "\n",
    "            out.append({cfg[\"id_col\"]: bid, cfg[\"time_col\"]: te.loc[t, cfg[\"time_col\"]], \"yhat\": yhat})\n",
    "    pred = pd.DataFrame(out)\n",
    "    return pred\n",
    "\n",
    "def make_submission(df_feat_new, yhat_df, id_cols=(\"건물번호\",\"timestamp\"), target_name=\"전력소비량(kWh)\"):\n",
    "    # id로 merge하여 순서 안정\n",
    "    sub = df_feat_new[id_cols].merge(\n",
    "        yhat_df.rename(columns={\"yhat\": target_name}),\n",
    "        on=list(id_cols),\n",
    "        how=\"left\",\n",
    "    )\n",
    "    # 혹시 누락되면 정렬 보정\n",
    "    sub = sub.sort_values(list(id_cols)).reset_index(drop=True)\n",
    "    assert sub[target_name].notna().all(), \"예측 누락이 있어요. id 매칭/루프 확인 필요\"\n",
    "    return sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b90a0491-9d97-4b9e-8326-6dcf5d790bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.inspection import permutation_importance, partial_dependence\n",
    "from scipy.stats import spearmanr\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# 스코어(낮을수록 좋음) — refit은 MAE 기준\n",
    "def rmse(y_true, y_pred): \n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "SCORERS = {\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"RMSE\": make_scorer(rmse, greater_is_better=False),\n",
    "}\n",
    "\n",
    "# 시간 순서 CV (누수 방지). 필요시 n_splits, test_size 조정\n",
    "tss = TimeSeriesSplit(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97272426-b97d-489c-bb00-769732d05633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "MODEL_SPECS = {\n",
    "    \"lgbm\": {\n",
    "        \"est\": LGBMRegressor(\n",
    "            objective=\"regression\",\n",
    "            random_state=SEED,\n",
    "            n_estimators=2000,\n",
    "            subsample=1.0, colsample_bytree=1.0,  # 재현성↑\n",
    "            deterministic=True, n_jobs=1\n",
    "        ),\n",
    "        \"param_dist\": {\n",
    "            \"learning_rate\":   np.linspace(0.02, 0.15, 30),\n",
    "            \"num_leaves\":      np.arange(15, 64),\n",
    "            \"min_data_in_leaf\":np.arange(10, 60),\n",
    "            \"max_depth\":       np.append([-1], np.arange(4, 13)),\n",
    "            \"reg_lambda\":      np.linspace(0.0, 2.0, 21),\n",
    "            \"max_bin\":         [63,127,255,511],\n",
    "        },\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"est\": XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_estimators=2000,\n",
    "            subsample=1.0, colsample_bytree=1.0,\n",
    "            tree_method=\"hist\",\n",
    "            enable_categorical=True,   # ★ 이 줄 추가\n",
    "            random_state=SEED, n_jobs=1\n",
    "        ),\n",
    "        \"param_dist\": {\n",
    "            \"learning_rate\":   np.linspace(0.02, 0.15, 30),\n",
    "            \"max_depth\":       np.arange(3, 13),\n",
    "            \"min_child_weight\":np.linspace(1.0, 12.0, 23),\n",
    "            \"gamma\":           np.linspace(0.0, 2.0, 21),\n",
    "            \"reg_lambda\":      np.linspace(0.0, 2.0, 21),\n",
    "        },\n",
    "    },\n",
    "    \"cat\": {\n",
    "        \"est\": CatBoostRegressor(\n",
    "            loss_function=\"RMSE\",\n",
    "            iterations=2000,\n",
    "            random_seed=SEED,\n",
    "            depth=6,\n",
    "            learning_rate=0.06,\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        ),\n",
    "        \"param_dist\": {\n",
    "            \"depth\":           np.arange(4, 10),\n",
    "            \"learning_rate\":   np.linspace(0.02, 0.15, 30),\n",
    "            \"l2_leaf_reg\":     np.linspace(1.0, 8.0, 29),\n",
    "            \"random_strength\": np.linspace(0.0, 1.0, 21),\n",
    "        },\n",
    "    },\n",
    "    \"hgb\": {\n",
    "        \"est\": HistGradientBoostingRegressor(\n",
    "            loss=\"squared_error\", random_state=SEED, max_iter=500\n",
    "        ),\n",
    "        \"param_dist\": {\n",
    "            \"learning_rate\":   np.linspace(0.02, 0.15, 30),\n",
    "            \"max_leaf_nodes\":  np.arange(15, 63),\n",
    "            \"min_samples_leaf\":np.arange(10, 60),\n",
    "            \"max_bins\":        [63,127,255,511],\n",
    "            \"l2_regularization\":np.linspace(0.0, 2.0, 21),\n",
    "        },\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"est\": RandomForestRegressor(\n",
    "            n_estimators=800, random_state=SEED, n_jobs=1\n",
    "        ),\n",
    "        \"param_dist\": {\n",
    "            \"max_depth\":       np.append([None], np.arange(5, 21)),\n",
    "            \"min_samples_leaf\":np.arange(1, 21),\n",
    "            \"max_features\":    [\"sqrt\", \"log2\", None, 0.3, 0.5, 0.7],\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "abf02980-236a-4b75-a30c-a4c3ebbc07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_one(name, est, param_dist, X, y, n_iter=40):  # n_iter는 시간에 맞춰 조절\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=est,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=SCORERS,\n",
    "        refit=\"MAE\",\n",
    "        cv=tss,\n",
    "        random_state=SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    # 결과 요약\n",
    "    best = search.best_estimator_\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "    best_row = res.loc[res['rank_test_MAE']==1].iloc[0]\n",
    "    out = {\n",
    "        \"model\": name,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"cv_MAE(mean)\": -best_row[\"mean_test_MAE\"],\n",
    "        \"cv_RMSE(mean)\": -best_row[\"mean_test_RMSE\"],\n",
    "    }\n",
    "    return best, out, search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "360cbd29-a9a7-49cc-af0a-ee646f25031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS = X_tr.select_dtypes(include=[\"category\",\"object\"]).columns.tolist()\n",
    "\n",
    "def cat_to_codes(df):\n",
    "    df2 = df.copy()\n",
    "    for c in CAT_COLS:\n",
    "        df2[c] = df2[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
    "    return df2\n",
    "\n",
    "def X_by_model(name, X):\n",
    "    # 사이킷런 HGB/RF는 코드화, 나머지는 원본 유지\n",
    "    return cat_to_codes(X) if name in [\"hgb\",\"rf\"] else X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17e1f01b-6055-4db6-847c-6bbed09a9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_one(name, est, param_dist, X, y, n_iter=40):\n",
    "    X_in = X_by_model(name, X)     # ★ 모델별 입력 변환\n",
    "    fit_params = {}\n",
    "    if name == \"cat\":\n",
    "        cat_idx = [X_in.columns.get_loc(c) for c in CAT_COLS]\n",
    "        fit_params[\"cat_features\"] = cat_idx  # ★ CatBoost에 카테고리 인덱스 전달\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=est,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=SCORERS,\n",
    "        refit=\"MAE\",\n",
    "        cv=tss,\n",
    "        random_state=SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X_in, y, **fit_params)  # ★ fit_params 반영\n",
    "    best = search.best_estimator_\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "    best_row = res.loc[res['rank_test_MAE']==1].iloc[0]\n",
    "    out = {\n",
    "        \"model\": name,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"cv_MAE(mean)\": -best_row[\"mean_test_MAE\"],\n",
    "        \"cv_RMSE(mean)\": -best_row[\"mean_test_RMSE\"],\n",
    "    }\n",
    "    return best, out, search\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bee5f242-99a8-4c0a-af60-b4aab88d8dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m search_store = {}\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, spec \u001b[38;5;129;01min\u001b[39;00m MODEL_SPECS.items():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     best, summary, search = \u001b[43mtune_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparam_dist\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     best_models[name] = best\n\u001b[32m      8\u001b[39m     rows.append(summary)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtune_one\u001b[39m\u001b[34m(name, est, param_dist, X, y, n_iter)\u001b[39m\n\u001b[32m      6\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33mcat_features\u001b[39m\u001b[33m\"\u001b[39m] = cat_idx  \u001b[38;5;66;03m# ★ CatBoost에 카테고리 인덱스 전달\u001b[39;00m\n\u001b[32m      8\u001b[39m search = RandomizedSearchCV(\n\u001b[32m      9\u001b[39m     estimator=est,\n\u001b[32m     10\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     verbose=\u001b[32m0\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ★ fit_params 반영\u001b[39;00m\n\u001b[32m     19\u001b[39m best = search.best_estimator_\n\u001b[32m     20\u001b[39m res = pd.DataFrame(search.cv_results_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    187\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     tree._fit(\n\u001b[32m    198\u001b[39m         X,\n\u001b[32m    199\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    203\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "rows = []\n",
    "search_store = {}\n",
    "\n",
    "for name, spec in MODEL_SPECS.items():\n",
    "    best, summary, search = tune_one(name, spec[\"est\"], spec[\"param_dist\"], X_tr, y_tr, n_iter=40)\n",
    "    best_models[name] = best\n",
    "    rows.append(summary)\n",
    "    search_store[name] = search\n",
    "\n",
    "cv_summary = pd.DataFrame(rows).sort_values(\"cv_MAE(mean)\")\n",
    "cv_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5aef231e-380b-455a-8ed4-a5b8a7424f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_one(name, est, param_dist, X, y, n_iter=40):\n",
    "    X_in = X_by_model(name, X)   # 모델별 입력 변환 (HGB/RF는 cat_to_codes 등)\n",
    "    fit_params = {}\n",
    "    if name == \"cat\":\n",
    "        # CatBoost는 카테고리 컬럼 인덱스를 넘겨야 함\n",
    "        cat_idx = [X_in.columns.get_loc(c) for c in CAT_COLS if c in X_in.columns]\n",
    "        fit_params[\"cat_features\"] = cat_idx\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=est,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=SCORERS,\n",
    "        refit=\"MAE\",\n",
    "        cv=tss,\n",
    "        random_state=SEED,\n",
    "        verbose=2,        # 진행 로그 보이게\n",
    "        n_jobs=1,         # ★ 병렬 끔 → wmic 문제 회피\n",
    "        error_score=\"raise\"  # 실패 파라미터 조합은 즉시 에러로 알려줌\n",
    "    )\n",
    "    search.fit(X_in, y, **fit_params)\n",
    "\n",
    "    best = search.best_estimator_\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "    best_row = res.loc[res['rank_test_MAE']==1].iloc[0]\n",
    "    summary = {\n",
    "        \"model\": name,\n",
    "        \"best_params\": search.best_params_,\n",
    "        \"cv_MAE(mean)\": -best_row[\"mean_test_MAE\"],\n",
    "        \"cv_RMSE(mean)\": -best_row[\"mean_test_RMSE\"],\n",
    "    }\n",
    "    return best, summary, search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bed94654-7911-47ef-a8d4-daf4a322b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    # squared=False 미지원 환경 대비: 직접 제곱근\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "SCORERS = {\n",
    "    \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    \"RMSE\": make_scorer(rmse, greater_is_better=False),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb15131e-c417-4e57-86cd-4791ce382724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [lgbm] RandomizedSearch 시작 ===\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  11.0s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  14.9s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  19.2s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  24.0s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  26.4s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  11.1s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  15.6s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  18.8s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  24.1s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  26.8s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=   9.7s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  12.9s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  15.8s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  18.3s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  21.0s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=   9.9s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  13.0s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  16.0s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  19.1s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  22.1s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  10.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  13.6s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  16.0s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  19.3s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  22.2s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  14.6s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  18.4s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  20.4s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  28.7s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  10.1s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  12.7s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  15.6s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  18.2s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  20.9s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  14.3s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  17.9s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  21.3s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  24.2s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  27.5s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  13.4s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  17.4s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  21.8s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  25.1s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  28.4s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=   8.6s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  12.1s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  15.4s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  19.2s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  21.9s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  12.9s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  15.6s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  18.6s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  20.6s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  12.2s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  15.5s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  18.6s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  21.7s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  24.9s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  11.3s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  15.3s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  20.1s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  24.7s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  27.4s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=   8.6s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  11.8s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  15.6s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  18.3s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  21.3s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  11.4s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  15.6s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  19.6s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  24.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  27.6s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  13.7s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  17.8s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  21.3s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  25.1s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  27.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  10.3s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  14.0s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  17.4s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  20.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  23.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  19.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  23.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  26.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  30.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  34.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=   7.9s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  11.4s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  14.1s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  17.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  20.7s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=   8.9s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  11.4s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  14.9s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  18.9s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  21.6s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=   8.9s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  11.7s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  14.7s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  17.3s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  20.6s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  14.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  18.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  21.7s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  26.2s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  29.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  10.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  13.6s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  16.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  19.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  22.1s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  12.5s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  16.0s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  19.2s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  23.7s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  26.9s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  14.3s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  17.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  20.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  23.6s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  27.4s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=   8.2s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  10.8s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  13.8s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  16.5s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  19.3s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=   7.7s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  11.9s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  15.0s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  18.6s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  21.8s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  17.6s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  24.3s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  28.3s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  33.1s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  35.7s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=   8.3s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  11.0s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  13.5s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  16.5s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  19.6s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  19.9s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  25.1s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  28.9s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  33.2s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  36.3s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=   8.1s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  11.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  18.9s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  22.4s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=   9.9s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  12.8s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  15.5s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  19.1s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  21.8s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=   8.2s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  11.5s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  14.2s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  17.4s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  19.3s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  10.4s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  13.4s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  16.1s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  19.7s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  22.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  10.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  13.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  16.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  19.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  22.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=   9.9s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  13.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  17.3s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  21.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  25.4s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  14.8s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  17.8s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  20.7s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  24.0s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=   7.0s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  10.1s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  13.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  16.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  19.6s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  11.1s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  14.3s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  17.1s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  19.6s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  22.9s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  13.1s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  16.9s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  19.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  22.9s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  25.3s\n",
      "=== [lgbm] 끝: MAE 173.30692, RMSE 357.79443 ===\n",
      "\n",
      "=== [xgb] RandomizedSearch 시작 ===\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END gamma=1.5, learning_rate=0.06034482758620689, max_depth=7, min_child_weight=5.5, reg_lambda=1.9000000000000001; total time=  20.2s\n",
      "[CV] END gamma=1.5, learning_rate=0.06034482758620689, max_depth=7, min_child_weight=5.5, reg_lambda=1.9000000000000001; total time=  29.8s\n",
      "[CV] END gamma=1.5, learning_rate=0.06034482758620689, max_depth=7, min_child_weight=5.5, reg_lambda=1.9000000000000001; total time=  40.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.06034482758620689, max_depth=7, min_child_weight=5.5, reg_lambda=1.9000000000000001; total time=  51.2s\n",
      "[CV] END gamma=1.5, learning_rate=0.06034482758620689, max_depth=7, min_child_weight=5.5, reg_lambda=1.9000000000000001; total time= 1.1min\n",
      "[CV] END gamma=1.9000000000000001, learning_rate=0.033448275862068964, max_depth=4, min_child_weight=6.5, reg_lambda=0.30000000000000004; total time=   8.6s\n",
      "[CV] END gamma=1.9000000000000001, learning_rate=0.033448275862068964, max_depth=4, min_child_weight=6.5, reg_lambda=0.30000000000000004; total time=  14.0s\n",
      "[CV] END gamma=1.9000000000000001, learning_rate=0.033448275862068964, max_depth=4, min_child_weight=6.5, reg_lambda=0.30000000000000004; total time=  20.1s\n",
      "[CV] END gamma=1.9000000000000001, learning_rate=0.033448275862068964, max_depth=4, min_child_weight=6.5, reg_lambda=0.30000000000000004; total time=  26.7s\n",
      "[CV] END gamma=1.9000000000000001, learning_rate=0.033448275862068964, max_depth=4, min_child_weight=6.5, reg_lambda=0.30000000000000004; total time=  34.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.0693103448275862, max_depth=8, min_child_weight=1.5, reg_lambda=1.8; total time=  31.3s\n",
      "[CV] END gamma=1.5, learning_rate=0.0693103448275862, max_depth=8, min_child_weight=1.5, reg_lambda=1.8; total time=  45.5s\n",
      "[CV] END gamma=1.5, learning_rate=0.0693103448275862, max_depth=8, min_child_weight=1.5, reg_lambda=1.8; total time= 1.1min\n",
      "[CV] END gamma=1.5, learning_rate=0.0693103448275862, max_depth=8, min_child_weight=1.5, reg_lambda=1.8; total time= 1.2min\n",
      "[CV] END gamma=1.5, learning_rate=0.0693103448275862, max_depth=8, min_child_weight=1.5, reg_lambda=1.8; total time= 1.5min\n",
      "[CV] END gamma=1.6, learning_rate=0.05137931034482758, max_depth=11, min_child_weight=7.0, reg_lambda=0.4; total time=  49.1s\n",
      "[CV] END gamma=1.6, learning_rate=0.05137931034482758, max_depth=11, min_child_weight=7.0, reg_lambda=0.4; total time= 1.3min\n",
      "[CV] END gamma=1.6, learning_rate=0.05137931034482758, max_depth=11, min_child_weight=7.0, reg_lambda=0.4; total time= 1.7min\n",
      "[CV] END gamma=1.6, learning_rate=0.05137931034482758, max_depth=11, min_child_weight=7.0, reg_lambda=0.4; total time= 2.2min\n",
      "[CV] END gamma=1.6, learning_rate=0.05137931034482758, max_depth=11, min_child_weight=7.0, reg_lambda=0.4; total time= 2.6min\n",
      "[CV] END gamma=1.1, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.0, reg_lambda=1.7000000000000002; total time=  18.8s\n",
      "[CV] END gamma=1.1, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.0, reg_lambda=1.7000000000000002; total time=  29.0s\n",
      "[CV] END gamma=1.1, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.0, reg_lambda=1.7000000000000002; total time=  39.3s\n",
      "[CV] END gamma=1.1, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.0, reg_lambda=1.7000000000000002; total time=  51.8s\n",
      "[CV] END gamma=1.1, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.0, reg_lambda=1.7000000000000002; total time= 1.1min\n",
      "[CV] END gamma=0.0, learning_rate=0.11862068965517242, max_depth=11, min_child_weight=4.0, reg_lambda=1.8; total time= 1.1min\n",
      "[CV] END gamma=0.0, learning_rate=0.11862068965517242, max_depth=11, min_child_weight=4.0, reg_lambda=1.8; total time= 1.7min\n",
      "[CV] END gamma=0.0, learning_rate=0.11862068965517242, max_depth=11, min_child_weight=4.0, reg_lambda=1.8; total time= 2.3min\n",
      "[CV] END gamma=0.0, learning_rate=0.11862068965517242, max_depth=11, min_child_weight=4.0, reg_lambda=1.8; total time= 2.9min\n",
      "[CV] END gamma=0.0, learning_rate=0.11862068965517242, max_depth=11, min_child_weight=4.0, reg_lambda=1.8; total time= 3.3min\n",
      "[CV] END gamma=0.5, learning_rate=0.024482758620689656, max_depth=8, min_child_weight=11.0, reg_lambda=1.5; total time=  23.0s\n",
      "[CV] END gamma=0.5, learning_rate=0.024482758620689656, max_depth=8, min_child_weight=11.0, reg_lambda=1.5; total time=  36.7s\n",
      "[CV] END gamma=0.5, learning_rate=0.024482758620689656, max_depth=8, min_child_weight=11.0, reg_lambda=1.5; total time=  51.0s\n",
      "[CV] END gamma=0.5, learning_rate=0.024482758620689656, max_depth=8, min_child_weight=11.0, reg_lambda=1.5; total time= 1.1min\n",
      "[CV] END gamma=0.5, learning_rate=0.024482758620689656, max_depth=8, min_child_weight=11.0, reg_lambda=1.5; total time= 1.3min\n",
      "[CV] END gamma=1.5, learning_rate=0.07379310344827586, max_depth=9, min_child_weight=4.0, reg_lambda=0.5; total time=  37.8s\n",
      "[CV] END gamma=1.5, learning_rate=0.07379310344827586, max_depth=9, min_child_weight=4.0, reg_lambda=0.5; total time=  55.6s\n",
      "[CV] END gamma=1.5, learning_rate=0.07379310344827586, max_depth=9, min_child_weight=4.0, reg_lambda=0.5; total time= 1.2min\n",
      "[CV] END gamma=1.5, learning_rate=0.07379310344827586, max_depth=9, min_child_weight=4.0, reg_lambda=0.5; total time= 1.5min\n",
      "[CV] END gamma=1.5, learning_rate=0.07379310344827586, max_depth=9, min_child_weight=4.0, reg_lambda=0.5; total time= 1.9min\n",
      "[CV] END gamma=1.0, learning_rate=0.13206896551724137, max_depth=3, min_child_weight=7.0, reg_lambda=0.4; total time=   6.5s\n",
      "[CV] END gamma=1.0, learning_rate=0.13206896551724137, max_depth=3, min_child_weight=7.0, reg_lambda=0.4; total time=  11.1s\n",
      "[CV] END gamma=1.0, learning_rate=0.13206896551724137, max_depth=3, min_child_weight=7.0, reg_lambda=0.4; total time=  16.3s\n",
      "[CV] END gamma=1.0, learning_rate=0.13206896551724137, max_depth=3, min_child_weight=7.0, reg_lambda=0.4; total time=  21.6s\n",
      "[CV] END gamma=1.0, learning_rate=0.13206896551724137, max_depth=3, min_child_weight=7.0, reg_lambda=0.4; total time=  27.3s\n",
      "[CV] END gamma=1.3, learning_rate=0.1275862068965517, max_depth=10, min_child_weight=7.5, reg_lambda=0.0; total time=  29.3s\n",
      "[CV] END gamma=1.3, learning_rate=0.1275862068965517, max_depth=10, min_child_weight=7.5, reg_lambda=0.0; total time=  54.5s\n",
      "[CV] END gamma=1.3, learning_rate=0.1275862068965517, max_depth=10, min_child_weight=7.5, reg_lambda=0.0; total time= 1.4min\n",
      "[CV] END gamma=1.3, learning_rate=0.1275862068965517, max_depth=10, min_child_weight=7.5, reg_lambda=0.0; total time= 1.8min\n",
      "[CV] END gamma=1.3, learning_rate=0.1275862068965517, max_depth=10, min_child_weight=7.5, reg_lambda=0.0; total time= 2.2min\n",
      "[CV] END gamma=0.7000000000000001, learning_rate=0.13206896551724137, max_depth=5, min_child_weight=2.0, reg_lambda=1.6; total time=  11.5s\n",
      "[CV] END gamma=0.7000000000000001, learning_rate=0.13206896551724137, max_depth=5, min_child_weight=2.0, reg_lambda=1.6; total time=  18.0s\n",
      "[CV] END gamma=0.7000000000000001, learning_rate=0.13206896551724137, max_depth=5, min_child_weight=2.0, reg_lambda=1.6; total time=  25.6s\n",
      "[CV] END gamma=0.7000000000000001, learning_rate=0.13206896551724137, max_depth=5, min_child_weight=2.0, reg_lambda=1.6; total time=  33.3s\n",
      "[CV] END gamma=0.7000000000000001, learning_rate=0.13206896551724137, max_depth=5, min_child_weight=2.0, reg_lambda=1.6; total time=  42.1s\n",
      "[CV] END gamma=2.0, learning_rate=0.12310344827586207, max_depth=4, min_child_weight=8.5, reg_lambda=2.0; total time=   8.4s\n",
      "[CV] END gamma=2.0, learning_rate=0.12310344827586207, max_depth=4, min_child_weight=8.5, reg_lambda=2.0; total time=  14.1s\n",
      "[CV] END gamma=2.0, learning_rate=0.12310344827586207, max_depth=4, min_child_weight=8.5, reg_lambda=2.0; total time=  20.1s\n",
      "[CV] END gamma=2.0, learning_rate=0.12310344827586207, max_depth=4, min_child_weight=8.5, reg_lambda=2.0; total time=  26.5s\n",
      "[CV] END gamma=2.0, learning_rate=0.12310344827586207, max_depth=4, min_child_weight=8.5, reg_lambda=2.0; total time=  33.3s\n",
      "[CV] END gamma=1.5, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.5, reg_lambda=0.8; total time=  18.5s\n",
      "[CV] END gamma=1.5, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.5, reg_lambda=0.8; total time=  28.9s\n",
      "[CV] END gamma=1.5, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.5, reg_lambda=0.8; total time=  40.1s\n",
      "[CV] END gamma=1.5, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.5, reg_lambda=0.8; total time=  50.6s\n",
      "[CV] END gamma=1.5, learning_rate=0.1096551724137931, max_depth=7, min_child_weight=8.5, reg_lambda=0.8; total time= 1.0min\n",
      "[CV] END gamma=0.8, learning_rate=0.09172413793103448, max_depth=10, min_child_weight=2.0, reg_lambda=0.8; total time=  45.2s\n",
      "[CV] END gamma=0.8, learning_rate=0.09172413793103448, max_depth=10, min_child_weight=2.0, reg_lambda=0.8; total time= 1.4min\n",
      "[CV] END gamma=0.8, learning_rate=0.09172413793103448, max_depth=10, min_child_weight=2.0, reg_lambda=0.8; total time= 1.8min\n",
      "[CV] END gamma=0.8, learning_rate=0.09172413793103448, max_depth=10, min_child_weight=2.0, reg_lambda=0.8; total time= 2.2min\n",
      "[CV] END gamma=0.8, learning_rate=0.09172413793103448, max_depth=10, min_child_weight=2.0, reg_lambda=0.8; total time= 2.6min\n",
      "[CV] END gamma=0.1, learning_rate=0.14103448275862068, max_depth=8, min_child_weight=11.5, reg_lambda=0.1; total time=  21.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.14103448275862068, max_depth=8, min_child_weight=11.5, reg_lambda=0.1; total time=  33.1s\n",
      "[CV] END gamma=0.1, learning_rate=0.14103448275862068, max_depth=8, min_child_weight=11.5, reg_lambda=0.1; total time=  46.7s\n",
      "[CV] END gamma=0.1, learning_rate=0.14103448275862068, max_depth=8, min_child_weight=11.5, reg_lambda=0.1; total time=  59.3s\n",
      "[CV] END gamma=0.1, learning_rate=0.14103448275862068, max_depth=8, min_child_weight=11.5, reg_lambda=0.1; total time= 1.2min\n",
      "[CV] END gamma=1.4000000000000001, learning_rate=0.11862068965517242, max_depth=10, min_child_weight=1.0, reg_lambda=0.1; total time=  31.9s\n",
      "[CV] END gamma=1.4000000000000001, learning_rate=0.11862068965517242, max_depth=10, min_child_weight=1.0, reg_lambda=0.1; total time=  57.9s\n",
      "[CV] END gamma=1.4000000000000001, learning_rate=0.11862068965517242, max_depth=10, min_child_weight=1.0, reg_lambda=0.1; total time= 1.5min\n",
      "[CV] END gamma=1.4000000000000001, learning_rate=0.11862068965517242, max_depth=10, min_child_weight=1.0, reg_lambda=0.1; total time= 2.0min\n",
      "[CV] END gamma=1.4000000000000001, learning_rate=0.11862068965517242, max_depth=10, min_child_weight=1.0, reg_lambda=0.1; total time= 2.6min\n",
      "[CV] END gamma=0.2, learning_rate=0.055862068965517236, max_depth=4, min_child_weight=11.5, reg_lambda=0.1; total time=   7.9s\n",
      "[CV] END gamma=0.2, learning_rate=0.055862068965517236, max_depth=4, min_child_weight=11.5, reg_lambda=0.1; total time=  13.0s\n",
      "[CV] END gamma=0.2, learning_rate=0.055862068965517236, max_depth=4, min_child_weight=11.5, reg_lambda=0.1; total time=  18.4s\n",
      "[CV] END gamma=0.2, learning_rate=0.055862068965517236, max_depth=4, min_child_weight=11.5, reg_lambda=0.1; total time=  25.2s\n",
      "[CV] END gamma=0.2, learning_rate=0.055862068965517236, max_depth=4, min_child_weight=11.5, reg_lambda=0.1; total time=  31.7s\n",
      "[CV] END gamma=0.5, learning_rate=0.07379310344827586, max_depth=12, min_child_weight=10.0, reg_lambda=1.6; total time=  42.4s\n",
      "[CV] END gamma=0.5, learning_rate=0.07379310344827586, max_depth=12, min_child_weight=10.0, reg_lambda=1.6; total time= 1.3min\n",
      "[CV] END gamma=0.5, learning_rate=0.07379310344827586, max_depth=12, min_child_weight=10.0, reg_lambda=1.6; total time= 1.8min\n",
      "[CV] END gamma=0.5, learning_rate=0.07379310344827586, max_depth=12, min_child_weight=10.0, reg_lambda=1.6; total time= 2.4min\n",
      "[CV] END gamma=0.5, learning_rate=0.07379310344827586, max_depth=12, min_child_weight=10.0, reg_lambda=1.6; total time= 2.9min\n",
      "[CV] END gamma=0.9, learning_rate=0.07827586206896552, max_depth=10, min_child_weight=5.0, reg_lambda=1.6; total time=  44.4s\n",
      "[CV] END gamma=0.9, learning_rate=0.07827586206896552, max_depth=10, min_child_weight=5.0, reg_lambda=1.6; total time= 1.1min\n",
      "[CV] END gamma=0.9, learning_rate=0.07827586206896552, max_depth=10, min_child_weight=5.0, reg_lambda=1.6; total time= 1.5min\n",
      "[CV] END gamma=0.9, learning_rate=0.07827586206896552, max_depth=10, min_child_weight=5.0, reg_lambda=1.6; total time= 1.8min\n",
      "[CV] END gamma=0.9, learning_rate=0.07827586206896552, max_depth=10, min_child_weight=5.0, reg_lambda=1.6; total time= 2.2min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.042413793103448276, max_depth=11, min_child_weight=2.5, reg_lambda=1.4000000000000001; total time= 1.1min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.042413793103448276, max_depth=11, min_child_weight=2.5, reg_lambda=1.4000000000000001; total time= 1.8min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.042413793103448276, max_depth=11, min_child_weight=2.5, reg_lambda=1.4000000000000001; total time= 2.2min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.042413793103448276, max_depth=11, min_child_weight=2.5, reg_lambda=1.4000000000000001; total time= 2.8min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.042413793103448276, max_depth=11, min_child_weight=2.5, reg_lambda=1.4000000000000001; total time= 3.2min\n",
      "[CV] END gamma=0.2, learning_rate=0.05137931034482758, max_depth=10, min_child_weight=2.5, reg_lambda=1.5; total time=  52.5s\n",
      "[CV] END gamma=0.2, learning_rate=0.05137931034482758, max_depth=10, min_child_weight=2.5, reg_lambda=1.5; total time= 1.3min\n",
      "[CV] END gamma=0.2, learning_rate=0.05137931034482758, max_depth=10, min_child_weight=2.5, reg_lambda=1.5; total time= 1.6min\n",
      "[CV] END gamma=0.2, learning_rate=0.05137931034482758, max_depth=10, min_child_weight=2.5, reg_lambda=1.5; total time= 2.0min\n",
      "[CV] END gamma=0.2, learning_rate=0.05137931034482758, max_depth=10, min_child_weight=2.5, reg_lambda=1.5; total time= 2.4min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.09620689655172414, max_depth=12, min_child_weight=8.5, reg_lambda=0.1; total time=  37.2s\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.09620689655172414, max_depth=12, min_child_weight=8.5, reg_lambda=0.1; total time= 1.1min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.09620689655172414, max_depth=12, min_child_weight=8.5, reg_lambda=0.1; total time= 1.7min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.09620689655172414, max_depth=12, min_child_weight=8.5, reg_lambda=0.1; total time= 2.4min\n",
      "[CV] END gamma=1.2000000000000002, learning_rate=0.09620689655172414, max_depth=12, min_child_weight=8.5, reg_lambda=0.1; total time= 3.1min\n",
      "[CV] END gamma=0.5, learning_rate=0.07827586206896552, max_depth=12, min_child_weight=3.5, reg_lambda=0.1; total time=  45.8s\n",
      "[CV] END gamma=0.5, learning_rate=0.07827586206896552, max_depth=12, min_child_weight=3.5, reg_lambda=0.1; total time= 1.4min\n",
      "[CV] END gamma=0.5, learning_rate=0.07827586206896552, max_depth=12, min_child_weight=3.5, reg_lambda=0.1; total time= 2.2min\n",
      "[CV] END gamma=0.5, learning_rate=0.07827586206896552, max_depth=12, min_child_weight=3.5, reg_lambda=0.1; total time= 2.9min\n",
      "[CV] END gamma=0.5, learning_rate=0.07827586206896552, max_depth=12, min_child_weight=3.5, reg_lambda=0.1; total time= 3.8min\n",
      "[CV] END gamma=0.0, learning_rate=0.11413793103448276, max_depth=6, min_child_weight=12.0, reg_lambda=1.4000000000000001; total time=  12.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.11413793103448276, max_depth=6, min_child_weight=12.0, reg_lambda=1.4000000000000001; total time=  20.0s\n",
      "[CV] END gamma=0.0, learning_rate=0.11413793103448276, max_depth=6, min_child_weight=12.0, reg_lambda=1.4000000000000001; total time=  28.2s\n",
      "[CV] END gamma=0.0, learning_rate=0.11413793103448276, max_depth=6, min_child_weight=12.0, reg_lambda=1.4000000000000001; total time=  37.2s\n",
      "[CV] END gamma=0.0, learning_rate=0.11413793103448276, max_depth=6, min_child_weight=12.0, reg_lambda=1.4000000000000001; total time=  46.5s\n",
      "[CV] END gamma=0.8, learning_rate=0.11413793103448276, max_depth=7, min_child_weight=5.5, reg_lambda=0.1; total time=  18.3s\n",
      "[CV] END gamma=0.8, learning_rate=0.11413793103448276, max_depth=7, min_child_weight=5.5, reg_lambda=0.1; total time=  28.0s\n",
      "[CV] END gamma=0.8, learning_rate=0.11413793103448276, max_depth=7, min_child_weight=5.5, reg_lambda=0.1; total time=  37.8s\n",
      "[CV] END gamma=0.8, learning_rate=0.11413793103448276, max_depth=7, min_child_weight=5.5, reg_lambda=0.1; total time=  49.7s\n",
      "[CV] END gamma=0.8, learning_rate=0.11413793103448276, max_depth=7, min_child_weight=5.5, reg_lambda=0.1; total time= 1.0min\n",
      "[CV] END gamma=1.5, learning_rate=0.11862068965517242, max_depth=7, min_child_weight=6.5, reg_lambda=0.8; total time=  17.9s\n",
      "[CV] END gamma=1.5, learning_rate=0.11862068965517242, max_depth=7, min_child_weight=6.5, reg_lambda=0.8; total time=  27.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.11862068965517242, max_depth=7, min_child_weight=6.5, reg_lambda=0.8; total time=  37.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.11862068965517242, max_depth=7, min_child_weight=6.5, reg_lambda=0.8; total time=  48.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.11862068965517242, max_depth=7, min_child_weight=6.5, reg_lambda=0.8; total time= 1.0min\n",
      "[CV] END gamma=0.9, learning_rate=0.10517241379310345, max_depth=3, min_child_weight=4.5, reg_lambda=0.8; total time=   6.1s\n",
      "[CV] END gamma=0.9, learning_rate=0.10517241379310345, max_depth=3, min_child_weight=4.5, reg_lambda=0.8; total time=  10.3s\n",
      "[CV] END gamma=0.9, learning_rate=0.10517241379310345, max_depth=3, min_child_weight=4.5, reg_lambda=0.8; total time=  14.9s\n",
      "[CV] END gamma=0.9, learning_rate=0.10517241379310345, max_depth=3, min_child_weight=4.5, reg_lambda=0.8; total time=  19.8s\n",
      "[CV] END gamma=0.9, learning_rate=0.10517241379310345, max_depth=3, min_child_weight=4.5, reg_lambda=0.8; total time=  25.8s\n",
      "[CV] END gamma=1.0, learning_rate=0.03793103448275862, max_depth=7, min_child_weight=6.5, reg_lambda=0.2; total time=  18.5s\n",
      "[CV] END gamma=1.0, learning_rate=0.03793103448275862, max_depth=7, min_child_weight=6.5, reg_lambda=0.2; total time=  28.0s\n",
      "[CV] END gamma=1.0, learning_rate=0.03793103448275862, max_depth=7, min_child_weight=6.5, reg_lambda=0.2; total time=  37.7s\n",
      "[CV] END gamma=1.0, learning_rate=0.03793103448275862, max_depth=7, min_child_weight=6.5, reg_lambda=0.2; total time=  49.1s\n",
      "[CV] END gamma=1.0, learning_rate=0.03793103448275862, max_depth=7, min_child_weight=6.5, reg_lambda=0.2; total time= 1.0min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=7.0, reg_lambda=0.0; total time=  28.7s\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=7.0, reg_lambda=0.0; total time=  56.3s\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=7.0, reg_lambda=0.0; total time= 1.5min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=7.0, reg_lambda=0.0; total time= 2.1min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=7.0, reg_lambda=0.0; total time= 2.7min\n",
      "[CV] END gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=9.5, reg_lambda=1.6; total time=  28.3s\n",
      "[CV] END gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=9.5, reg_lambda=1.6; total time=  44.1s\n",
      "[CV] END gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=9.5, reg_lambda=1.6; total time= 1.0min\n",
      "[CV] END gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=9.5, reg_lambda=1.6; total time= 1.3min\n",
      "[CV] END gamma=0.9, learning_rate=0.02, max_depth=9, min_child_weight=9.5, reg_lambda=1.6; total time= 1.6min\n",
      "[CV] END gamma=1.7000000000000002, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=8.0, reg_lambda=0.6000000000000001; total time=  27.1s\n",
      "[CV] END gamma=1.7000000000000002, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=8.0, reg_lambda=0.6000000000000001; total time=  50.5s\n",
      "[CV] END gamma=1.7000000000000002, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=8.0, reg_lambda=0.6000000000000001; total time= 1.3min\n",
      "[CV] END gamma=1.7000000000000002, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=8.0, reg_lambda=0.6000000000000001; total time= 1.8min\n",
      "[CV] END gamma=1.7000000000000002, learning_rate=0.1275862068965517, max_depth=11, min_child_weight=8.0, reg_lambda=0.6000000000000001; total time= 2.5min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.06034482758620689, max_depth=11, min_child_weight=8.0, reg_lambda=1.2000000000000002; total time=  45.4s\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.06034482758620689, max_depth=11, min_child_weight=8.0, reg_lambda=1.2000000000000002; total time= 1.2min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.06034482758620689, max_depth=11, min_child_weight=8.0, reg_lambda=1.2000000000000002; total time= 1.6min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.06034482758620689, max_depth=11, min_child_weight=8.0, reg_lambda=1.2000000000000002; total time= 2.0min\n",
      "[CV] END gamma=0.6000000000000001, learning_rate=0.06034482758620689, max_depth=11, min_child_weight=8.0, reg_lambda=1.2000000000000002; total time= 2.5min\n",
      "[CV] END gamma=1.0, learning_rate=0.1096551724137931, max_depth=9, min_child_weight=7.0, reg_lambda=1.2000000000000002; total time=  30.8s\n",
      "[CV] END gamma=1.0, learning_rate=0.1096551724137931, max_depth=9, min_child_weight=7.0, reg_lambda=1.2000000000000002; total time=  47.2s\n",
      "[CV] END gamma=1.0, learning_rate=0.1096551724137931, max_depth=9, min_child_weight=7.0, reg_lambda=1.2000000000000002; total time= 1.0min\n",
      "[CV] END gamma=1.0, learning_rate=0.1096551724137931, max_depth=9, min_child_weight=7.0, reg_lambda=1.2000000000000002; total time= 1.3min\n",
      "[CV] END gamma=1.0, learning_rate=0.1096551724137931, max_depth=9, min_child_weight=7.0, reg_lambda=1.2000000000000002; total time= 1.6min\n",
      "[CV] END gamma=1.5, learning_rate=0.09172413793103448, max_depth=9, min_child_weight=5.5, reg_lambda=1.5; total time=  32.0s\n",
      "[CV] END gamma=1.5, learning_rate=0.09172413793103448, max_depth=9, min_child_weight=5.5, reg_lambda=1.5; total time=  48.4s\n",
      "[CV] END gamma=1.5, learning_rate=0.09172413793103448, max_depth=9, min_child_weight=5.5, reg_lambda=1.5; total time= 1.1min\n",
      "[CV] END gamma=1.5, learning_rate=0.09172413793103448, max_depth=9, min_child_weight=5.5, reg_lambda=1.5; total time= 1.3min\n",
      "[CV] END gamma=1.5, learning_rate=0.09172413793103448, max_depth=9, min_child_weight=5.5, reg_lambda=1.5; total time= 1.6min\n",
      "[CV] END gamma=1.3, learning_rate=0.05137931034482758, max_depth=7, min_child_weight=2.0, reg_lambda=0.2; total time=  20.7s\n",
      "[CV] END gamma=1.3, learning_rate=0.05137931034482758, max_depth=7, min_child_weight=2.0, reg_lambda=0.2; total time=  30.5s\n",
      "[CV] END gamma=1.3, learning_rate=0.05137931034482758, max_depth=7, min_child_weight=2.0, reg_lambda=0.2; total time=  40.3s\n",
      "[CV] END gamma=1.3, learning_rate=0.05137931034482758, max_depth=7, min_child_weight=2.0, reg_lambda=0.2; total time=  51.8s\n",
      "[CV] END gamma=1.3, learning_rate=0.05137931034482758, max_depth=7, min_child_weight=2.0, reg_lambda=0.2; total time= 1.1min\n",
      "[CV] END gamma=0.4, learning_rate=0.08724137931034483, max_depth=8, min_child_weight=9.0, reg_lambda=1.0; total time=  22.3s\n",
      "[CV] END gamma=0.4, learning_rate=0.08724137931034483, max_depth=8, min_child_weight=9.0, reg_lambda=1.0; total time=  33.9s\n",
      "[CV] END gamma=0.4, learning_rate=0.08724137931034483, max_depth=8, min_child_weight=9.0, reg_lambda=1.0; total time=  46.2s\n",
      "[CV] END gamma=0.4, learning_rate=0.08724137931034483, max_depth=8, min_child_weight=9.0, reg_lambda=1.0; total time=  59.3s\n",
      "[CV] END gamma=0.4, learning_rate=0.08724137931034483, max_depth=8, min_child_weight=9.0, reg_lambda=1.0; total time= 1.2min\n",
      "[CV] END gamma=0.30000000000000004, learning_rate=0.10517241379310345, max_depth=4, min_child_weight=2.5, reg_lambda=1.9000000000000001; total time=   8.0s\n",
      "[CV] END gamma=0.30000000000000004, learning_rate=0.10517241379310345, max_depth=4, min_child_weight=2.5, reg_lambda=1.9000000000000001; total time=  12.8s\n",
      "[CV] END gamma=0.30000000000000004, learning_rate=0.10517241379310345, max_depth=4, min_child_weight=2.5, reg_lambda=1.9000000000000001; total time=  18.6s\n",
      "[CV] END gamma=0.30000000000000004, learning_rate=0.10517241379310345, max_depth=4, min_child_weight=2.5, reg_lambda=1.9000000000000001; total time=  25.5s\n",
      "[CV] END gamma=0.30000000000000004, learning_rate=0.10517241379310345, max_depth=4, min_child_weight=2.5, reg_lambda=1.9000000000000001; total time=  30.9s\n",
      "[CV] END gamma=0.4, learning_rate=0.08275862068965517, max_depth=4, min_child_weight=11.0, reg_lambda=2.0; total time=   8.0s\n",
      "[CV] END gamma=0.4, learning_rate=0.08275862068965517, max_depth=4, min_child_weight=11.0, reg_lambda=2.0; total time=  12.9s\n",
      "[CV] END gamma=0.4, learning_rate=0.08275862068965517, max_depth=4, min_child_weight=11.0, reg_lambda=2.0; total time=  19.1s\n",
      "[CV] END gamma=0.4, learning_rate=0.08275862068965517, max_depth=4, min_child_weight=11.0, reg_lambda=2.0; total time=  24.7s\n",
      "[CV] END gamma=0.4, learning_rate=0.08275862068965517, max_depth=4, min_child_weight=11.0, reg_lambda=2.0; total time=  31.5s\n",
      "[CV] END gamma=1.0, learning_rate=0.06482758620689655, max_depth=10, min_child_weight=7.0, reg_lambda=0.9; total time=  38.5s\n",
      "[CV] END gamma=1.0, learning_rate=0.06482758620689655, max_depth=10, min_child_weight=7.0, reg_lambda=0.9; total time=  59.8s\n",
      "[CV] END gamma=1.0, learning_rate=0.06482758620689655, max_depth=10, min_child_weight=7.0, reg_lambda=0.9; total time= 1.3min\n",
      "[CV] END gamma=1.0, learning_rate=0.06482758620689655, max_depth=10, min_child_weight=7.0, reg_lambda=0.9; total time= 1.7min\n",
      "[CV] END gamma=1.0, learning_rate=0.06482758620689655, max_depth=10, min_child_weight=7.0, reg_lambda=0.9; total time= 2.1min\n",
      "[CV] END gamma=0.0, learning_rate=0.07827586206896552, max_depth=9, min_child_weight=1.5, reg_lambda=1.6; total time=  41.8s\n",
      "[CV] END gamma=0.0, learning_rate=0.07827586206896552, max_depth=9, min_child_weight=1.5, reg_lambda=1.6; total time=  59.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.07827586206896552, max_depth=9, min_child_weight=1.5, reg_lambda=1.6; total time= 1.3min\n",
      "[CV] END gamma=0.0, learning_rate=0.07827586206896552, max_depth=9, min_child_weight=1.5, reg_lambda=1.6; total time= 1.5min\n",
      "[CV] END gamma=0.0, learning_rate=0.07827586206896552, max_depth=9, min_child_weight=1.5, reg_lambda=1.6; total time= 1.8min\n",
      "=== [xgb] 끝: MAE 818.77630, RMSE 1028.82982 ===\n",
      "\n",
      "=== [cat] RandomizedSearch 시작 ===\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.02896551724137931, random_strength=0.15000000000000002; total time=  33.8s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.02896551724137931, random_strength=0.15000000000000002; total time=  42.5s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.02896551724137931, random_strength=0.15000000000000002; total time=  50.5s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.02896551724137931, random_strength=0.15000000000000002; total time=  58.8s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.02896551724137931, random_strength=0.15000000000000002; total time= 1.1min\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.06482758620689655, random_strength=1.0; total time=  36.6s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.06482758620689655, random_strength=1.0; total time=  43.2s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.06482758620689655, random_strength=1.0; total time=  51.8s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.06482758620689655, random_strength=1.0; total time=  59.0s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.06482758620689655, random_strength=1.0; total time= 1.2min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.09620689655172414, random_strength=0.8500000000000001; total time= 1.7min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.09620689655172414, random_strength=0.8500000000000001; total time= 2.0min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.09620689655172414, random_strength=0.8500000000000001; total time= 2.3min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.09620689655172414, random_strength=0.8500000000000001; total time= 2.6min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.09620689655172414, random_strength=0.8500000000000001; total time= 2.8min\n",
      "[CV] END depth=8, l2_leaf_reg=2.25, learning_rate=0.14551724137931032, random_strength=0.1; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=2.25, learning_rate=0.14551724137931032, random_strength=0.1; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=2.25, learning_rate=0.14551724137931032, random_strength=0.1; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=2.25, learning_rate=0.14551724137931032, random_strength=0.1; total time= 2.2min\n",
      "[CV] END depth=8, l2_leaf_reg=2.25, learning_rate=0.14551724137931032, random_strength=0.1; total time= 2.4min\n",
      "[CV] END depth=7, l2_leaf_reg=1.0, learning_rate=0.033448275862068964, random_strength=0.65; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=1.0, learning_rate=0.033448275862068964, random_strength=0.65; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=1.0, learning_rate=0.033448275862068964, random_strength=0.65; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=1.0, learning_rate=0.033448275862068964, random_strength=0.65; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=1.0, learning_rate=0.033448275862068964, random_strength=0.65; total time= 2.0min\n",
      "[CV] END depth=4, l2_leaf_reg=3.25, learning_rate=0.14551724137931032, random_strength=0.35000000000000003; total time=  36.5s\n",
      "[CV] END depth=4, l2_leaf_reg=3.25, learning_rate=0.14551724137931032, random_strength=0.35000000000000003; total time=  46.8s\n",
      "[CV] END depth=4, l2_leaf_reg=3.25, learning_rate=0.14551724137931032, random_strength=0.35000000000000003; total time=  55.7s\n",
      "[CV] END depth=4, l2_leaf_reg=3.25, learning_rate=0.14551724137931032, random_strength=0.35000000000000003; total time= 1.0min\n",
      "[CV] END depth=4, l2_leaf_reg=3.25, learning_rate=0.14551724137931032, random_strength=0.35000000000000003; total time= 1.1min\n",
      "[CV] END depth=8, l2_leaf_reg=4.5, learning_rate=0.12310344827586207, random_strength=0.15000000000000002; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=4.5, learning_rate=0.12310344827586207, random_strength=0.15000000000000002; total time= 1.7min\n",
      "[CV] END depth=8, l2_leaf_reg=4.5, learning_rate=0.12310344827586207, random_strength=0.15000000000000002; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=4.5, learning_rate=0.12310344827586207, random_strength=0.15000000000000002; total time= 2.1min\n",
      "[CV] END depth=8, l2_leaf_reg=4.5, learning_rate=0.12310344827586207, random_strength=0.15000000000000002; total time= 2.4min\n",
      "[CV] END depth=6, l2_leaf_reg=1.25, learning_rate=0.024482758620689656, random_strength=0.15000000000000002; total time=  54.5s\n",
      "[CV] END depth=6, l2_leaf_reg=1.25, learning_rate=0.024482758620689656, random_strength=0.15000000000000002; total time= 1.1min\n",
      "[CV] END depth=6, l2_leaf_reg=1.25, learning_rate=0.024482758620689656, random_strength=0.15000000000000002; total time= 1.3min\n",
      "[CV] END depth=6, l2_leaf_reg=1.25, learning_rate=0.024482758620689656, random_strength=0.15000000000000002; total time= 1.5min\n",
      "[CV] END depth=6, l2_leaf_reg=1.25, learning_rate=0.024482758620689656, random_strength=0.15000000000000002; total time= 1.7min\n",
      "[CV] END depth=8, l2_leaf_reg=6.5, learning_rate=0.136551724137931, random_strength=0.6000000000000001; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=6.5, learning_rate=0.136551724137931, random_strength=0.6000000000000001; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=6.5, learning_rate=0.136551724137931, random_strength=0.6000000000000001; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=6.5, learning_rate=0.136551724137931, random_strength=0.6000000000000001; total time= 2.1min\n",
      "[CV] END depth=8, l2_leaf_reg=6.5, learning_rate=0.136551724137931, random_strength=0.6000000000000001; total time= 2.3min\n",
      "[CV] END depth=6, l2_leaf_reg=4.0, learning_rate=0.024482758620689656, random_strength=0.5; total time=  55.2s\n",
      "[CV] END depth=6, l2_leaf_reg=4.0, learning_rate=0.024482758620689656, random_strength=0.5; total time= 1.1min\n",
      "[CV] END depth=6, l2_leaf_reg=4.0, learning_rate=0.024482758620689656, random_strength=0.5; total time= 1.3min\n",
      "[CV] END depth=6, l2_leaf_reg=4.0, learning_rate=0.024482758620689656, random_strength=0.5; total time= 1.5min\n",
      "[CV] END depth=6, l2_leaf_reg=4.0, learning_rate=0.024482758620689656, random_strength=0.5; total time= 1.7min\n",
      "[CV] END depth=7, l2_leaf_reg=3.0, learning_rate=0.10517241379310345, random_strength=0.7000000000000001; total time= 1.2min\n",
      "[CV] END depth=7, l2_leaf_reg=3.0, learning_rate=0.10517241379310345, random_strength=0.7000000000000001; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=3.0, learning_rate=0.10517241379310345, random_strength=0.7000000000000001; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=3.0, learning_rate=0.10517241379310345, random_strength=0.7000000000000001; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=3.0, learning_rate=0.10517241379310345, random_strength=0.7000000000000001; total time= 2.1min\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.07827586206896552, random_strength=0.0; total time=  35.1s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.07827586206896552, random_strength=0.0; total time=  43.4s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.07827586206896552, random_strength=0.0; total time=  51.5s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.07827586206896552, random_strength=0.0; total time=  59.8s\n",
      "[CV] END depth=4, l2_leaf_reg=7.25, learning_rate=0.07827586206896552, random_strength=0.0; total time= 1.1min\n",
      "[CV] END depth=6, l2_leaf_reg=2.75, learning_rate=0.046896551724137925, random_strength=0.7000000000000001; total time=  59.0s\n",
      "[CV] END depth=6, l2_leaf_reg=2.75, learning_rate=0.046896551724137925, random_strength=0.7000000000000001; total time= 1.1min\n",
      "[CV] END depth=6, l2_leaf_reg=2.75, learning_rate=0.046896551724137925, random_strength=0.7000000000000001; total time= 1.3min\n",
      "[CV] END depth=6, l2_leaf_reg=2.75, learning_rate=0.046896551724137925, random_strength=0.7000000000000001; total time= 1.5min\n",
      "[CV] END depth=6, l2_leaf_reg=2.75, learning_rate=0.046896551724137925, random_strength=0.7000000000000001; total time= 1.7min\n",
      "[CV] END depth=7, l2_leaf_reg=5.75, learning_rate=0.11413793103448276, random_strength=0.0; total time= 1.2min\n",
      "[CV] END depth=7, l2_leaf_reg=5.75, learning_rate=0.11413793103448276, random_strength=0.0; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=5.75, learning_rate=0.11413793103448276, random_strength=0.0; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=5.75, learning_rate=0.11413793103448276, random_strength=0.0; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=5.75, learning_rate=0.11413793103448276, random_strength=0.0; total time= 2.0min\n",
      "[CV] END depth=7, l2_leaf_reg=4.75, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=4.75, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=4.75, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=4.75, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.9min\n",
      "[CV] END depth=7, l2_leaf_reg=4.75, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 2.0min\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.046896551724137925, random_strength=0.65; total time=  36.1s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.046896551724137925, random_strength=0.65; total time=  44.9s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.046896551724137925, random_strength=0.65; total time=  55.2s\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.046896551724137925, random_strength=0.65; total time= 1.0min\n",
      "[CV] END depth=4, l2_leaf_reg=1.25, learning_rate=0.046896551724137925, random_strength=0.65; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=2.75, learning_rate=0.1275862068965517, random_strength=0.55; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=2.75, learning_rate=0.1275862068965517, random_strength=0.55; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=2.75, learning_rate=0.1275862068965517, random_strength=0.55; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=2.75, learning_rate=0.1275862068965517, random_strength=0.55; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=2.75, learning_rate=0.1275862068965517, random_strength=0.55; total time= 2.0min\n",
      "[CV] END depth=7, l2_leaf_reg=4.0, learning_rate=0.14103448275862068, random_strength=0.9; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=4.0, learning_rate=0.14103448275862068, random_strength=0.9; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=4.0, learning_rate=0.14103448275862068, random_strength=0.9; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=4.0, learning_rate=0.14103448275862068, random_strength=0.9; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=4.0, learning_rate=0.14103448275862068, random_strength=0.9; total time= 2.0min\n",
      "[CV] END depth=7, l2_leaf_reg=5.0, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=5.0, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=5.0, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 1.5min\n",
      "[CV] END depth=7, l2_leaf_reg=5.0, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=5.0, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 2.1min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.136551724137931, random_strength=0.65; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.136551724137931, random_strength=0.65; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.136551724137931, random_strength=0.65; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.136551724137931, random_strength=0.65; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.136551724137931, random_strength=0.65; total time= 2.0min\n",
      "[CV] END depth=4, l2_leaf_reg=3.0, learning_rate=0.07379310344827586, random_strength=0.9500000000000001; total time=  37.4s\n",
      "[CV] END depth=4, l2_leaf_reg=3.0, learning_rate=0.07379310344827586, random_strength=0.9500000000000001; total time=  45.4s\n",
      "[CV] END depth=4, l2_leaf_reg=3.0, learning_rate=0.07379310344827586, random_strength=0.9500000000000001; total time=  55.1s\n",
      "[CV] END depth=4, l2_leaf_reg=3.0, learning_rate=0.07379310344827586, random_strength=0.9500000000000001; total time= 1.0min\n",
      "[CV] END depth=4, l2_leaf_reg=3.0, learning_rate=0.07379310344827586, random_strength=0.9500000000000001; total time= 1.2min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 1.7min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 2.0min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 2.3min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 2.5min\n",
      "[CV] END depth=9, l2_leaf_reg=5.75, learning_rate=0.024482758620689656, random_strength=0.7000000000000001; total time= 2.9min\n",
      "[CV] END depth=9, l2_leaf_reg=6.25, learning_rate=0.046896551724137925, random_strength=0.9; total time= 1.7min\n",
      "[CV] END depth=9, l2_leaf_reg=6.25, learning_rate=0.046896551724137925, random_strength=0.9; total time= 2.0min\n",
      "[CV] END depth=9, l2_leaf_reg=6.25, learning_rate=0.046896551724137925, random_strength=0.9; total time= 2.3min\n",
      "[CV] END depth=9, l2_leaf_reg=6.25, learning_rate=0.046896551724137925, random_strength=0.9; total time= 2.5min\n",
      "[CV] END depth=9, l2_leaf_reg=6.25, learning_rate=0.046896551724137925, random_strength=0.9; total time= 2.9min\n",
      "[CV] END depth=8, l2_leaf_reg=4.75, learning_rate=0.14103448275862068, random_strength=0.35000000000000003; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=4.75, learning_rate=0.14103448275862068, random_strength=0.35000000000000003; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=4.75, learning_rate=0.14103448275862068, random_strength=0.35000000000000003; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=4.75, learning_rate=0.14103448275862068, random_strength=0.35000000000000003; total time= 2.2min\n",
      "[CV] END depth=8, l2_leaf_reg=4.75, learning_rate=0.14103448275862068, random_strength=0.35000000000000003; total time= 2.4min\n",
      "[CV] END depth=6, l2_leaf_reg=7.75, learning_rate=0.05137931034482758, random_strength=0.5; total time=  55.9s\n",
      "[CV] END depth=6, l2_leaf_reg=7.75, learning_rate=0.05137931034482758, random_strength=0.5; total time= 1.1min\n",
      "[CV] END depth=6, l2_leaf_reg=7.75, learning_rate=0.05137931034482758, random_strength=0.5; total time= 1.3min\n",
      "[CV] END depth=6, l2_leaf_reg=7.75, learning_rate=0.05137931034482758, random_strength=0.5; total time= 1.5min\n",
      "[CV] END depth=6, l2_leaf_reg=7.75, learning_rate=0.05137931034482758, random_strength=0.5; total time= 1.7min\n",
      "[CV] END depth=8, l2_leaf_reg=5.75, learning_rate=0.07379310344827586, random_strength=0.15000000000000002; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=5.75, learning_rate=0.07379310344827586, random_strength=0.15000000000000002; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=5.75, learning_rate=0.07379310344827586, random_strength=0.15000000000000002; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=5.75, learning_rate=0.07379310344827586, random_strength=0.15000000000000002; total time= 2.2min\n",
      "[CV] END depth=8, l2_leaf_reg=5.75, learning_rate=0.07379310344827586, random_strength=0.15000000000000002; total time= 2.4min\n",
      "[CV] END depth=5, l2_leaf_reg=5.0, learning_rate=0.09172413793103448, random_strength=0.35000000000000003; total time=  45.0s\n",
      "[CV] END depth=5, l2_leaf_reg=5.0, learning_rate=0.09172413793103448, random_strength=0.35000000000000003; total time=  55.2s\n",
      "[CV] END depth=5, l2_leaf_reg=5.0, learning_rate=0.09172413793103448, random_strength=0.35000000000000003; total time= 1.1min\n",
      "[CV] END depth=5, l2_leaf_reg=5.0, learning_rate=0.09172413793103448, random_strength=0.35000000000000003; total time= 1.3min\n",
      "[CV] END depth=5, l2_leaf_reg=5.0, learning_rate=0.09172413793103448, random_strength=0.35000000000000003; total time= 1.5min\n",
      "[CV] END depth=7, l2_leaf_reg=7.75, learning_rate=0.042413793103448276, random_strength=0.35000000000000003; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=7.75, learning_rate=0.042413793103448276, random_strength=0.35000000000000003; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=7.75, learning_rate=0.042413793103448276, random_strength=0.35000000000000003; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=7.75, learning_rate=0.042413793103448276, random_strength=0.35000000000000003; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=7.75, learning_rate=0.042413793103448276, random_strength=0.35000000000000003; total time= 2.0min\n",
      "[CV] END depth=9, l2_leaf_reg=1.5, learning_rate=0.10517241379310345, random_strength=0.35000000000000003; total time= 1.8min\n",
      "[CV] END depth=9, l2_leaf_reg=1.5, learning_rate=0.10517241379310345, random_strength=0.35000000000000003; total time= 2.1min\n",
      "[CV] END depth=9, l2_leaf_reg=1.5, learning_rate=0.10517241379310345, random_strength=0.35000000000000003; total time= 2.3min\n",
      "[CV] END depth=9, l2_leaf_reg=1.5, learning_rate=0.10517241379310345, random_strength=0.35000000000000003; total time= 2.6min\n",
      "[CV] END depth=9, l2_leaf_reg=1.5, learning_rate=0.10517241379310345, random_strength=0.35000000000000003; total time= 2.9min\n",
      "[CV] END depth=9, l2_leaf_reg=7.0, learning_rate=0.12310344827586207, random_strength=0.8500000000000001; total time= 1.7min\n",
      "[CV] END depth=9, l2_leaf_reg=7.0, learning_rate=0.12310344827586207, random_strength=0.8500000000000001; total time= 2.1min\n",
      "[CV] END depth=9, l2_leaf_reg=7.0, learning_rate=0.12310344827586207, random_strength=0.8500000000000001; total time= 2.3min\n",
      "[CV] END depth=9, l2_leaf_reg=7.0, learning_rate=0.12310344827586207, random_strength=0.8500000000000001; total time= 2.7min\n",
      "[CV] END depth=9, l2_leaf_reg=7.0, learning_rate=0.12310344827586207, random_strength=0.8500000000000001; total time= 2.9min\n",
      "[CV] END depth=5, l2_leaf_reg=3.75, learning_rate=0.11413793103448276, random_strength=0.8500000000000001; total time=  45.8s\n",
      "[CV] END depth=5, l2_leaf_reg=3.75, learning_rate=0.11413793103448276, random_strength=0.8500000000000001; total time=  55.5s\n",
      "[CV] END depth=5, l2_leaf_reg=3.75, learning_rate=0.11413793103448276, random_strength=0.8500000000000001; total time= 1.1min\n",
      "[CV] END depth=5, l2_leaf_reg=3.75, learning_rate=0.11413793103448276, random_strength=0.8500000000000001; total time= 1.3min\n",
      "[CV] END depth=5, l2_leaf_reg=3.75, learning_rate=0.11413793103448276, random_strength=0.8500000000000001; total time= 1.5min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.02896551724137931, random_strength=0.8; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.02896551724137931, random_strength=0.8; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.02896551724137931, random_strength=0.8; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.02896551724137931, random_strength=0.8; total time= 2.1min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.02896551724137931, random_strength=0.8; total time= 2.4min\n",
      "[CV] END depth=5, l2_leaf_reg=1.0, learning_rate=0.05137931034482758, random_strength=0.7000000000000001; total time=  47.7s\n",
      "[CV] END depth=5, l2_leaf_reg=1.0, learning_rate=0.05137931034482758, random_strength=0.7000000000000001; total time=  55.1s\n",
      "[CV] END depth=5, l2_leaf_reg=1.0, learning_rate=0.05137931034482758, random_strength=0.7000000000000001; total time= 1.1min\n",
      "[CV] END depth=5, l2_leaf_reg=1.0, learning_rate=0.05137931034482758, random_strength=0.7000000000000001; total time= 1.3min\n",
      "[CV] END depth=5, l2_leaf_reg=1.0, learning_rate=0.05137931034482758, random_strength=0.7000000000000001; total time= 1.4min\n",
      "[CV] END depth=4, l2_leaf_reg=2.0, learning_rate=0.06482758620689655, random_strength=0.8500000000000001; total time=  40.5s\n",
      "[CV] END depth=4, l2_leaf_reg=2.0, learning_rate=0.06482758620689655, random_strength=0.8500000000000001; total time=  47.5s\n",
      "[CV] END depth=4, l2_leaf_reg=2.0, learning_rate=0.06482758620689655, random_strength=0.8500000000000001; total time=  53.9s\n",
      "[CV] END depth=4, l2_leaf_reg=2.0, learning_rate=0.06482758620689655, random_strength=0.8500000000000001; total time= 1.0min\n",
      "[CV] END depth=4, l2_leaf_reg=2.0, learning_rate=0.06482758620689655, random_strength=0.8500000000000001; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=2.5, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=2.5, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.4min\n",
      "[CV] END depth=7, l2_leaf_reg=2.5, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=2.5, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=2.5, learning_rate=0.136551724137931, random_strength=0.7000000000000001; total time= 2.1min\n",
      "[CV] END depth=7, l2_leaf_reg=5.25, learning_rate=0.06034482758620689, random_strength=0.8; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=5.25, learning_rate=0.06034482758620689, random_strength=0.8; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=5.25, learning_rate=0.06034482758620689, random_strength=0.8; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=5.25, learning_rate=0.06034482758620689, random_strength=0.8; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=5.25, learning_rate=0.06034482758620689, random_strength=0.8; total time= 2.1min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.0693103448275862, random_strength=0.15000000000000002; total time= 1.4min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.0693103448275862, random_strength=0.15000000000000002; total time= 1.6min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.0693103448275862, random_strength=0.15000000000000002; total time= 1.9min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.0693103448275862, random_strength=0.15000000000000002; total time= 2.1min\n",
      "[CV] END depth=8, l2_leaf_reg=5.5, learning_rate=0.0693103448275862, random_strength=0.15000000000000002; total time= 2.4min\n",
      "[CV] END depth=5, l2_leaf_reg=7.75, learning_rate=0.12310344827586207, random_strength=0.5; total time=  47.9s\n",
      "[CV] END depth=5, l2_leaf_reg=7.75, learning_rate=0.12310344827586207, random_strength=0.5; total time=  55.7s\n",
      "[CV] END depth=5, l2_leaf_reg=7.75, learning_rate=0.12310344827586207, random_strength=0.5; total time= 1.1min\n",
      "[CV] END depth=5, l2_leaf_reg=7.75, learning_rate=0.12310344827586207, random_strength=0.5; total time= 1.3min\n",
      "[CV] END depth=5, l2_leaf_reg=7.75, learning_rate=0.12310344827586207, random_strength=0.5; total time= 1.5min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.024482758620689656, random_strength=0.2; total time= 1.2min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.024482758620689656, random_strength=0.2; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.024482758620689656, random_strength=0.2; total time= 1.5min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.024482758620689656, random_strength=0.2; total time= 1.7min\n",
      "[CV] END depth=7, l2_leaf_reg=6.0, learning_rate=0.024482758620689656, random_strength=0.2; total time= 2.1min\n",
      "[CV] END depth=7, l2_leaf_reg=1.75, learning_rate=0.055862068965517236, random_strength=0.9; total time= 1.1min\n",
      "[CV] END depth=7, l2_leaf_reg=1.75, learning_rate=0.055862068965517236, random_strength=0.9; total time= 1.3min\n",
      "[CV] END depth=7, l2_leaf_reg=1.75, learning_rate=0.055862068965517236, random_strength=0.9; total time= 1.6min\n",
      "[CV] END depth=7, l2_leaf_reg=1.75, learning_rate=0.055862068965517236, random_strength=0.9; total time= 1.8min\n",
      "[CV] END depth=7, l2_leaf_reg=1.75, learning_rate=0.055862068965517236, random_strength=0.9; total time= 2.0min\n",
      "=== [cat] 끝: MAE 351.68780, RMSE 596.36980 ===\n",
      "\n",
      "=== [hgb] RandomizedSearch 시작 ===\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   3.0s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   5.4s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   3.4s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   4.7s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   6.7s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   5.6s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   7.2s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   6.7s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   4.8s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   5.9s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  10.2s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  10.8s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  11.7s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  12.5s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  13.5s\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'max_bins' parameter of HistGradientBoostingRegressor must be an int in the range [2, 255]. Got 511 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, spec \u001b[38;5;129;01min\u001b[39;00m MODEL_SPECS.items():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] RandomizedSearch 시작 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     best, summary, search = \u001b[43mtune_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparam_dist\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m=== [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] 끝: MAE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary[\u001b[33m'\u001b[39m\u001b[33mcv_MAE(mean)\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, RMSE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary[\u001b[33m'\u001b[39m\u001b[33mcv_RMSE(mean)\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m     best_models[name] = best\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtune_one\u001b[39m\u001b[34m(name, est, param_dist, X, y, n_iter)\u001b[39m\n\u001b[32m      7\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33mcat_features\u001b[39m\u001b[33m\"\u001b[39m] = cat_idx\n\u001b[32m      9\u001b[39m search = RandomizedSearchCV(\n\u001b[32m     10\u001b[39m     estimator=est,\n\u001b[32m     11\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     error_score=\u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 실패 파라미터 조합은 즉시 에러로 알려줌\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m best = search.best_estimator_\n\u001b[32m     24\u001b[39m res = pd.DataFrame(search.cv_results_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1382\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1377\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1378\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1379\u001b[39m )\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:436\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    430\u001b[39m \n\u001b[32m    431\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'max_bins' parameter of HistGradientBoostingRegressor must be an int in the range [2, 255]. Got 511 instead."
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "rows = []\n",
    "search_store = {}\n",
    "\n",
    "for name, spec in MODEL_SPECS.items():\n",
    "    print(f\"\\n=== [{name}] RandomizedSearch 시작 ===\")\n",
    "    best, summary, search = tune_one(name, spec[\"est\"], spec[\"param_dist\"], X_tr, y_tr, n_iter=40)\n",
    "    print(f\"=== [{name}] 끝: MAE {summary['cv_MAE(mean)']:.5f}, RMSE {summary['cv_RMSE(mean)']:.5f} ===\")\n",
    "    best_models[name] = best\n",
    "    rows.append(summary)\n",
    "    search_store[name] = search\n",
    "\n",
    "cv_summary = pd.DataFrame(rows).sort_values(\"cv_MAE(mean)\")\n",
    "cv_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1e435b3-92be-4b15-8d1e-ce88c00ec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "MODEL_SPECS[\"xgb\"][\"est\"] = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=True,\n",
    "    random_state=SEED, n_jobs=1\n",
    ")\n",
    "\n",
    "MODEL_SPECS[\"xgb\"][\"param_dist\"] = {\n",
    "    # 너무 큰 lr 제거하고, 적당한 범위로\n",
    "    \"learning_rate\": uniform(0.03, 0.08),        # 0.03 ~ 0.11\n",
    "    \"max_depth\": randint(3, 9),                  # 3 ~ 8\n",
    "    \"min_child_weight\": uniform(2.0, 8.0),       # 2 ~ 10\n",
    "    \"gamma\": uniform(0.0, 1.5),\n",
    "    # 과적합 억제용 샘플링 추가\n",
    "    \"subsample\": uniform(0.6, 0.4),              # 0.6 ~ 1.0\n",
    "    \"colsample_bytree\": uniform(0.6, 0.4),       # 0.6 ~ 1.0\n",
    "    # 규제 튜닝\n",
    "    \"reg_lambda\": uniform(0.0, 2.0),\n",
    "    # 트리 개수도 탐색 (너무 크지 않게)\n",
    "    \"n_estimators\": randint(400, 1201)           # 400 ~ 1200\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81a97ec8-1830-4993-8f77-6ffbc65e8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "MODEL_SPECS[\"cat\"][\"est\"] = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    random_seed=SEED,\n",
    "    allow_writing_files=False,\n",
    "    verbose=False,\n",
    "    thread_count=1\n",
    ")\n",
    "\n",
    "MODEL_SPECS[\"cat\"][\"param_dist\"] = {\n",
    "    \"depth\": randint(4, 9),                      # 4 ~ 8\n",
    "    \"learning_rate\": uniform(0.03, 0.09),        # 0.03 ~ 0.12 중 좁힘\n",
    "    \"l2_leaf_reg\": uniform(1.0, 7.0),\n",
    "    \"random_strength\": uniform(0.0, 1.0),\n",
    "    # 규제/샘플링 추가\n",
    "    \"bagging_temperature\": uniform(0.0, 1.0),\n",
    "    \"rsm\": uniform(0.6, 0.4),                    # 0.6 ~ 1.0 (column sampling)\n",
    "    # 반복 수도 탐색\n",
    "    \"iterations\": randint(500, 1501)             # 500 ~ 1500\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fe2400a-ed8a-449e-9421-dc723365eca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [lgbm] RandomizedSearch 시작 (n_iter=40) ===\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  11.3s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  22.6s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  20.2s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  23.7s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=6, min_data_in_leaf=15, num_leaves=40, reg_lambda=1.6; total time=  26.2s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  11.0s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  15.8s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  18.9s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  21.7s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=7, min_data_in_leaf=59, num_leaves=47, reg_lambda=1.7000000000000002; total time=  26.4s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=   9.5s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  12.8s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  15.7s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  17.9s\n",
      "[CV] END learning_rate=0.14103448275862068, max_bin=255, max_depth=8, min_data_in_leaf=39, num_leaves=24, reg_lambda=0.2; total time=  20.6s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=   9.7s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  12.2s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  14.8s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  18.1s\n",
      "[CV] END learning_rate=0.15, max_bin=127, max_depth=7, min_data_in_leaf=20, num_leaves=34, reg_lambda=1.0; total time=  20.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=   9.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  13.1s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  15.9s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  17.1s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=63, max_depth=12, min_data_in_leaf=47, num_leaves=46, reg_lambda=1.4000000000000001; total time=  19.4s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  12.6s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  15.8s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  20.0s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  23.9s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=127, max_depth=11, min_data_in_leaf=49, num_leaves=56, reg_lambda=0.0; total time=  25.7s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=   8.2s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  10.6s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  13.1s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  15.4s\n",
      "[CV] END learning_rate=0.09620689655172414, max_bin=127, max_depth=8, min_data_in_leaf=40, num_leaves=29, reg_lambda=0.7000000000000001; total time=  17.8s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  12.0s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  15.2s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  17.9s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  20.9s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=12, min_data_in_leaf=42, num_leaves=31, reg_lambda=1.6; total time=  23.4s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  11.5s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  15.3s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  18.6s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  23.7s\n",
      "[CV] END learning_rate=0.12310344827586207, max_bin=127, max_depth=8, min_data_in_leaf=43, num_leaves=58, reg_lambda=0.8; total time=  24.3s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=   7.1s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  10.1s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  13.0s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  16.4s\n",
      "[CV] END learning_rate=0.07379310344827586, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=46, reg_lambda=0.7000000000000001; total time=  18.7s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=   8.3s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  13.2s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  15.9s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=63, max_depth=10, min_data_in_leaf=47, num_leaves=38, reg_lambda=0.5; total time=  18.1s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  10.8s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  13.5s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  16.6s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  18.7s\n",
      "[CV] END learning_rate=0.0693103448275862, max_bin=255, max_depth=9, min_data_in_leaf=15, num_leaves=42, reg_lambda=1.6; total time=  21.6s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  10.0s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  13.9s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  17.6s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  22.2s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=7, min_data_in_leaf=50, num_leaves=63, reg_lambda=1.5; total time=  26.8s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=   8.7s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  11.4s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  14.4s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  17.2s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=255, max_depth=10, min_data_in_leaf=17, num_leaves=22, reg_lambda=1.9000000000000001; total time=  19.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  10.4s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  14.8s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  18.9s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  23.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=6, min_data_in_leaf=10, num_leaves=54, reg_lambda=1.8; total time=  27.4s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  13.6s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  18.3s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  21.6s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  25.4s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=127, max_depth=9, min_data_in_leaf=48, num_leaves=61, reg_lambda=1.4000000000000001; total time=  28.1s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  10.6s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  13.7s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  17.0s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  19.7s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=7, min_data_in_leaf=10, num_leaves=42, reg_lambda=1.8; total time=  23.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  19.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  23.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  26.8s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  30.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=511, max_depth=9, min_data_in_leaf=14, num_leaves=61, reg_lambda=0.2; total time=  33.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=   8.1s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  10.9s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  13.2s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  16.9s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=127, max_depth=9, min_data_in_leaf=51, num_leaves=20, reg_lambda=1.1; total time=  20.9s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=   8.1s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  11.1s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  14.0s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  17.4s\n",
      "[CV] END learning_rate=0.046896551724137925, max_bin=511, max_depth=4, min_data_in_leaf=20, num_leaves=21, reg_lambda=0.1; total time=  20.4s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=   8.4s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  11.2s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  13.8s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  16.4s\n",
      "[CV] END learning_rate=0.06034482758620689, max_bin=63, max_depth=-1, min_data_in_leaf=31, num_leaves=38, reg_lambda=1.5; total time=  19.0s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  13.5s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  17.2s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  20.4s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  23.9s\n",
      "[CV] END learning_rate=0.02896551724137931, max_bin=63, max_depth=10, min_data_in_leaf=53, num_leaves=61, reg_lambda=1.0; total time=  27.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  10.1s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  12.7s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  15.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  18.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=12, min_data_in_leaf=18, num_leaves=63, reg_lambda=1.9000000000000001; total time=  20.9s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  11.9s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  15.4s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  18.4s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  21.8s\n",
      "[CV] END learning_rate=0.024482758620689656, max_bin=255, max_depth=8, min_data_in_leaf=10, num_leaves=39, reg_lambda=1.5; total time=  25.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  13.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  16.5s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  19.4s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  22.3s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=-1, min_data_in_leaf=40, num_leaves=34, reg_lambda=1.4000000000000001; total time=  24.7s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=   7.6s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  10.2s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  12.9s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  15.3s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=127, max_depth=7, min_data_in_leaf=19, num_leaves=25, reg_lambda=1.6; total time=  17.8s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=   7.5s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  11.1s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  14.0s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  18.1s\n",
      "[CV] END learning_rate=0.1275862068965517, max_bin=63, max_depth=5, min_data_in_leaf=33, num_leaves=29, reg_lambda=0.7000000000000001; total time=  20.6s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  16.8s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  22.5s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  26.6s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  31.1s\n",
      "[CV] END learning_rate=0.09172413793103448, max_bin=511, max_depth=9, min_data_in_leaf=45, num_leaves=61, reg_lambda=0.30000000000000004; total time=  34.4s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=   7.6s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  10.4s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  13.0s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  15.5s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=127, max_depth=8, min_data_in_leaf=10, num_leaves=29, reg_lambda=1.5; total time=  18.2s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  19.2s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  23.4s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  26.6s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  30.5s\n",
      "[CV] END learning_rate=0.03793103448275862, max_bin=511, max_depth=-1, min_data_in_leaf=18, num_leaves=57, reg_lambda=1.9000000000000001; total time=  34.0s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  11.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  14.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  17.9s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=5, min_data_in_leaf=23, num_leaves=59, reg_lambda=2.0; total time=  21.1s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=   9.8s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  12.5s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  15.0s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  17.8s\n",
      "[CV] END learning_rate=0.08275862068965517, max_bin=255, max_depth=12, min_data_in_leaf=54, num_leaves=26, reg_lambda=0.7000000000000001; total time=  20.2s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=   8.1s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  11.0s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  13.4s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  16.2s\n",
      "[CV] END learning_rate=0.11413793103448276, max_bin=63, max_depth=-1, min_data_in_leaf=41, num_leaves=39, reg_lambda=0.8; total time=  18.5s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=   9.7s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  12.5s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  15.0s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  17.8s\n",
      "[CV] END learning_rate=0.08724137931034483, max_bin=255, max_depth=-1, min_data_in_leaf=53, num_leaves=27, reg_lambda=1.3; total time=  20.3s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=   9.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  12.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  15.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  18.7s\n",
      "[CV] END learning_rate=0.1096551724137931, max_bin=511, max_depth=6, min_data_in_leaf=12, num_leaves=23, reg_lambda=0.4; total time=  21.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=   9.0s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  13.1s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  16.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  20.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=63, max_depth=6, min_data_in_leaf=49, num_leaves=63, reg_lambda=0.9; total time=  23.8s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  13.7s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  16.3s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  19.7s\n",
      "[CV] END learning_rate=0.042413793103448276, max_bin=63, max_depth=9, min_data_in_leaf=52, num_leaves=42, reg_lambda=0.5; total time=  22.2s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=   6.4s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=   9.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  12.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  15.5s\n",
      "[CV] END learning_rate=0.10517241379310345, max_bin=127, max_depth=4, min_data_in_leaf=10, num_leaves=27, reg_lambda=2.0; total time=  18.1s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  10.6s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  13.5s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  15.9s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  18.5s\n",
      "[CV] END learning_rate=0.11862068965517242, max_bin=255, max_depth=12, min_data_in_leaf=33, num_leaves=35, reg_lambda=1.8; total time=  21.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  12.2s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  15.4s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  18.4s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  21.0s\n",
      "[CV] END learning_rate=0.06482758620689655, max_bin=127, max_depth=10, min_data_in_leaf=52, num_leaves=47, reg_lambda=1.5; total time=  23.8s\n",
      "\n",
      "=== [xgb] RandomizedSearch 시작 (n_iter=20) ===\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=1.4260714596148742, learning_rate=0.08855951534491241, max_depth=7, min_child_weight=6.774801263571896, n_estimators=521, reg_lambda=0.3119890406724053, subsample=0.6232334448672797; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=1.4260714596148742, learning_rate=0.08855951534491241, max_depth=7, min_child_weight=6.774801263571896, n_estimators=521, reg_lambda=0.3119890406724053, subsample=0.6232334448672797; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=1.4260714596148742, learning_rate=0.08855951534491241, max_depth=7, min_child_weight=6.774801263571896, n_estimators=521, reg_lambda=0.3119890406724053, subsample=0.6232334448672797; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=1.4260714596148742, learning_rate=0.08855951534491241, max_depth=7, min_child_weight=6.774801263571896, n_estimators=521, reg_lambda=0.3119890406724053, subsample=0.6232334448672797; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.749816047538945, gamma=1.4260714596148742, learning_rate=0.08855951534491241, max_depth=7, min_child_weight=6.774801263571896, n_estimators=521, reg_lambda=0.3119890406724053, subsample=0.6232334448672797; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.9464704583099741, gamma=0.9016725176148133, learning_rate=0.08664580622368365, max_depth=8, min_child_weight=2.451292632216802, n_estimators=743, reg_lambda=1.6648852816008435, subsample=0.6849356442713105; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.9464704583099741, gamma=0.9016725176148133, learning_rate=0.08664580622368365, max_depth=8, min_child_weight=2.451292632216802, n_estimators=743, reg_lambda=1.6648852816008435, subsample=0.6849356442713105; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.9464704583099741, gamma=0.9016725176148133, learning_rate=0.08664580622368365, max_depth=8, min_child_weight=2.451292632216802, n_estimators=743, reg_lambda=1.6648852816008435, subsample=0.6849356442713105; total time=  25.5s\n",
      "[CV] END colsample_bytree=0.9464704583099741, gamma=0.9016725176148133, learning_rate=0.08664580622368365, max_depth=8, min_child_weight=2.451292632216802, n_estimators=743, reg_lambda=1.6648852816008435, subsample=0.6849356442713105; total time=  32.3s\n",
      "[CV] END colsample_bytree=0.9464704583099741, gamma=0.9016725176148133, learning_rate=0.08664580622368365, max_depth=8, min_child_weight=2.451292632216802, n_estimators=743, reg_lambda=1.6648852816008435, subsample=0.6849356442713105; total time=  39.5s\n",
      "[CV] END colsample_bytree=0.6727299868828402, gamma=0.2751067647801507, learning_rate=0.05433937943676302, max_depth=8, min_child_weight=2.0565304417577392, n_estimators=960, reg_lambda=1.0495493205167783, subsample=0.7599443886861021; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.6727299868828402, gamma=0.2751067647801507, learning_rate=0.05433937943676302, max_depth=8, min_child_weight=2.0565304417577392, n_estimators=960, reg_lambda=1.0495493205167783, subsample=0.7599443886861021; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.6727299868828402, gamma=0.2751067647801507, learning_rate=0.05433937943676302, max_depth=8, min_child_weight=2.0565304417577392, n_estimators=960, reg_lambda=1.0495493205167783, subsample=0.7599443886861021; total time=  27.9s\n",
      "[CV] END colsample_bytree=0.6727299868828402, gamma=0.2751067647801507, learning_rate=0.05433937943676302, max_depth=8, min_child_weight=2.0565304417577392, n_estimators=960, reg_lambda=1.0495493205167783, subsample=0.7599443886861021; total time=  35.8s\n",
      "[CV] END colsample_bytree=0.6727299868828402, gamma=0.2751067647801507, learning_rate=0.05433937943676302, max_depth=8, min_child_weight=2.0565304417577392, n_estimators=960, reg_lambda=1.0495493205167783, subsample=0.7599443886861021; total time=  43.6s\n",
      "[CV] END colsample_bytree=0.6186662652854461, gamma=1.4606332782621887, learning_rate=0.04862170723442434, max_depth=8, min_child_weight=8.281407691144109, n_estimators=962, reg_lambda=0.7649239825343255, subsample=0.9932923543227152; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.6186662652854461, gamma=1.4606332782621887, learning_rate=0.04862170723442434, max_depth=8, min_child_weight=8.281407691144109, n_estimators=962, reg_lambda=0.7649239825343255, subsample=0.9932923543227152; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.6186662652854461, gamma=1.4606332782621887, learning_rate=0.04862170723442434, max_depth=8, min_child_weight=8.281407691144109, n_estimators=962, reg_lambda=0.7649239825343255, subsample=0.9932923543227152; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.6186662652854461, gamma=1.4606332782621887, learning_rate=0.04862170723442434, max_depth=8, min_child_weight=8.281407691144109, n_estimators=962, reg_lambda=0.7649239825343255, subsample=0.9932923543227152; total time=  30.4s\n",
      "[CV] END colsample_bytree=0.6186662652854461, gamma=1.4606332782621887, learning_rate=0.04862170723442434, max_depth=8, min_child_weight=8.281407691144109, n_estimators=962, reg_lambda=0.7649239825343255, subsample=0.9932923543227152; total time=  37.5s\n",
      "[CV] END colsample_bytree=0.786705157299192, gamma=1.2899106101044808, learning_rate=0.08442460308702238, max_depth=3, min_child_weight=2.520412743882236, n_estimators=787, reg_lambda=1.8844035113697055, subsample=0.8253152871382157; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.786705157299192, gamma=1.2899106101044808, learning_rate=0.08442460308702238, max_depth=3, min_child_weight=2.520412743882236, n_estimators=787, reg_lambda=1.8844035113697055, subsample=0.8253152871382157; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.786705157299192, gamma=1.2899106101044808, learning_rate=0.08442460308702238, max_depth=3, min_child_weight=2.520412743882236, n_estimators=787, reg_lambda=1.8844035113697055, subsample=0.8253152871382157; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.786705157299192, gamma=1.2899106101044808, learning_rate=0.08442460308702238, max_depth=3, min_child_weight=2.520412743882236, n_estimators=787, reg_lambda=1.8844035113697055, subsample=0.8253152871382157; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.786705157299192, gamma=1.2899106101044808, learning_rate=0.08442460308702238, max_depth=3, min_child_weight=2.520412743882236, n_estimators=787, reg_lambda=1.8844035113697055, subsample=0.8253152871382157; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.7541666010159664, gamma=0.02394937833032129, learning_rate=0.04847150604977192, max_depth=6, min_child_weight=5.52121994991681, n_estimators=854, reg_lambda=1.2199933155652418, subsample=0.9332779646944658; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.7541666010159664, gamma=0.02394937833032129, learning_rate=0.04847150604977192, max_depth=6, min_child_weight=5.52121994991681, n_estimators=854, reg_lambda=1.2199933155652418, subsample=0.9332779646944658; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7541666010159664, gamma=0.02394937833032129, learning_rate=0.04847150604977192, max_depth=6, min_child_weight=5.52121994991681, n_estimators=854, reg_lambda=1.2199933155652418, subsample=0.9332779646944658; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.7541666010159664, gamma=0.02394937833032129, learning_rate=0.04847150604977192, max_depth=6, min_child_weight=5.52121994991681, n_estimators=854, reg_lambda=1.2199933155652418, subsample=0.9332779646944658; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.7541666010159664, gamma=0.02394937833032129, learning_rate=0.04847150604977192, max_depth=6, min_child_weight=5.52121994991681, n_estimators=854, reg_lambda=1.2199933155652418, subsample=0.9332779646944658; total time=  26.1s\n",
      "[CV] END colsample_bytree=0.6693458614031088, gamma=0.5865909113598612, learning_rate=0.04457888702304499, max_depth=6, min_child_weight=4.493688608715288, n_estimators=789, reg_lambda=0.41588332573637765, subsample=0.8270801311279966; total time=   5.9s\n",
      "[CV] END colsample_bytree=0.6693458614031088, gamma=0.5865909113598612, learning_rate=0.04457888702304499, max_depth=6, min_child_weight=4.493688608715288, n_estimators=789, reg_lambda=0.41588332573637765, subsample=0.8270801311279966; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.6693458614031088, gamma=0.5865909113598612, learning_rate=0.04457888702304499, max_depth=6, min_child_weight=4.493688608715288, n_estimators=789, reg_lambda=0.41588332573637765, subsample=0.8270801311279966; total time=  14.3s\n",
      "[CV] END colsample_bytree=0.6693458614031088, gamma=0.5865909113598612, learning_rate=0.04457888702304499, max_depth=6, min_child_weight=4.493688608715288, n_estimators=789, reg_lambda=0.41588332573637765, subsample=0.8270801311279966; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.6693458614031088, gamma=0.5865909113598612, learning_rate=0.04457888702304499, max_depth=6, min_child_weight=4.493688608715288, n_estimators=789, reg_lambda=0.41588332573637765, subsample=0.8270801311279966; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.6125253169822235, gamma=1.2634271618924977, learning_rate=0.06598033066958126, max_depth=4, min_child_weight=9.158618803421192, n_estimators=669, reg_lambda=1.4545439917128418, subsample=0.7306163075223342; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6125253169822235, gamma=1.2634271618924977, learning_rate=0.06598033066958126, max_depth=4, min_child_weight=9.158618803421192, n_estimators=669, reg_lambda=1.4545439917128418, subsample=0.7306163075223342; total time=   5.5s\n",
      "[CV] END colsample_bytree=0.6125253169822235, gamma=1.2634271618924977, learning_rate=0.06598033066958126, max_depth=4, min_child_weight=9.158618803421192, n_estimators=669, reg_lambda=1.4545439917128418, subsample=0.7306163075223342; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.6125253169822235, gamma=1.2634271618924977, learning_rate=0.06598033066958126, max_depth=4, min_child_weight=9.158618803421192, n_estimators=669, reg_lambda=1.4545439917128418, subsample=0.7306163075223342; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.6125253169822235, gamma=1.2634271618924977, learning_rate=0.06598033066958126, max_depth=4, min_child_weight=9.158618803421192, n_estimators=669, reg_lambda=1.4545439917128418, subsample=0.7306163075223342; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.8281775897621597, gamma=0.7812513900387354, learning_rate=0.10689376194794793, max_depth=7, min_child_weight=5.109418317515856, n_estimators=737, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8281775897621597, gamma=0.7812513900387354, learning_rate=0.10689376194794793, max_depth=7, min_child_weight=5.109418317515856, n_estimators=737, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.8281775897621597, gamma=0.7812513900387354, learning_rate=0.10689376194794793, max_depth=7, min_child_weight=5.109418317515856, n_estimators=737, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.8281775897621597, gamma=0.7812513900387354, learning_rate=0.10689376194794793, max_depth=7, min_child_weight=5.109418317515856, n_estimators=737, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  22.7s\n",
      "[CV] END colsample_bytree=0.8281775897621597, gamma=0.7812513900387354, learning_rate=0.10689376194794793, max_depth=7, min_child_weight=5.109418317515856, n_estimators=737, reg_lambda=1.0793842647781595, subsample=0.8347004662655393; total time=  28.2s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.9105513715300271, learning_rate=0.05207993456180347, max_depth=7, min_child_weight=8.417575846032317, n_estimators=464, reg_lambda=0.03127281348238786, subsample=0.7693605922825478; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.9105513715300271, learning_rate=0.05207993456180347, max_depth=7, min_child_weight=8.417575846032317, n_estimators=464, reg_lambda=0.03127281348238786, subsample=0.7693605922825478; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.9105513715300271, learning_rate=0.05207993456180347, max_depth=7, min_child_weight=8.417575846032317, n_estimators=464, reg_lambda=0.03127281348238786, subsample=0.7693605922825478; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.9105513715300271, learning_rate=0.05207993456180347, max_depth=7, min_child_weight=8.417575846032317, n_estimators=464, reg_lambda=0.03127281348238786, subsample=0.7693605922825478; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.9861021229056552, gamma=0.9105513715300271, learning_rate=0.05207993456180347, max_depth=7, min_child_weight=8.417575846032317, n_estimators=464, reg_lambda=0.03127281348238786, subsample=0.7693605922825478; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.7579526072702278, gamma=0.4402322620770572, learning_rate=0.031126385817206757, max_depth=5, min_child_weight=7.654858750780937, n_estimators=1074, reg_lambda=1.5803510810624113, subsample=0.8423839899124046; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.7579526072702278, gamma=0.4402322620770572, learning_rate=0.031126385817206757, max_depth=5, min_child_weight=7.654858750780937, n_estimators=1074, reg_lambda=1.5803510810624113, subsample=0.8423839899124046; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7579526072702278, gamma=0.4402322620770572, learning_rate=0.031126385817206757, max_depth=5, min_child_weight=7.654858750780937, n_estimators=1074, reg_lambda=1.5803510810624113, subsample=0.8423839899124046; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.7579526072702278, gamma=0.4402322620770572, learning_rate=0.031126385817206757, max_depth=5, min_child_weight=7.654858750780937, n_estimators=1074, reg_lambda=1.5803510810624113, subsample=0.8423839899124046; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.7579526072702278, gamma=0.4402322620770572, learning_rate=0.031126385817206757, max_depth=5, min_child_weight=7.654858750780937, n_estimators=1074, reg_lambda=1.5803510810624113, subsample=0.8423839899124046; total time=  27.9s\n",
      "[CV] END colsample_bytree=0.9705203514053395, gamma=0.9766155382529167, learning_rate=0.10319677404350246, max_depth=3, min_child_weight=6.986385014620463, n_estimators=432, reg_lambda=0.12711670057204727, subsample=0.7243929286862649; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9705203514053395, gamma=0.9766155382529167, learning_rate=0.10319677404350246, max_depth=3, min_child_weight=6.986385014620463, n_estimators=432, reg_lambda=0.12711670057204727, subsample=0.7243929286862649; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9705203514053395, gamma=0.9766155382529167, learning_rate=0.10319677404350246, max_depth=3, min_child_weight=6.986385014620463, n_estimators=432, reg_lambda=0.12711670057204727, subsample=0.7243929286862649; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9705203514053395, gamma=0.9766155382529167, learning_rate=0.10319677404350246, max_depth=3, min_child_weight=6.986385014620463, n_estimators=432, reg_lambda=0.12711670057204727, subsample=0.7243929286862649; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.9705203514053395, gamma=0.9766155382529167, learning_rate=0.10319677404350246, max_depth=3, min_child_weight=6.986385014620463, n_estimators=432, reg_lambda=0.12711670057204727, subsample=0.7243929286862649; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7300733288106989, gamma=1.0944092675070962, learning_rate=0.08100459770841706, max_depth=5, min_child_weight=6.489947406781609, n_estimators=1138, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.7300733288106989, gamma=1.0944092675070962, learning_rate=0.08100459770841706, max_depth=5, min_child_weight=6.489947406781609, n_estimators=1138, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7300733288106989, gamma=1.0944092675070962, learning_rate=0.08100459770841706, max_depth=5, min_child_weight=6.489947406781609, n_estimators=1138, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.7300733288106989, gamma=1.0944092675070962, learning_rate=0.08100459770841706, max_depth=5, min_child_weight=6.489947406781609, n_estimators=1138, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.7300733288106989, gamma=1.0944092675070962, learning_rate=0.08100459770841706, max_depth=5, min_child_weight=6.489947406781609, n_estimators=1138, reg_lambda=0.2391884918766034, subsample=0.885297914889198; total time=  29.6s\n",
      "[CV] END colsample_bytree=0.9043140194467589, gamma=0.8419157963542443, learning_rate=0.09167737439636488, max_depth=5, min_child_weight=6.1818626350559525, n_estimators=414, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9043140194467589, gamma=0.8419157963542443, learning_rate=0.09167737439636488, max_depth=5, min_child_weight=6.1818626350559525, n_estimators=414, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9043140194467589, gamma=0.8419157963542443, learning_rate=0.09167737439636488, max_depth=5, min_child_weight=6.1818626350559525, n_estimators=414, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.9043140194467589, gamma=0.8419157963542443, learning_rate=0.09167737439636488, max_depth=5, min_child_weight=6.1818626350559525, n_estimators=414, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.9043140194467589, gamma=0.8419157963542443, learning_rate=0.09167737439636488, max_depth=5, min_child_weight=6.1818626350559525, n_estimators=414, reg_lambda=0.22178164162366265, subsample=0.7757346007463081; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.6806876809341584, gamma=1.343645393510279, learning_rate=0.06802961785456893, max_depth=7, min_child_weight=6.068565529317622, n_estimators=1133, reg_lambda=0.2786629088117514, subsample=0.8417669517111269; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.6806876809341584, gamma=1.343645393510279, learning_rate=0.06802961785456893, max_depth=7, min_child_weight=6.068565529317622, n_estimators=1133, reg_lambda=0.2786629088117514, subsample=0.8417669517111269; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.6806876809341584, gamma=1.343645393510279, learning_rate=0.06802961785456893, max_depth=7, min_child_weight=6.068565529317622, n_estimators=1133, reg_lambda=0.2786629088117514, subsample=0.8417669517111269; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.6806876809341584, gamma=1.343645393510279, learning_rate=0.06802961785456893, max_depth=7, min_child_weight=6.068565529317622, n_estimators=1133, reg_lambda=0.2786629088117514, subsample=0.8417669517111269; total time=  32.8s\n",
      "[CV] END colsample_bytree=0.6806876809341584, gamma=1.343645393510279, learning_rate=0.06802961785456893, max_depth=7, min_child_weight=6.068565529317622, n_estimators=1133, reg_lambda=0.2786629088117514, subsample=0.8417669517111269; total time=  40.7s\n",
      "[CV] END colsample_bytree=0.8159364365206693, gamma=0.3045918371021541, learning_rate=0.10542828564463848, max_depth=5, min_child_weight=7.5582794643176365, n_estimators=1195, reg_lambda=1.8593953046851461, subsample=0.9232481518257668; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.8159364365206693, gamma=0.3045918371021541, learning_rate=0.10542828564463848, max_depth=5, min_child_weight=7.5582794643176365, n_estimators=1195, reg_lambda=1.8593953046851461, subsample=0.9232481518257668; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.8159364365206693, gamma=0.3045918371021541, learning_rate=0.10542828564463848, max_depth=5, min_child_weight=7.5582794643176365, n_estimators=1195, reg_lambda=1.8593953046851461, subsample=0.9232481518257668; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.8159364365206693, gamma=0.3045918371021541, learning_rate=0.10542828564463848, max_depth=5, min_child_weight=7.5582794643176365, n_estimators=1195, reg_lambda=1.8593953046851461, subsample=0.9232481518257668; total time=  24.6s\n",
      "[CV] END colsample_bytree=0.8159364365206693, gamma=0.3045918371021541, learning_rate=0.10542828564463848, max_depth=5, min_child_weight=7.5582794643176365, n_estimators=1195, reg_lambda=1.8593953046851461, subsample=0.9232481518257668; total time=  31.5s\n",
      "[CV] END colsample_bytree=0.8533615026041694, gamma=1.3071908852815766, learning_rate=0.09429376615192915, max_depth=6, min_child_weight=5.33207958296293, n_estimators=730, reg_lambda=0.6486900420105479, subsample=0.6488351818802693; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8533615026041694, gamma=1.3071908852815766, learning_rate=0.09429376615192915, max_depth=6, min_child_weight=5.33207958296293, n_estimators=730, reg_lambda=0.6486900420105479, subsample=0.6488351818802693; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.8533615026041694, gamma=1.3071908852815766, learning_rate=0.09429376615192915, max_depth=6, min_child_weight=5.33207958296293, n_estimators=730, reg_lambda=0.6486900420105479, subsample=0.6488351818802693; total time=  14.3s\n",
      "[CV] END colsample_bytree=0.8533615026041694, gamma=1.3071908852815766, learning_rate=0.09429376615192915, max_depth=6, min_child_weight=5.33207958296293, n_estimators=730, reg_lambda=0.6486900420105479, subsample=0.6488351818802693; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.8533615026041694, gamma=1.3071908852815766, learning_rate=0.09429376615192915, max_depth=6, min_child_weight=5.33207958296293, n_estimators=730, reg_lambda=0.6486900420105479, subsample=0.6488351818802693; total time=  24.4s\n",
      "[CV] END colsample_bytree=0.7425191352307899, gamma=1.360242662318631, learning_rate=0.05177057995077082, max_depth=5, min_child_weight=5.4168623090100505, n_estimators=1027, reg_lambda=0.705137712668338, subsample=0.7219125032632117; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.7425191352307899, gamma=1.360242662318631, learning_rate=0.05177057995077082, max_depth=5, min_child_weight=5.4168623090100505, n_estimators=1027, reg_lambda=0.705137712668338, subsample=0.7219125032632117; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7425191352307899, gamma=1.360242662318631, learning_rate=0.05177057995077082, max_depth=5, min_child_weight=5.4168623090100505, n_estimators=1027, reg_lambda=0.705137712668338, subsample=0.7219125032632117; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.7425191352307899, gamma=1.360242662318631, learning_rate=0.05177057995077082, max_depth=5, min_child_weight=5.4168623090100505, n_estimators=1027, reg_lambda=0.705137712668338, subsample=0.7219125032632117; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.7425191352307899, gamma=1.360242662318631, learning_rate=0.05177057995077082, max_depth=5, min_child_weight=5.4168623090100505, n_estimators=1027, reg_lambda=0.705137712668338, subsample=0.7219125032632117; total time=  27.6s\n",
      "[CV] END colsample_bytree=0.6658623412571767, gamma=0.801134129063163, learning_rate=0.06878639770871867, max_depth=3, min_child_weight=2.9589229386694624, n_estimators=1083, reg_lambda=0.48825104449554835, subsample=0.6673164168691722; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6658623412571767, gamma=0.801134129063163, learning_rate=0.06878639770871867, max_depth=3, min_child_weight=2.9589229386694624, n_estimators=1083, reg_lambda=0.48825104449554835, subsample=0.6673164168691722; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.6658623412571767, gamma=0.801134129063163, learning_rate=0.06878639770871867, max_depth=3, min_child_weight=2.9589229386694624, n_estimators=1083, reg_lambda=0.48825104449554835, subsample=0.6673164168691722; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.6658623412571767, gamma=0.801134129063163, learning_rate=0.06878639770871867, max_depth=3, min_child_weight=2.9589229386694624, n_estimators=1083, reg_lambda=0.48825104449554835, subsample=0.6673164168691722; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.6658623412571767, gamma=0.801134129063163, learning_rate=0.06878639770871867, max_depth=3, min_child_weight=2.9589229386694624, n_estimators=1083, reg_lambda=0.48825104449554835, subsample=0.6673164168691722; total time=  20.3s\n",
      "[CV] END colsample_bytree=0.687505687829228, gamma=0.8371530030260117, learning_rate=0.06230689368464327, max_depth=8, min_child_weight=9.774256661767685, n_estimators=963, reg_lambda=0.4937521256772024, subsample=0.8785217091359153; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.687505687829228, gamma=0.8371530030260117, learning_rate=0.06230689368464327, max_depth=8, min_child_weight=9.774256661767685, n_estimators=963, reg_lambda=0.4937521256772024, subsample=0.8785217091359153; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.687505687829228, gamma=0.8371530030260117, learning_rate=0.06230689368464327, max_depth=8, min_child_weight=9.774256661767685, n_estimators=963, reg_lambda=0.4937521256772024, subsample=0.8785217091359153; total time=  24.5s\n",
      "[CV] END colsample_bytree=0.687505687829228, gamma=0.8371530030260117, learning_rate=0.06230689368464327, max_depth=8, min_child_weight=9.774256661767685, n_estimators=963, reg_lambda=0.4937521256772024, subsample=0.8785217091359153; total time=  32.2s\n",
      "[CV] END colsample_bytree=0.687505687829228, gamma=0.8371530030260117, learning_rate=0.06230689368464327, max_depth=8, min_child_weight=9.774256661767685, n_estimators=963, reg_lambda=0.4937521256772024, subsample=0.8785217091359153; total time=  39.6s\n",
      "\n",
      "=== [cat] RandomizedSearch 시작 (n_iter=20) ===\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END bagging_temperature=0.3745401188473625, depth=8, iterations=770, l2_leaf_reg=6.123957592679836, learning_rate=0.08387926357773329, random_strength=0.15601864044243652, rsm=0.662397808134481; total time=  53.5s\n",
      "[CV] END bagging_temperature=0.3745401188473625, depth=8, iterations=770, l2_leaf_reg=6.123957592679836, learning_rate=0.08387926357773329, random_strength=0.15601864044243652, rsm=0.662397808134481; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3745401188473625, depth=8, iterations=770, l2_leaf_reg=6.123957592679836, learning_rate=0.08387926357773329, random_strength=0.15601864044243652, rsm=0.662397808134481; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.3745401188473625, depth=8, iterations=770, l2_leaf_reg=6.123957592679836, learning_rate=0.08387926357773329, random_strength=0.15601864044243652, rsm=0.662397808134481; total time= 1.7min\n",
      "[CV] END bagging_temperature=0.3745401188473625, depth=8, iterations=770, l2_leaf_reg=6.123957592679836, learning_rate=0.08387926357773329, random_strength=0.15601864044243652, rsm=0.662397808134481; total time= 2.0min\n",
      "[CV] END bagging_temperature=0.05808361216819946, depth=8, iterations=599, l2_leaf_reg=2.0000677254535857, learning_rate=0.08857996256539676, random_strength=0.056411579027100256, rsm=0.8887995089067299; total time=  50.8s\n",
      "[CV] END bagging_temperature=0.05808361216819946, depth=8, iterations=599, l2_leaf_reg=2.0000677254535857, learning_rate=0.08857996256539676, random_strength=0.056411579027100256, rsm=0.8887995089067299; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.05808361216819946, depth=8, iterations=599, l2_leaf_reg=2.0000677254535857, learning_rate=0.08857996256539676, random_strength=0.056411579027100256, rsm=0.8887995089067299; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.05808361216819946, depth=8, iterations=599, l2_leaf_reg=2.0000677254535857, learning_rate=0.08857996256539676, random_strength=0.056411579027100256, rsm=0.8887995089067299; total time= 1.6min\n",
      "[CV] END bagging_temperature=0.05808361216819946, depth=8, iterations=599, l2_leaf_reg=2.0000677254535857, learning_rate=0.08857996256539676, random_strength=0.056411579027100256, rsm=0.8887995089067299; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.9385527090157502, depth=5, iterations=691, l2_leaf_reg=7.945480915038523, learning_rate=0.08557333586649449, random_strength=0.6116531604882809, rsm=0.6028265220878869; total time=  18.7s\n",
      "[CV] END bagging_temperature=0.9385527090157502, depth=5, iterations=691, l2_leaf_reg=7.945480915038523, learning_rate=0.08557333586649449, random_strength=0.6116531604882809, rsm=0.6028265220878869; total time=  28.0s\n",
      "[CV] END bagging_temperature=0.9385527090157502, depth=5, iterations=691, l2_leaf_reg=7.945480915038523, learning_rate=0.08557333586649449, random_strength=0.6116531604882809, rsm=0.6028265220878869; total time=  37.2s\n",
      "[CV] END bagging_temperature=0.9385527090157502, depth=5, iterations=691, l2_leaf_reg=7.945480915038523, learning_rate=0.08557333586649449, random_strength=0.6116531604882809, rsm=0.6028265220878869; total time=  46.8s\n",
      "[CV] END bagging_temperature=0.9385527090157502, depth=5, iterations=691, l2_leaf_reg=7.945480915038523, learning_rate=0.08557333586649449, random_strength=0.6116531604882809, rsm=0.6028265220878869; total time=  56.8s\n",
      "[CV] END bagging_temperature=0.023062425041415757, depth=6, iterations=558, l2_leaf_reg=3.7990268020067886, learning_rate=0.034199909689225386, random_strength=0.9737555188414592, rsm=0.6931085361721216; total time=  21.5s\n",
      "[CV] END bagging_temperature=0.023062425041415757, depth=6, iterations=558, l2_leaf_reg=3.7990268020067886, learning_rate=0.034199909689225386, random_strength=0.9737555188414592, rsm=0.6931085361721216; total time=  30.4s\n",
      "[CV] END bagging_temperature=0.023062425041415757, depth=6, iterations=558, l2_leaf_reg=3.7990268020067886, learning_rate=0.034199909689225386, random_strength=0.9737555188414592, rsm=0.6931085361721216; total time=  39.5s\n",
      "[CV] END bagging_temperature=0.023062425041415757, depth=6, iterations=558, l2_leaf_reg=3.7990268020067886, learning_rate=0.034199909689225386, random_strength=0.9737555188414592, rsm=0.6931085361721216; total time=  49.3s\n",
      "[CV] END bagging_temperature=0.023062425041415757, depth=6, iterations=558, l2_leaf_reg=3.7990268020067886, learning_rate=0.034199909689225386, random_strength=0.9737555188414592, rsm=0.6931085361721216; total time=  58.5s\n",
      "[CV] END bagging_temperature=0.0906064345328208, depth=6, iterations=1375, l2_leaf_reg=4.599641068895281, learning_rate=0.08331731119758382, random_strength=0.046450412719997725, rsm=0.8430179407605753; total time=  58.7s\n",
      "[CV] END bagging_temperature=0.0906064345328208, depth=6, iterations=1375, l2_leaf_reg=4.599641068895281, learning_rate=0.08331731119758382, random_strength=0.046450412719997725, rsm=0.8430179407605753; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.0906064345328208, depth=6, iterations=1375, l2_leaf_reg=4.599641068895281, learning_rate=0.08331731119758382, random_strength=0.046450412719997725, rsm=0.8430179407605753; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.0906064345328208, depth=6, iterations=1375, l2_leaf_reg=4.599641068895281, learning_rate=0.08331731119758382, random_strength=0.046450412719997725, rsm=0.8430179407605753; total time= 2.2min\n",
      "[CV] END bagging_temperature=0.0906064345328208, depth=6, iterations=1375, l2_leaf_reg=4.599641068895281, learning_rate=0.08331731119758382, random_strength=0.046450412719997725, rsm=0.8430179407605753; total time= 2.7min\n",
      "[CV] END bagging_temperature=0.17052412368729153, depth=5, iterations=887, l2_leaf_reg=7.59541228979397, learning_rate=0.08069593960609853, random_strength=0.3854165025399161, rsm=0.6063865008880857; total time=  24.1s\n",
      "[CV] END bagging_temperature=0.17052412368729153, depth=5, iterations=887, l2_leaf_reg=7.59541228979397, learning_rate=0.08069593960609853, random_strength=0.3854165025399161, rsm=0.6063865008880857; total time=  36.1s\n",
      "[CV] END bagging_temperature=0.17052412368729153, depth=5, iterations=887, l2_leaf_reg=7.59541228979397, learning_rate=0.08069593960609853, random_strength=0.3854165025399161, rsm=0.6063865008880857; total time=  47.8s\n",
      "[CV] END bagging_temperature=0.17052412368729153, depth=5, iterations=887, l2_leaf_reg=7.59541228979397, learning_rate=0.08069593960609853, random_strength=0.3854165025399161, rsm=0.6063865008880857; total time=  59.6s\n",
      "[CV] END bagging_temperature=0.17052412368729153, depth=5, iterations=887, l2_leaf_reg=7.59541228979397, learning_rate=0.08069593960609853, random_strength=0.3854165025399161, rsm=0.6063865008880857; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.230893825622149, depth=7, iterations=866, l2_leaf_reg=5.782844631778207, learning_rate=0.08489969920043589, random_strength=0.8331949117361643, rsm=0.6693458614031088; total time=  43.5s\n",
      "[CV] END bagging_temperature=0.230893825622149, depth=7, iterations=866, l2_leaf_reg=5.782844631778207, learning_rate=0.08489969920043589, random_strength=0.8331949117361643, rsm=0.6693458614031088; total time=  59.6s\n",
      "[CV] END bagging_temperature=0.230893825622149, depth=7, iterations=866, l2_leaf_reg=5.782844631778207, learning_rate=0.08489969920043589, random_strength=0.8331949117361643, rsm=0.6693458614031088; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.230893825622149, depth=7, iterations=866, l2_leaf_reg=5.782844631778207, learning_rate=0.08489969920043589, random_strength=0.8331949117361643, rsm=0.6693458614031088; total time= 1.5min\n",
      "[CV] END bagging_temperature=0.230893825622149, depth=7, iterations=866, l2_leaf_reg=5.782844631778207, learning_rate=0.08489969920043589, random_strength=0.8331949117361643, rsm=0.6693458614031088; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.3910606075732408, depth=5, iterations=1371, l2_leaf_reg=6.287529872223567, learning_rate=0.06826402870421203, random_strength=0.20794166286818883, rsm=0.8270801311279966; total time=  44.4s\n",
      "[CV] END bagging_temperature=0.3910606075732408, depth=5, iterations=1371, l2_leaf_reg=6.287529872223567, learning_rate=0.06826402870421203, random_strength=0.20794166286818883, rsm=0.8270801311279966; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.3910606075732408, depth=5, iterations=1371, l2_leaf_reg=6.287529872223567, learning_rate=0.06826402870421203, random_strength=0.20794166286818883, rsm=0.8270801311279966; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.3910606075732408, depth=5, iterations=1371, l2_leaf_reg=6.287529872223567, learning_rate=0.06826402870421203, random_strength=0.20794166286818883, rsm=0.8270801311279966; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.3910606075732408, depth=5, iterations=1371, l2_leaf_reg=6.287529872223567, learning_rate=0.06826402870421203, random_strength=0.20794166286818883, rsm=0.8270801311279966; total time= 2.1min\n",
      "[CV] END bagging_temperature=0.03131329245555858, depth=5, iterations=1229, l2_leaf_reg=4.14827893358836, learning_rate=0.06556352124016329, random_strength=0.9266588657937942, rsm=0.8909087983425683; total time=  41.7s\n",
      "[CV] END bagging_temperature=0.03131329245555858, depth=5, iterations=1229, l2_leaf_reg=4.14827893358836, learning_rate=0.06556352124016329, random_strength=0.9266588657937942, rsm=0.8909087983425683; total time= 1.0min\n",
      "[CV] END bagging_temperature=0.03131329245555858, depth=5, iterations=1229, l2_leaf_reg=4.14827893358836, learning_rate=0.06556352124016329, random_strength=0.9266588657937942, rsm=0.8909087983425683; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.03131329245555858, depth=5, iterations=1229, l2_leaf_reg=4.14827893358836, learning_rate=0.06556352124016329, random_strength=0.9266588657937942, rsm=0.8909087983425683; total time= 1.6min\n",
      "[CV] END bagging_temperature=0.03131329245555858, depth=5, iterations=1229, l2_leaf_reg=4.14827893358836, learning_rate=0.06556352124016329, random_strength=0.9266588657937942, rsm=0.8909087983425683; total time= 2.0min\n",
      "[CV] END bagging_temperature=0.3265407688058354, depth=7, iterations=1201, l2_leaf_reg=3.2773123153428503, learning_rate=0.06498095607205337, random_strength=0.2713490317738959, rsm=0.9314950036607718; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3265407688058354, depth=7, iterations=1201, l2_leaf_reg=3.2773123153428503, learning_rate=0.06498095607205337, random_strength=0.2713490317738959, rsm=0.9314950036607718; total time= 1.7min\n",
      "[CV] END bagging_temperature=0.3265407688058354, depth=7, iterations=1201, l2_leaf_reg=3.2773123153428503, learning_rate=0.06498095607205337, random_strength=0.2713490317738959, rsm=0.9314950036607718; total time= 2.1min\n",
      "[CV] END bagging_temperature=0.3265407688058354, depth=7, iterations=1201, l2_leaf_reg=3.2773123153428503, learning_rate=0.06498095607205337, random_strength=0.2713490317738959, rsm=0.9314950036607718; total time= 2.5min\n",
      "[CV] END bagging_temperature=0.3265407688058354, depth=7, iterations=1201, l2_leaf_reg=3.2773123153428503, learning_rate=0.06498095607205337, random_strength=0.2713490317738959, rsm=0.9314950036607718; total time= 3.0min\n",
      "[CV] END bagging_temperature=0.3567533266935893, depth=7, iterations=687, l2_leaf_reg=4.798872582107739, learning_rate=0.04268318024772864, random_strength=0.8021969807540397, rsm=0.6298202574719083; total time=  32.6s\n",
      "[CV] END bagging_temperature=0.3567533266935893, depth=7, iterations=687, l2_leaf_reg=4.798872582107739, learning_rate=0.04268318024772864, random_strength=0.8021969807540397, rsm=0.6298202574719083; total time=  45.4s\n",
      "[CV] END bagging_temperature=0.3567533266935893, depth=7, iterations=687, l2_leaf_reg=4.798872582107739, learning_rate=0.04268318024772864, random_strength=0.8021969807540397, rsm=0.6298202574719083; total time=  57.8s\n",
      "[CV] END bagging_temperature=0.3567533266935893, depth=7, iterations=687, l2_leaf_reg=4.798872582107739, learning_rate=0.04268318024772864, random_strength=0.8021969807540397, rsm=0.6298202574719083; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3567533266935893, depth=7, iterations=687, l2_leaf_reg=4.798872582107739, learning_rate=0.04268318024772864, random_strength=0.8021969807540397, rsm=0.6298202574719083; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.9868869366005173, depth=4, iterations=1147, l2_leaf_reg=1.0386548198652168, learning_rate=0.10339152856093507, random_strength=0.7068573438476171, rsm=0.8916028672163949; total time=  30.5s\n",
      "[CV] END bagging_temperature=0.9868869366005173, depth=4, iterations=1147, l2_leaf_reg=1.0386548198652168, learning_rate=0.10339152856093507, random_strength=0.7068573438476171, rsm=0.8916028672163949; total time=  45.3s\n",
      "[CV] END bagging_temperature=0.9868869366005173, depth=4, iterations=1147, l2_leaf_reg=1.0386548198652168, learning_rate=0.10339152856093507, random_strength=0.7068573438476171, rsm=0.8916028672163949; total time= 1.0min\n",
      "[CV] END bagging_temperature=0.9868869366005173, depth=4, iterations=1147, l2_leaf_reg=1.0386548198652168, learning_rate=0.10339152856093507, random_strength=0.7068573438476171, rsm=0.8916028672163949; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.9868869366005173, depth=4, iterations=1147, l2_leaf_reg=1.0386548198652168, learning_rate=0.10339152856093507, random_strength=0.7068573438476171, rsm=0.8916028672163949; total time= 1.5min\n",
      "[CV] END bagging_temperature=0.7712703466859457, depth=8, iterations=989, l2_leaf_reg=3.509260099809908, learning_rate=0.040428215357261675, random_strength=0.8631034258755935, rsm=0.8493192507310232; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.7712703466859457, depth=8, iterations=989, l2_leaf_reg=3.509260099809908, learning_rate=0.040428215357261675, random_strength=0.8631034258755935, rsm=0.8493192507310232; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.7712703466859457, depth=8, iterations=989, l2_leaf_reg=3.509260099809908, learning_rate=0.040428215357261675, random_strength=0.8631034258755935, rsm=0.8493192507310232; total time= 2.1min\n",
      "[CV] END bagging_temperature=0.7712703466859457, depth=8, iterations=989, l2_leaf_reg=3.509260099809908, learning_rate=0.040428215357261675, random_strength=0.8631034258755935, rsm=0.8493192507310232; total time= 2.5min\n",
      "[CV] END bagging_temperature=0.7712703466859457, depth=8, iterations=989, l2_leaf_reg=3.509260099809908, learning_rate=0.040428215357261675, random_strength=0.8631034258755935, rsm=0.8493192507310232; total time= 3.1min\n",
      "[CV] END bagging_temperature=0.3308980248526492, depth=8, iterations=598, l2_leaf_reg=5.1390845139540895, learning_rate=0.054724961369105776, random_strength=0.5612434258477011, rsm=0.7531707499015159; total time=  45.2s\n",
      "[CV] END bagging_temperature=0.3308980248526492, depth=8, iterations=598, l2_leaf_reg=5.1390845139540895, learning_rate=0.054724961369105776, random_strength=0.5612434258477011, rsm=0.7531707499015159; total time=  59.1s\n",
      "[CV] END bagging_temperature=0.3308980248526492, depth=8, iterations=598, l2_leaf_reg=5.1390845139540895, learning_rate=0.054724961369105776, random_strength=0.5612434258477011, rsm=0.7531707499015159; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.3308980248526492, depth=8, iterations=598, l2_leaf_reg=5.1390845139540895, learning_rate=0.054724961369105776, random_strength=0.5612434258477011, rsm=0.7531707499015159; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.3308980248526492, depth=8, iterations=598, l2_leaf_reg=5.1390845139540895, learning_rate=0.054724961369105776, random_strength=0.5612434258477011, rsm=0.7531707499015159; total time= 1.7min\n",
      "[CV] END bagging_temperature=0.9717120953891037, depth=6, iterations=1268, l2_leaf_reg=6.052106648154113, learning_rate=0.051238642777406015, random_strength=0.25606832276132396, rsm=0.6161734358153725; total time=  48.7s\n",
      "[CV] END bagging_temperature=0.9717120953891037, depth=6, iterations=1268, l2_leaf_reg=6.052106648154113, learning_rate=0.051238642777406015, random_strength=0.25606832276132396, rsm=0.6161734358153725; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.9717120953891037, depth=6, iterations=1268, l2_leaf_reg=6.052106648154113, learning_rate=0.051238642777406015, random_strength=0.25606832276132396, rsm=0.6161734358153725; total time= 1.5min\n",
      "[CV] END bagging_temperature=0.9717120953891037, depth=6, iterations=1268, l2_leaf_reg=6.052106648154113, learning_rate=0.051238642777406015, random_strength=0.25606832276132396, rsm=0.6161734358153725; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.9717120953891037, depth=6, iterations=1268, l2_leaf_reg=6.052106648154113, learning_rate=0.051238642777406015, random_strength=0.25606832276132396, rsm=0.6161734358153725; total time= 2.1min\n",
      "[CV] END bagging_temperature=0.7106628896857874, depth=5, iterations=1053, l2_leaf_reg=4.075355513060391, learning_rate=0.048154728210185654, random_strength=0.8957635956735194, rsm=0.7901480892728447; total time=  33.3s\n",
      "[CV] END bagging_temperature=0.7106628896857874, depth=5, iterations=1053, l2_leaf_reg=4.075355513060391, learning_rate=0.048154728210185654, random_strength=0.8957635956735194, rsm=0.7901480892728447; total time=  49.5s\n",
      "[CV] END bagging_temperature=0.7106628896857874, depth=5, iterations=1053, l2_leaf_reg=4.075355513060391, learning_rate=0.048154728210185654, random_strength=0.8957635956735194, rsm=0.7901480892728447; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.7106628896857874, depth=5, iterations=1053, l2_leaf_reg=4.075355513060391, learning_rate=0.048154728210185654, random_strength=0.8957635956735194, rsm=0.7901480892728447; total time= 1.3min\n",
      "[CV] END bagging_temperature=0.7106628896857874, depth=5, iterations=1053, l2_leaf_reg=4.075355513060391, learning_rate=0.048154728210185654, random_strength=0.8957635956735194, rsm=0.7901480892728447; total time= 1.6min\n",
      "[CV] END bagging_temperature=0.5632755719763837, depth=7, iterations=1233, l2_leaf_reg=1.9753201808411298, learning_rate=0.08439756413500354, random_strength=0.5398410913016731, rsm=0.6812244898939077; total time= 1.0min\n",
      "[CV] END bagging_temperature=0.5632755719763837, depth=7, iterations=1233, l2_leaf_reg=1.9753201808411298, learning_rate=0.08439756413500354, random_strength=0.5398410913016731, rsm=0.6812244898939077; total time= 1.4min\n",
      "[CV] END bagging_temperature=0.5632755719763837, depth=7, iterations=1233, l2_leaf_reg=1.9753201808411298, learning_rate=0.08439756413500354, random_strength=0.5398410913016731, rsm=0.6812244898939077; total time= 1.8min\n",
      "[CV] END bagging_temperature=0.5632755719763837, depth=7, iterations=1233, l2_leaf_reg=1.9753201808411298, learning_rate=0.08439756413500354, random_strength=0.5398410913016731, rsm=0.6812244898939077; total time= 2.2min\n",
      "[CV] END bagging_temperature=0.5632755719763837, depth=7, iterations=1233, l2_leaf_reg=1.9753201808411298, learning_rate=0.08439756413500354, random_strength=0.5398410913016731, rsm=0.6812244898939077; total time= 2.7min\n",
      "[CV] END bagging_temperature=0.942853570557981, depth=6, iterations=742, l2_leaf_reg=2.128549010778031, learning_rate=0.11367278871083157, random_strength=0.808120379564417, rsm=0.8533615026041694; total time=  32.2s\n",
      "[CV] END bagging_temperature=0.942853570557981, depth=6, iterations=742, l2_leaf_reg=2.128549010778031, learning_rate=0.11367278871083157, random_strength=0.808120379564417, rsm=0.8533615026041694; total time=  46.0s\n",
      "[CV] END bagging_temperature=0.942853570557981, depth=6, iterations=742, l2_leaf_reg=2.128549010778031, learning_rate=0.11367278871083157, random_strength=0.808120379564417, rsm=0.8533615026041694; total time=  58.9s\n",
      "[CV] END bagging_temperature=0.942853570557981, depth=6, iterations=742, l2_leaf_reg=2.128549010778031, learning_rate=0.11367278871083157, random_strength=0.808120379564417, rsm=0.8533615026041694; total time= 1.2min\n",
      "[CV] END bagging_temperature=0.942853570557981, depth=6, iterations=742, l2_leaf_reg=2.128549010778031, learning_rate=0.11367278871083157, random_strength=0.808120379564417, rsm=0.8533615026041694; total time= 1.5min\n",
      "[CV] END bagging_temperature=0.8714605901877177, depth=7, iterations=1119, l2_leaf_reg=2.305990412202251, learning_rate=0.11033030986409799, random_strength=0.5393422419156507, rsm=0.922976062065625; total time= 1.1min\n",
      "[CV] END bagging_temperature=0.8714605901877177, depth=7, iterations=1119, l2_leaf_reg=2.305990412202251, learning_rate=0.11033030986409799, random_strength=0.5393422419156507, rsm=0.922976062065625; total time= 1.5min\n",
      "[CV] END bagging_temperature=0.8714605901877177, depth=7, iterations=1119, l2_leaf_reg=2.305990412202251, learning_rate=0.11033030986409799, random_strength=0.5393422419156507, rsm=0.922976062065625; total time= 1.9min\n",
      "[CV] END bagging_temperature=0.8714605901877177, depth=7, iterations=1119, l2_leaf_reg=2.305990412202251, learning_rate=0.11033030986409799, random_strength=0.5393422419156507, rsm=0.922976062065625; total time= 2.3min\n",
      "[CV] END bagging_temperature=0.8714605901877177, depth=7, iterations=1119, l2_leaf_reg=2.305990412202251, learning_rate=0.11033030986409799, random_strength=0.5393422419156507, rsm=0.922976062065625; total time= 2.8min\n",
      "[CV] END bagging_temperature=0.8960912999234932, depth=4, iterations=884, l2_leaf_reg=2.595546137793592, learning_rate=0.06843970097636307, random_strength=0.8180147659224931, rsm=0.9442922333025374; total time=  23.9s\n",
      "[CV] END bagging_temperature=0.8960912999234932, depth=4, iterations=884, l2_leaf_reg=2.595546137793592, learning_rate=0.06843970097636307, random_strength=0.8180147659224931, rsm=0.9442922333025374; total time=  35.1s\n",
      "[CV] END bagging_temperature=0.8960912999234932, depth=4, iterations=884, l2_leaf_reg=2.595546137793592, learning_rate=0.06843970097636307, random_strength=0.8180147659224931, rsm=0.9442922333025374; total time=  46.5s\n",
      "[CV] END bagging_temperature=0.8960912999234932, depth=4, iterations=884, l2_leaf_reg=2.595546137793592, learning_rate=0.06843970097636307, random_strength=0.8180147659224931, rsm=0.9442922333025374; total time=  58.1s\n",
      "[CV] END bagging_temperature=0.8960912999234932, depth=4, iterations=884, l2_leaf_reg=2.595546137793592, learning_rate=0.06843970097636307, random_strength=0.8180147659224931, rsm=0.9442922333025374; total time= 1.2min\n",
      "\n",
      "=== [hgb] RandomizedSearch 시작 (n_iter=30) ===\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   3.1s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   5.8s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   3.4s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   4.7s\n",
      "[CV] END l2_regularization=0.5, learning_rate=0.136551724137931, max_bins=127, max_leaf_nodes=29, min_samples_leaf=53; total time=   6.7s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   5.6s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   7.0s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   6.7s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   4.7s\n",
      "[CV] END l2_regularization=1.4000000000000001, learning_rate=0.14551724137931032, max_bins=127, max_leaf_nodes=42, min_samples_leaf=32; total time=   5.9s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  10.3s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  10.9s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  11.7s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  12.4s\n",
      "[CV] END l2_regularization=1.7000000000000002, learning_rate=0.033448275862068964, max_bins=63, max_leaf_nodes=48, min_samples_leaf=44; total time=  13.2s\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'max_bins' parameter of HistGradientBoostingRegressor must be an int in the range [2, 255]. Got 511 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m n_iter = N_ITER_MAP.get(name, \u001b[32m20\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] RandomizedSearch 시작 (n_iter=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m best, summary, search = \u001b[43mtune_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparam_dist\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m ...\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtune_one\u001b[39m\u001b[34m(name, est, param_dist, X, y, n_iter)\u001b[39m\n\u001b[32m      7\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33mcat_features\u001b[39m\u001b[33m\"\u001b[39m] = cat_idx\n\u001b[32m      9\u001b[39m search = RandomizedSearchCV(\n\u001b[32m     10\u001b[39m     estimator=est,\n\u001b[32m     11\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     error_score=\u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 실패 파라미터 조합은 즉시 에러로 알려줌\u001b[39;00m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m best = search.best_estimator_\n\u001b[32m     24\u001b[39m res = pd.DataFrame(search.cv_results_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1382\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1377\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1378\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1379\u001b[39m )\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:436\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    430\u001b[39m \n\u001b[32m    431\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'max_bins' parameter of HistGradientBoostingRegressor must be an int in the range [2, 255]. Got 511 instead."
     ]
    }
   ],
   "source": [
    "N_ITER_MAP = {\"lgbm\": 40, \"xgb\": 20, \"cat\": 20, \"hgb\": 30, \"rf\": 15}\n",
    "\n",
    "for name, spec in MODEL_SPECS.items():\n",
    "    n_iter = N_ITER_MAP.get(name, 20)\n",
    "    print(f\"\\n=== [{name}] RandomizedSearch 시작 (n_iter={n_iter}) ===\")\n",
    "    best, summary, search = tune_one(name, spec[\"est\"], spec[\"param_dist\"], X_tr, y_tr, n_iter=n_iter)\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78ad62a6-480a-4838-b91d-3c67a8dde3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WIN] search  score=-276.281829\n",
      "best_params_ {'bagging_temperature': np.float64(0.3567533266935893), 'depth': 7, 'iterations': 687, 'l2_leaf_reg': np.float64(4.798872582107739), 'learning_rate': np.float64(0.04268318024772864), 'random_strength': np.float64(0.8021969807540397), 'rsm': np.float64(0.6298202574719083)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['final_winner.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0) 후보 검색: 메모리 내에서 best_estimator_/best_score_ 가진 객체 자동 수집\n",
    "def _is_fitted_search(obj):\n",
    "    return hasattr(obj, \"best_score_\") and hasattr(obj, \"best_estimator_\")\n",
    "\n",
    "searches = {name: obj for name, obj in globals().items() if _is_fitted_search(obj)}\n",
    "\n",
    "# 흔한 별칭도 추가로 시도 (있으면 딕트에 합침)\n",
    "for alias in [\"lgbm_rs\",\"rs_lgbm\",\"xgb_rs\",\"rs_xgb\",\"cat_rs\",\"rs_cat\",\"gbm_rs\",\"hgb_rs\",\"rf_rs\"]:\n",
    "    if alias in globals() and _is_fitted_search(globals()[alias]):\n",
    "        searches[alias] = globals()[alias]\n",
    "\n",
    "if not searches:\n",
    "    raise RuntimeError(\"학습 완료된 검색 객체를 못 찾았습니다. (커널 리셋/변수명 확인)\")\n",
    "\n",
    "# 1) 우승자 고르기 (같은 스코어링 가정)\n",
    "winner_key = max(searches, key=lambda k: searches[k].best_score_)\n",
    "winner_rs  = searches[winner_key]\n",
    "winner_model = winner_rs.best_estimator_  # refit=True라면 이미 전체 데이터로 재학습된 모델\n",
    "\n",
    "print(f\"[WIN] {winner_key}  score={winner_rs.best_score_:.6f}\")\n",
    "print(\"best_params_\", winner_rs.best_params_)\n",
    "\n",
    "# 2) refit=False로 돌렸다면 직접 재학습\n",
    "if winner_model is None:\n",
    "    Est = type(winner_rs.estimator)\n",
    "    winner_model = Est(**winner_rs.best_params_).fit(X, y)\n",
    "\n",
    "# 3) 저장\n",
    "from joblib import dump\n",
    "dump(winner_model, \"final_winner.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe2a770b-2832-4669-bd34-cfc8f920ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: CatBoostRegressor | Using estimator: CatBoostRegressor\n",
      "[data] TARGET='전력소비량(kWh)', X.shape=(204000, 17)\n",
      "[warn] feature 불일치 \n",
      " - model missing: ['cons_lag1', 'cons_lag_24h', 'cons_lag_48h', 'cons_lag_72h', 'cons_lag_168h', 'cons_mean_24h', 'cons_samehour_mean_7d', 'cons_std_24h', 'delta_1h', 'delta_7d', 'CDD', 'CDD_x_rad', 'CDD_humid_adj', 'weekday', 'is_weekend', 'is_holiday', 'has_pv', 'has_ess', 'has_pcs', 'is_daylight', 'is_offpeak', 'is_peak', 'ess_charge_potential', 'ess_discharge_potential', 'log1p_태양광용량(kW)', 'log1p_ESS저장용량(kWh)', 'log1p_PCS용량(kW)', 'ess_to_load_lag_ratio', 'month', 'hour', 'dayofyear', 'cons_lag1_per_m2', 'cons_mean24_per_m2', 'CDD_x_rad_area'] \n",
      " - data extras: ['건물유형', '날짜', '시간']\n",
      "(pretrained predict 실패 → 동일 파라미터 새 모델로 재학습)\n",
      "  catboost/libs/data/model_dataset_compatibility.cpp:81: At position 7 should be feature with name 연면적(m2) (found 건물유형).\n",
      "[REG] RMSE=444.0766  MAE=273.8381  R2=0.9854\n",
      "\n",
      "Top feature importances:\n",
      "건물유형            37.700752\n",
      "건물번호            15.929366\n",
      "냉방면적(m2)        14.800325\n",
      "연면적(m2)         13.352256\n",
      "태양광용량(kW)        8.545996\n",
      "PCS용량(kW)        1.968462\n",
      "시간               1.712765\n",
      "날짜               1.506848\n",
      "일사(MJ/m2)        1.420652\n",
      "hour_cos         1.236204\n",
      "기온(°C)           0.828190\n",
      "hour_sin         0.472288\n",
      "ESS저장용량(kWh)     0.413033\n",
      "습도(%)            0.051677\n",
      "일조(hr)           0.049100\n",
      "강수량(mm)          0.006341\n",
      "풍속(m/s)          0.005745\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 0) 모델 로드\n",
    "obj = load(\"final_winner.joblib\")\n",
    "est = obj if hasattr(obj, \"predict\") else getattr(obj, \"best_estimator_\", obj)\n",
    "print(\"Loaded:\", type(obj).__name__, \"| Using estimator:\", type(est).__name__)\n",
    "\n",
    "# 1) 데이터 준비 (df 기준, 타깃 명시)\n",
    "assert 'df' in globals(), \"df 변수가 필요합니다.\"\n",
    "TARGET = \"전력소비량(kWh)\" if \"전력소비량(kWh)\" in df.columns else df.columns[-1]\n",
    "y = df[TARGET]\n",
    "X = df.drop(columns=[TARGET]).copy()\n",
    "print(f\"[data] TARGET='{TARGET}', X.shape={X.shape}\")\n",
    "\n",
    "# 2) 모델이 기억한 피처 순서에 맞춰 재정렬\n",
    "if hasattr(est, \"feature_names_\"):\n",
    "    fn = list(est.feature_names_)\n",
    "    missing = [c for c in fn if c not in X.columns]\n",
    "    extras  = [c for c in X.columns if c not in fn]\n",
    "    if missing or extras:\n",
    "        print(\"[warn] feature 불일치\",\n",
    "              \"\\n - model missing:\", missing,\n",
    "              \"\\n - data extras:\", extras)\n",
    "        # 불일치가 있으면 예측 실패 가능성↑ → 새 학습으로 폴백될 수 있음\n",
    "    else:\n",
    "        X = X[fn]  # 순서 맞추기\n",
    "        print(\"[info] 컬럼 순서 모델에 맞춰 정렬 완료.\")\n",
    "\n",
    "# 3) 홀드아웃 분할\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) 예측 (실패 시 동일 파라미터 새 모델 만들어 학습 후 예측)\n",
    "def predict_or_refit(model, X_te, X_tr, y_tr):\n",
    "    try:\n",
    "        return model.predict(X_te), model\n",
    "    except Exception as e:\n",
    "        print(\"(pretrained predict 실패 → 동일 파라미터 새 모델로 재학습)\\n \", e)\n",
    "        new_model = type(model)(**model.get_params())\n",
    "        new_model.fit(X_tr, y_tr)\n",
    "        return new_model.predict(X_te), new_model\n",
    "\n",
    "y_pred, est = predict_or_refit(est, X_te, X_tr, y_tr)\n",
    "\n",
    "# 5) 회귀 지표 (버전 호환: RMSE = sqrt(MSE))\n",
    "rmse = mean_squared_error(y_te, y_pred) ** 0.5\n",
    "mae  = mean_absolute_error(y_te, y_pred)\n",
    "r2   = r2_score(y_te, y_pred)\n",
    "print(f\"[REG] RMSE={rmse:.4f}  MAE={mae:.4f}  R2={r2:.4f}\")\n",
    "\n",
    "# 6) 중요도(가능하면 상위 20개)\n",
    "try:\n",
    "    if hasattr(est, \"get_feature_importance\"):\n",
    "        fi = pd.Series(est.get_feature_importance(), index=X.columns).sort_values(ascending=False).head(20)\n",
    "        print(\"\\nTop feature importances:\")\n",
    "        print(fi)\n",
    "except Exception:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b82306d-9a7e-4229-b801-19aa6fecc4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 3828.2641116\ttest: 2397.2452595\tbest: 2397.2452595 (0)\ttotal: 14.8ms\tremaining: 10.1s\n",
      "100:\tlearn: 217.9493224\ttest: 149.7434810\tbest: 149.7434810 (100)\ttotal: 1.39s\tremaining: 8.06s\n",
      "200:\tlearn: 137.7667311\ttest: 93.5256631\tbest: 93.5256631 (200)\ttotal: 2.7s\tremaining: 6.53s\n",
      "300:\tlearn: 108.2132538\ttest: 75.3806850\tbest: 75.3806850 (300)\ttotal: 4.05s\tremaining: 5.2s\n",
      "400:\tlearn: 91.1485818\ttest: 63.9402526\tbest: 63.9389206 (399)\ttotal: 5.39s\tremaining: 3.85s\n",
      "500:\tlearn: 80.0228457\ttest: 58.3351909\tbest: 58.2957086 (499)\ttotal: 6.78s\tremaining: 2.52s\n",
      "600:\tlearn: 72.3833507\ttest: 54.7263474\tbest: 54.7263474 (600)\ttotal: 8.09s\tremaining: 1.16s\n",
      "686:\tlearn: 67.2343403\ttest: 52.4991448\tbest: 52.4826659 (678)\ttotal: 9.27s\tremaining: 0us\n",
      "\n",
      "bestTest = 52.48266587\n",
      "bestIteration = 678\n",
      "\n",
      "Shrink model to first 679 iterations.\n",
      "[WITH engineered feats] RMSE=52.4827  MAE=35.6911  R2=0.9990\n",
      "saved -> cat_w_engineered_feats.joblib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "from joblib import dump\n",
    "\n",
    "BASE_TEMP = 26.0  # CDD 기준온도\n",
    "\n",
    "def build_features(raw):\n",
    "    df2 = raw.copy()\n",
    "\n",
    "    # 0) 시간키 만들기\n",
    "    if not np.issubdtype(df2[\"날짜\"].dtype, np.datetime64):\n",
    "        df2[\"날짜\"] = pd.to_datetime(df2[\"날짜\"])\n",
    "    if \"시간\" in df2.columns:\n",
    "        df2[\"dt\"] = df2[\"날짜\"] + pd.to_timedelta(df2[\"시간\"], unit=\"h\")\n",
    "    else:\n",
    "        # '날짜'가 이미 시간까지 포함이면 그대로 사용\n",
    "        df2[\"dt\"] = pd.to_datetime(df2[\"날짜\"])\n",
    "        df2[\"시간\"] = df2[\"dt\"].dt.hour\n",
    "\n",
    "    # 1) 기본 시간 파생\n",
    "    df2[\"month\"]     = df2[\"dt\"].dt.month\n",
    "    df2[\"hour\"]      = df2[\"dt\"].dt.hour\n",
    "    df2[\"dayofyear\"] = df2[\"dt\"].dt.dayofyear\n",
    "    df2[\"weekday\"]   = df2[\"dt\"].dt.weekday\n",
    "    df2[\"is_weekend\"] = (df2[\"weekday\"] >= 5).astype(int)\n",
    "    # 휴일 정보가 없으면 0으로 둠 (있으면 병합해 1로 표시)\n",
    "    df2[\"is_holiday\"] = 0\n",
    "\n",
    "    # 2) CDD류\n",
    "    if \"기온(°C)\" in df2.columns:\n",
    "        cdd = (df2[\"기온(°C)\"] - BASE_TEMP).clip(lower=0)\n",
    "        df2[\"CDD\"] = cdd\n",
    "        if \"일사(MJ/m2)\" in df2.columns:\n",
    "            df2[\"CDD_x_rad\"] = cdd * df2[\"일사(MJ/m2)\"]\n",
    "        else:\n",
    "            df2[\"CDD_x_rad\"] = 0.0\n",
    "        if \"습도(%)\" in df2.columns:\n",
    "            # 간단 가중 (습도 영향 0.3 배수)\n",
    "            df2[\"CDD_humid_adj\"] = cdd * (1 + 0.3 * (df2[\"습도(%)\"]/100.0))\n",
    "        else:\n",
    "            df2[\"CDD_humid_adj\"] = cdd\n",
    "    else:\n",
    "        df2[[\"CDD\",\"CDD_x_rad\",\"CDD_humid_adj\"]] = 0.0\n",
    "\n",
    "    # 3) 설비 유무/로그 변환\n",
    "    for col, logcol, flag in [\n",
    "        (\"태양광용량(kW)\", \"log1p_태양광용량(kW)\", \"has_pv\"),\n",
    "        (\"ESS저장용량(kWh)\", \"log1p_ESS저장용량(kWh)\", \"has_ess\"),\n",
    "        (\"PCS용량(kW)\", \"log1p_PCS용량(kW)\", \"has_pcs\"),\n",
    "    ]:\n",
    "        if col in df2.columns:\n",
    "            df2[logcol] = np.log1p(df2[col].fillna(0))\n",
    "            df2[flag]   = (df2[col].fillna(0) > 0).astype(int)\n",
    "        else:\n",
    "            df2[logcol] = 0.0\n",
    "            df2[flag]   = 0\n",
    "\n",
    "    # 4) 주간/야간/일사 기반 플래그\n",
    "    if \"일사(MJ/m2)\" in df2.columns:\n",
    "        df2[\"is_daylight\"] = (df2[\"일사(MJ/m2)\"] > 0).astype(int)\n",
    "    else:\n",
    "        df2[\"is_daylight\"] = df2[\"hour\"].between(8, 17).astype(int)\n",
    "\n",
    "    # TOU(요금제) 정보 없으니 기본값 0\n",
    "    df2[\"is_offpeak\"] = 0\n",
    "    df2[\"is_peak\"]    = 0\n",
    "\n",
    "    # 5) 소비량 랙/롤링 (건물별 시계열)\n",
    "    tgt = \"전력소비량(kWh)\"\n",
    "    df2 = df2.sort_values([\"건물번호\",\"dt\"]).copy()\n",
    "\n",
    "    def _group_feats(g):\n",
    "        g[\"cons_lag1\"]      = g[tgt].shift(1)\n",
    "        g[\"cons_lag_24h\"]   = g[tgt].shift(24)\n",
    "        g[\"cons_lag_48h\"]   = g[tgt].shift(48)\n",
    "        g[\"cons_lag_72h\"]   = g[tgt].shift(72)\n",
    "        g[\"cons_lag_168h\"]  = g[tgt].shift(168)\n",
    "\n",
    "        g[\"cons_mean_24h\"]  = g[tgt].shift(1).rolling(24).mean()\n",
    "        g[\"cons_std_24h\"]   = g[tgt].shift(1).rolling(24).std()\n",
    "\n",
    "        # 지난 7일 같은 시각 평균: 24,48,...,168h 랙의 평균\n",
    "        samehour_lags = [24,48,72,96,120,144,168]\n",
    "        g[\"cons_samehour_mean_7d\"] = np.nanmean([g[tgt].shift(k) for k in samehour_lags], axis=0)\n",
    "\n",
    "        g[\"delta_1h\"] = g[tgt] - g[\"cons_lag1\"]\n",
    "        g[\"delta_7d\"] = g[tgt] - g[\"cons_lag_168h\"]\n",
    "\n",
    "        if \"연면적(m2)\" in g.columns:\n",
    "            g[\"cons_lag1_per_m2\"]   = g[\"cons_lag1\"] / g[\"연면적(m2)\"].replace(0,np.nan)\n",
    "            g[\"cons_mean24_per_m2\"] = g[\"cons_mean_24h\"] / g[\"연면적(m2)\"].replace(0,np.nan)\n",
    "        else:\n",
    "            g[\"cons_lag1_per_m2\"] = g[\"cons_mean24_per_m2\"] = np.nan\n",
    "\n",
    "        # ESS 관련 간단 파생\n",
    "        if \"ESS저장용량(kWh)\" in g.columns:\n",
    "            g[\"ess_to_load_lag_ratio\"] = g[\"ESS저장용량(kWh)\"] / (g[\"cons_lag1\"].abs() + 1e-3)\n",
    "        else:\n",
    "            g[\"ess_to_load_lag_ratio\"] = 0.0\n",
    "\n",
    "        return g\n",
    "\n",
    "    df2 = df2.groupby(\"건물번호\", group_keys=False).apply(_group_feats)\n",
    "\n",
    "    # 면적 보정된 CDD*일사\n",
    "    if {\"CDD_x_rad\",\"연면적(m2)\"} <= set(df2.columns):\n",
    "        df2[\"CDD_x_rad_area\"] = df2[\"CDD_x_rad\"] * df2[\"연면적(m2)\"]\n",
    "    else:\n",
    "        df2[\"CDD_x_rad_area\"] = 0.0\n",
    "\n",
    "    # 6) 초기 NA 제거 (시계열 랙/롤링으로 생긴 앞부분)\n",
    "    df2 = df2.dropna(subset=[\n",
    "        \"cons_lag1\",\"cons_lag_24h\",\"cons_lag_168h\",\"cons_mean_24h\",\"cons_std_24h\",\n",
    "        \"cons_samehour_mean_7d\"\n",
    "    ])\n",
    "\n",
    "    return df2\n",
    "\n",
    "# === 피처 생성 → 학습/평가 ===\n",
    "df_feat = build_features(df)\n",
    "\n",
    "TARGET = \"전력소비량(kWh)\"\n",
    "y = df_feat[TARGET]\n",
    "# 모델 missing에 있었던 피처들을 최대한 포함 + 원본 주요 수치도 포함\n",
    "feature_cols = [c for c in df_feat.columns if c not in [TARGET, \"dt\", \"날짜\"]]\n",
    "\n",
    "X = df_feat[feature_cols]\n",
    "\n",
    "# 시간 정렬 후 홀드아웃 분할(80/20)\n",
    "df_feat = df_feat.sort_values([\"건물번호\",\"dt\"])\n",
    "split_idx = int(len(df_feat)*0.8)\n",
    "X_tr, X_te = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_tr, y_te = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# CatBoost 하이퍼파라미터: 랜덤서치 우승 세트\n",
    "params = dict(\n",
    "    bagging_temperature=0.3567533266935893,\n",
    "    depth=7,\n",
    "    iterations=687,\n",
    "    l2_leaf_reg=4.798872582107739,\n",
    "    learning_rate=0.04268318024772864,\n",
    "    random_strength=0.8021969807540397,\n",
    "    rsm=0.6298202574719083,\n",
    "    loss_function=\"RMSE\",\n",
    "    eval_metric=\"RMSE\",\n",
    "    verbose=100,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# 범주형 지정(문자/카테고리형)\n",
    "cat_cols = X_tr.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "\n",
    "est2 = CatBoostRegressor(**params)\n",
    "est2.fit(X_tr, y_tr, cat_features=cat_cols, eval_set=(X_te, y_te))\n",
    "\n",
    "y_hat = est2.predict(X_te)\n",
    "rmse = mean_squared_error(y_te, y_hat) ** 0.5\n",
    "mae  = mean_absolute_error(y_te, y_hat)\n",
    "r2   = r2_score(y_te, y_hat)\n",
    "print(f\"[WITH engineered feats] RMSE={rmse:.4f}  MAE={mae:.4f}  R2={r2:.4f}\")\n",
    "\n",
    "# 저장(피처 스키마 함께)\n",
    "dump({\"model\": est2, \"features\": feature_cols, \"cat_cols\": cat_cols, \"target\": TARGET},\n",
    "     \"cat_w_engineered_feats.joblib\")\n",
    "print(\"saved -> cat_w_engineered_feats.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b464afa-f0a2-4ebf-9165-97e099888936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# 학습 때 쓴 build_features()는 그대로 재사용해야 합니다.\n",
    "pack = load(\"cat_w_engineered_feats.joblib\")\n",
    "model   = pack[\"model\"]\n",
    "FEATS   = pack[\"features\"]\n",
    "CATCOLS = pack[\"cat_cols\"]\n",
    "TARGET  = pack[\"target\"]  # '전력소비량(kWh)'\n",
    "\n",
    "def predict_from_raw(raw_df):\n",
    "    df_feat = build_features(raw_df)     # ★ 학습과 동일 함수\n",
    "    X = df_feat[FEATS].copy()\n",
    "    for c in CATCOLS:\n",
    "        if c in X:\n",
    "            X[c] = X[c].astype(\"category\")\n",
    "    y_hat = model.predict(X)\n",
    "    return df_feat[[\"건물번호\",\"dt\"]].assign(pred=y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdeb3a62-347b-453d-8824-c046ee4f9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def forecast_next_24h(hist_df, future_exog_df):\n",
    "    \"\"\"\n",
    "    hist_df : 과거 실측 포함(raw 스키마, 건물번호/날짜/시간/기상/설비/소비량)\n",
    "    future_exog_df : 같은 스키마에서 미래구간의 외생변수(기온·일사·습도·날짜·시간 등)만 채운 데이터\n",
    "                      TARGET(전력소비량)은 비워둠\n",
    "    \"\"\"\n",
    "    # 시간축/열 맞춰서 이어붙이기\n",
    "    df_all = pd.concat([hist_df, future_exog_df], ignore_index=True, sort=False)\n",
    "\n",
    "    preds = []\n",
    "    # 미래 시각을 오름차순으로 한 스텝씩 예측→TARGET 채워넣기(랙 업데이트용)\n",
    "    for t in sorted(future_exog_df[\"날짜\"].astype(\"datetime64[ns]\") + \n",
    "                    pd.to_timedelta(future_exog_df[\"시간\"], unit=\"h\").unique()):\n",
    "        df_all[\"dt\"] = pd.to_datetime(df_all[\"날짜\"]) + pd.to_timedelta(df_all[\"시간\"], unit=\"h\")\n",
    "        df_feat = build_features(df_all)\n",
    "\n",
    "        this_mask = df_feat[\"dt\"].eq(t)\n",
    "        X_t = df_feat.loc[this_mask, FEATS].copy()\n",
    "        for c in CATCOLS:\n",
    "            if c in X_t:\n",
    "                X_t[c] = X_t[c].astype(\"category\")\n",
    "\n",
    "        y_t = model.predict(X_t)\n",
    "        # 원본 df_all의 해당 시각 TARGET을 예측값으로 채워 다음 스텝 랙에 반영\n",
    "        idx_all = df_all[\"dt\"].eq(t)\n",
    "        df_all.loc[idx_all, TARGET] = y_t\n",
    "        preds.append(df_feat.loc[this_mask, [\"건물번호\",\"dt\"]].assign(pred=y_t))\n",
    "\n",
    "    return pd.concat(preds, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ff7b2ba-6046-438a-a9fa-20cd470629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스키마/카테고리 목록 함께 백업\n",
    "import json\n",
    "json.dump({\"features\": FEATS, \"cat_cols\": CATCOLS, \"target\": TARGET},\n",
    "          open(\"model_schema.json\",\"w\"), ensure_ascii=False, indent=2)\n",
    "\n",
    "# CatBoost 원포맷 저장(파이썬 아닌 환경에서 쓸 때)\n",
    "model.save_model(\"cat_model.cbm\", format=\"cbm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c87829ab-dbaf-4aae-8463-23ed91e22429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: CatBoostRegressor\n",
      "n_features: 48 | target: 전력소비량(kWh)\n"
     ]
    }
   ],
   "source": [
    "import json, math, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 0-1) 모델 패키지 로드\n",
    "pack   = load(\"cat_w_engineered_feats.joblib\")\n",
    "model  = pack[\"model\"]\n",
    "FEATS  = pack[\"features\"]\n",
    "CATCOLS= pack[\"cat_cols\"]\n",
    "TARGET = pack[\"target\"]     # '전력소비량(kWh)'\n",
    "\n",
    "print(\"Loaded:\", type(model).__name__)\n",
    "print(\"n_features:\", len(FEATS), \"| target:\", TARGET)\n",
    "\n",
    "# 0-2) 유틸\n",
    "def to_dt(df):\n",
    "    if \"dt\" in df: return df.copy()\n",
    "    out = df.copy()\n",
    "    out[\"dt\"] = pd.to_datetime(out[\"날짜\"]) + pd.to_timedelta(out[\"시간\"], unit=\"h\")\n",
    "    return out\n",
    "\n",
    "def ensure_cat(df, cat_cols):\n",
    "    for c in cat_cols:\n",
    "        if c in df:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    # sklearn 버전 이슈( squared 파라미터 ) 회피\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def metrics_frame(y_true, y_pred):\n",
    "    return pd.DataFrame({\n",
    "        \"RMSE\":[rmse(y_true, y_pred)],\n",
    "        \"MAE\":[mean_absolute_error(y_true, y_pred)],\n",
    "        \"R2\":[r2_score(y_true, y_pred)]\n",
    "    })\n",
    "\n",
    "def scatter_diag(ax, x, y, alpha=0.3):\n",
    "    ax.scatter(x, y, s=8, alpha=alpha)\n",
    "    lo = np.nanmin([x.min(), y.min()])\n",
    "    hi = np.nanmax([x.max(), y.max()])\n",
    "    ax.plot([lo,hi],[lo,hi], linestyle=\"--\")\n",
    "    ax.set_xlim(lo, hi); ax.set_ylim(lo, hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1f761f0-ee20-443d-8243-f968ff5f9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_compare(raw_df, test_ratio=0.2, buildings_to_plot=None):\n",
    "    df = to_dt(raw_df).sort_values(\"dt\").reset_index(drop=True)\n",
    "\n",
    "    # 시계열 80/20 분할\n",
    "    cutoff = df[\"dt\"].quantile(1 - test_ratio)\n",
    "    df_tr  = df[df[\"dt\"] <= cutoff].copy()\n",
    "    df_te  = df[df[\"dt\"] >  cutoff].copy()\n",
    "\n",
    "    # --- 재귀 예측(테스트 구간) ---\n",
    "    df_all = pd.concat([df_tr, df_te], ignore_index=True)\n",
    "    preds  = []\n",
    "    # 테스트 시간 오름차순(전 건물 동시 예측)\n",
    "    future_times = np.sort(df_te[\"dt\"].unique())\n",
    "    for t in future_times:\n",
    "        # 매 스텝마다 피처 재계산(과거 실측 + 직전 시점 예측 포함)\n",
    "        feat_all = build_features(df_all)   # ★ 학습과 동일 함수 사용\n",
    "        feat_all = ensure_cat(feat_all, CATCOLS)\n",
    "        # 이번 시점 t의 행만 뽑아 예측\n",
    "        m = feat_all[\"dt\"].eq(t)\n",
    "        X_t = feat_all.loc[m, FEATS]\n",
    "        yhat_t = model.predict(X_t)\n",
    "        # 예측을 원본 df_all의 TARGET에 채워넣어 다음 시점 랙이 예측값을 참조하도록\n",
    "        idx = df_all[\"dt\"].eq(t)\n",
    "        df_all.loc[idx, TARGET] = yhat_t\n",
    "        preds.append(\n",
    "            feat_all.loc[m, [\"건물번호\",\"dt\"]].assign(pred=yhat_t)\n",
    "        )\n",
    "\n",
    "    pred_df = pd.concat(preds, ignore_index=True)\n",
    "    # 실측 결합\n",
    "    truth = df_te[[\"건물번호\",\"dt\", TARGET]].rename(columns={TARGET:\"y\"})\n",
    "    out   = pred_df.merge(truth, on=[\"건물번호\",\"dt\"], how=\"left\")\n",
    "\n",
    "    # --- 요약 지표 ---\n",
    "    overall = metrics_frame(out[\"y\"], out[\"pred\"])\n",
    "    by_bld  = out.groupby(\"건물번호\").apply(lambda g: metrics_frame(g[\"y\"], g[\"pred\"])).reset_index().drop(columns=0)\n",
    "    by_bld.rename(columns={\"RMSE\":\"RMSE\",\"MAE\":\"MAE\",\"R2\":\"R2\"}, inplace=True)\n",
    "\n",
    "    print(\"=== Overall (holdout) ===\")\n",
    "    display(overall)\n",
    "    print(\"\\n=== By Building ===\")\n",
    "    display(by_bld.sort_values(\"RMSE\"))\n",
    "\n",
    "    # --- 플롯: 산점/잔차/시간대 ---\n",
    "    fig1, ax1 = plt.subplots(figsize=(5,5))\n",
    "    scatter_diag(ax1, out[\"y\"].values, out[\"pred\"].values, alpha=0.2)\n",
    "    ax1.set_xlabel(\"Actual\"); ax1.set_ylabel(\"Predicted\"); ax1.set_title(\"Holdout: Pred vs Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    # Residual dist\n",
    "    out[\"resid\"] = out[\"pred\"] - out[\"y\"]\n",
    "    fig2, ax2 = plt.subplots(figsize=(6,3))\n",
    "    ax2.hist(out[\"resid\"].dropna(), bins=60)\n",
    "    ax2.set_title(\"Residual distribution (pred - actual)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Hour-of-day bias\n",
    "    tmp = out.copy()\n",
    "    tmp[\"hour\"] = tmp[\"dt\"].dt.hour\n",
    "    hstat = tmp.groupby(\"hour\")[\"resid\"].agg([\"median\",\"mean\",\"std\"]).reset_index()\n",
    "    print(\"\\n=== Residual by hour ===\")\n",
    "    display(hstat)\n",
    "    fig3, ax3 = plt.subplots(figsize=(6,3))\n",
    "    ax3.plot(hstat[\"hour\"], hstat[\"mean\"], marker=\"o\")\n",
    "    ax3.set_xlabel(\"Hour\"); ax3.set_ylabel(\"Residual mean\"); ax3.set_title(\"Residual mean by hour\")\n",
    "    plt.show()\n",
    "\n",
    "    # 타임시리즈 예시(건물 3개)\n",
    "    if buildings_to_plot is None:\n",
    "        buildings_to_plot = list(out[\"건물번호\"].dropna().unique())[:3]\n",
    "\n",
    "    for b in buildings_to_plot:\n",
    "        g = out[out[\"건물번호\"]==b].sort_values(\"dt\")\n",
    "        fig, ax = plt.subplots(figsize=(10,3))\n",
    "        ax.plot(g[\"dt\"], g[\"y\"],  label=\"Actual\")\n",
    "        ax.plot(g[\"dt\"], g[\"pred\"], label=\"Pred\", alpha=0.8)\n",
    "        ax.legend(); ax.set_title(f\"Building {b} - Holdout\")\n",
    "        plt.show()\n",
    "\n",
    "    return out, overall, by_bld\n",
    "\n",
    "# 실행 예시\n",
    "# raw_df = ...  # 원본 전체 데이터프레임(학습에 쓴 것과 동일 스키마)\n",
    "# out, overall, by_bld = holdout_compare(raw_df, test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64922f9b-8d5f-4713-810f-a505bf962ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_backtest(raw_df, n_splits=4):\n",
    "    df = to_dt(raw_df).sort_values(\"dt\").reset_index(drop=True)\n",
    "    ts = df[\"dt\"].sort_values().unique()\n",
    "    cut_idx = np.linspace(0, len(ts), n_splits+1, dtype=int)\n",
    "\n",
    "    report = []\n",
    "    pred_all = []\n",
    "\n",
    "    for k in range(n_splits):\n",
    "        t0, t1 = ts[cut_idx[k]], ts[cut_idx[k+1]-1]\n",
    "        df_tr = df[df[\"dt\"] <= t0].copy()\n",
    "        df_te = df[(df[\"dt\"] > t0) & (df[\"dt\"] <= t1)].copy()\n",
    "        if df_te.empty: continue\n",
    "\n",
    "        # 재귀 예측\n",
    "        df_all = pd.concat([df_tr, df_te], ignore_index=True)\n",
    "        preds=[]\n",
    "        for t in np.sort(df_te[\"dt\"].unique()):\n",
    "            feat_all = build_features(df_all)\n",
    "            feat_all = ensure_cat(feat_all, CATCOLS)\n",
    "            m = feat_all[\"dt\"].eq(t)\n",
    "            X_t = feat_all.loc[m, FEATS]\n",
    "            yhat_t = model.predict(X_t)\n",
    "            idx = df_all[\"dt\"].eq(t)\n",
    "            df_all.loc[idx, TARGET] = yhat_t\n",
    "            preds.append(feat_all.loc[m, [\"건물번호\",\"dt\"]].assign(pred=yhat_t))\n",
    "\n",
    "        fold_pred = pd.concat(preds, ignore_index=True)\n",
    "        fold_truth= df_te[[\"건물번호\",\"dt\", TARGET]].rename(columns={TARGET:\"y\"})\n",
    "        fold_out  = fold_pred.merge(fold_truth, on=[\"건물번호\",\"dt\"], how=\"left\")\n",
    "        fold_out[\"fold\"] = k\n",
    "        pred_all.append(fold_out)\n",
    "\n",
    "        m = metrics_frame(fold_out[\"y\"], fold_out[\"pred\"])\n",
    "        m[\"fold\"] = k; m[\"from\"]=t0; m[\"to\"]=t1\n",
    "        report.append(m)\n",
    "\n",
    "        print(f\"[Fold {k}] {t0} → {t1} | RMSE={m['RMSE'].values[0]:.3f}  MAE={m['MAE'].values[0]:.3f}  R2={m['R2'].values[0]:.4f}\")\n",
    "\n",
    "    rep = pd.concat(report, ignore_index=True) if report else pd.DataFrame()\n",
    "    pred_all = pd.concat(pred_all, ignore_index=True) if pred_all else pd.DataFrame()\n",
    "\n",
    "    print(\"\\n=== Rolling backtest summary ===\")\n",
    "    display(rep)\n",
    "\n",
    "    # 플롯: 폴드별 RMSE\n",
    "    if not rep.empty:\n",
    "        fig, ax = plt.subplots(figsize=(6,3))\n",
    "        ax.plot(rep[\"fold\"], rep[\"RMSE\"], marker=\"o\")\n",
    "        ax.set_xlabel(\"Fold\"); ax.set_ylabel(\"RMSE\"); ax.set_title(\"Rolling backtest RMSE\")\n",
    "        plt.show()\n",
    "\n",
    "    return pred_all, rep\n",
    "\n",
    "# 실행 예시\n",
    "# pred_all, rep = rolling_backtest(raw_df, n_splits=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8240249-1012-4cee-aeec-bd57192b46c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded model from dict: cat_w_engineered_feats.joblib -> CatBoostRegressor\n",
      "[model] n_features_expected: 48\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feat_names:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     train_df = \u001b[43madd_simple_extra_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_names\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m train_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     92\u001b[39m     test_df  = add_simple_extra_feats(test_df,  feat_names)\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# (라그/롤링 추가 함수는 그대로 사용한다고 가정)\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# ...\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# test_feat = add_lag_rolling(train_df, test_df, feat_names)\u001b[39;00m\n\u001b[32m     97\u001b[39m \n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 5) 최종 X_test 생성\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36madd_simple_extra_feats\u001b[39m\u001b[34m(df, expect_cols)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expect_cols: \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhas_pv\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m expect_cols \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m태양광용량(kW)\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out.columns:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     out[\u001b[33m\"\u001b[39m\u001b[33mhas_pv\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m태양광용량(kW)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhas_ess\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m expect_cols \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mESS저장용량(kWh)\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out.columns:\n\u001b[32m     70\u001b[39m     out[\u001b[33m\"\u001b[39m\u001b[33mhas_ess\u001b[39m\u001b[33m\"\u001b[39m] = (out[\u001b[33m\"\u001b[39m\u001b[33mESS저장용량(kWh)\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[39m, in \u001b[36mOpsMixin.__gt__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6116\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6117\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6119\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:129\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    127\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mops.pyx:107\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_compare\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081db1a6-b0b1-4d7b-8b1d-90cae08e3ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756e9ce-34cb-4b6c-9c61-3c125e23bc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df99ea0-29b6-46dc-a379-83b6bdecffc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb05bf58-eda0-4b1a-8e29-d40e2cb99067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded model from dict: cat_w_engineered_feats.joblib -> CatBoostRegressor\n",
      "[model] n_features_expected: 48\n"
     ]
    }
   ],
   "source": [
    "# 1) 모델 로드 (dict 대응 + feat_names 복구)\n",
    "model = None\n",
    "feat_names_saved = None\n",
    "\n",
    "for p in MODEL_PATHS:\n",
    "    if os.path.exists(p):\n",
    "        obj = joblib.load(p)\n",
    "        if isinstance(obj, dict):\n",
    "            model = obj.get(\"model\", obj)\n",
    "            feat_names_saved = obj.get(\"feat_names\")  # dict에 저장해둔 피처명 복구\n",
    "            print(f\"[OK] Loaded model from dict: {p} -> {type(model).__name__}\")\n",
    "        else:\n",
    "            model = obj\n",
    "            print(f\"[OK] Loaded model: {p} -> {type(model).__name__}\")\n",
    "        break\n",
    "if model is None:\n",
    "    raise FileNotFoundError(\"모델 파일을 찾지 못했습니다.\")\n",
    "\n",
    "# 피처 이름 확보 (dict 저장분 > 모델 내부 > 없음)\n",
    "feat_names = feat_names_saved or list(getattr(model, \"feature_names_\", [])) or None\n",
    "print(\"[model] n_features_expected:\", len(feat_names) if feat_names else \"(unknown)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee882432-ae3a-49f1-95b7-0c5754955f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_simple_extra_feats(df, expect_cols):\n",
    "    out = df.copy()\n",
    "    if not expect_cols:\n",
    "        return out\n",
    "\n",
    "    # ---- 수치형 강제 변환 (문자 -> 숫자) ----\n",
    "    num_cols = [\n",
    "        \"태양광용량(kW)\", \"ESS저장용량(kWh)\", \"PCS용량(kW)\",\n",
    "        \"기온(°C)\", \"일사(MJ/m2)\", \"습도(%)\", \"연면적(m2)\"\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "    # ---- has_* 플래그 ----\n",
    "    if \"has_pv\" in expect_cols and \"태양광용량(kW)\" in out.columns:\n",
    "        pv = out[\"태양광용량(kW)\"].fillna(0.0)\n",
    "        out[\"has_pv\"] = (pv > 0).astype(int)\n",
    "\n",
    "    if \"has_ess\" in expect_cols and \"ESS저장용량(kWh)\" in out.columns:\n",
    "        ess = out[\"ESS저장용량(kWh)\"].fillna(0.0)\n",
    "        out[\"has_ess\"] = (ess > 0).astype(int)\n",
    "\n",
    "    if \"has_pcs\" in expect_cols and \"PCS용량(kW)\" in out.columns:\n",
    "        pcs = out[\"PCS용량(kW)\"].fillna(0.0)\n",
    "        out[\"has_pcs\"] = (pcs > 0).astype(int)\n",
    "\n",
    "    # ---- log1p_* ----\n",
    "    if \"log1p_태양광용량(kW)\" in expect_cols and \"태양광용량(kW)\" in out.columns:\n",
    "        out[\"log1p_태양광용량(kW)\"] = np.log1p(out[\"태양광용량(kW)\"].fillna(0.0))\n",
    "    if \"log1p_ESS저장용량(kWh)\" in expect_cols and \"ESS저장용량(kWh)\" in out.columns:\n",
    "        out[\"log1p_ESS저장용량(kWh)\"] = np.log1p(out[\"ESS저장용량(kWh)\"].fillna(0.0))\n",
    "    if \"log1p_PCS용량(kW)\" in expect_cols and \"PCS용량(kW)\" in out.columns:\n",
    "        out[\"log1p_PCS용량(kW)\"] = np.log1p(out[\"PCS용량(kW)\"].fillna(0.0))\n",
    "\n",
    "    # ---- CDD 및 파생 ----\n",
    "    if \"기온(°C)\" in out.columns:\n",
    "        t = out[\"기온(°C)\"].astype(float)\n",
    "        cdd = np.clip(t - CDDH_BASE_TEMP, 0, None)\n",
    "        if \"CDD\" in expect_cols:\n",
    "            out[\"CDD\"] = cdd\n",
    "\n",
    "        if \"일사(MJ/m2)\" in out.columns and \"CDD_x_rad\" in expect_cols:\n",
    "            out[\"CDD_x_rad\"] = cdd * out[\"일사(MJ/m2)\"].astype(float)\n",
    "\n",
    "        if \"습도(%)\" in out.columns and \"CDD_humid_adj\" in expect_cols:\n",
    "            out[\"CDD_humid_adj\"] = cdd * (1 + out[\"습도(%)\"].astype(float) / 100.0)\n",
    "\n",
    "        if (\n",
    "            \"연면적(m2)\" in out.columns and\n",
    "            \"일사(MJ/m2)\" in out.columns and\n",
    "            \"CDD_x_rad_area\" in expect_cols\n",
    "        ):\n",
    "            out[\"CDD_x_rad_area\"] = (\n",
    "                cdd * out[\"일사(MJ/m2)\"].astype(float) * out[\"연면적(m2)\"].astype(float)\n",
    "            )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "139f5b37-9124-4ff2-a207-045a16a46be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feat_names:\n",
    "    for c in feat_names:\n",
    "        if c not in test_df.columns:\n",
    "            test_df[c] = np.nan\n",
    "    X_test = test_df.reindex(columns=feat_names)\n",
    "else:\n",
    "    drop_cols = ID_COLS + ([Y_COL] if Y_COL in test_df.columns else [])\n",
    "    base_cols = [c for c in test_df.columns if c not in drop_cols]\n",
    "    X_test = test_df[base_cols]\n",
    "    print(\"[warn] feature_names_ 없음 -> 공통 컬럼만 사용\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "081c861a-f81e-4b0f-ac6e-7b79ddeeaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"건물용도\"]   # 학습 때 범주형으로 넣었던 컬럼들\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb33e225-24cd-4ad6-a76c-de7599dbbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['건물번호', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '일조(hr)', '일사(MJ/m2)', '건물유형', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', '시간', 'hour_sin', 'hour_cos', 'month', 'hour', 'dayofyear', 'weekday', 'is_weekend', 'is_holiday', 'CDD', 'CDD_x_rad', 'CDD_humid_adj', 'log1p_태양광용량(kW)', 'has_pv', 'log1p_ESS저장용량(kWh)', 'has_ess', 'log1p_PCS용량(kW)', 'has_pcs', 'is_daylight', 'is_offpeak', 'is_peak', 'cons_lag1', 'cons_lag_24h', 'cons_lag_48h', 'cons_lag_72h', 'cons_lag_168h', 'cons_mean_24h', 'cons_std_24h', 'cons_samehour_mean_7d', 'delta_1h', 'delta_7d', 'cons_lag1_per_m2', 'cons_mean24_per_m2', 'ess_to_load_lag_ratio', 'CDD_x_rad_area']\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5169bad3-f477-4ac3-8470-4bfc1c6c92d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved -> submission.csv\n",
      "   건물번호         날짜  시간  전력소비량(kWh)\n",
      "0     1 2024-08-25   0  122.559533\n",
      "1     1 2024-08-25   1  122.494814\n",
      "2     1 2024-08-25   2  122.623458\n",
      "3     1 2024-08-25   3  122.078199\n",
      "4     1 2024-08-25   4  122.078199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import Pool\n",
    "\n",
    "# 0) 안전장치: 필요한 전역이 있는지 확인\n",
    "assert 'X_test' in globals(), \"X_test가 없습니다.\"\n",
    "assert 'test_df' in globals(), \"test_df가 없습니다.\"\n",
    "assert 'model' in globals(), \"model이 없습니다.\"\n",
    "\n",
    "# 1) '건물유형'을 모델 학습과 동일하게 숫자로 맞추기\n",
    "if '건물유형' in X_test.columns and not pd.api.types.is_numeric_dtype(X_test['건물유형']):\n",
    "    mapped = None\n",
    "\n",
    "    # (우선권) train_df에 '건물번호'별 숫자 코드가 있으면 그걸 그대로 매핑 (가장 안전)\n",
    "    if 'train_df' in globals() and train_df is not None \\\n",
    "       and '건물번호' in train_df.columns and '건물유형' in train_df.columns \\\n",
    "       and pd.api.types.is_numeric_dtype(train_df['건물유형']):\n",
    "        b2code = (train_df\n",
    "                  .dropna(subset=['건물번호','건물유형'])\n",
    "                  .groupby('건물번호')['건물유형']\n",
    "                  .agg(lambda s: s.mode().iloc[0]))\n",
    "        mapped = test_df['건물번호'].map(b2code)\n",
    "\n",
    "    # (대안1) 아직도 문자열이면: train_df의 문자열 카테고리 기준으로 고정 인코딩\n",
    "    if mapped is None or mapped.isna().all():\n",
    "        if 'train_df' in globals() and train_df is not None and '건물유형' in train_df.columns:\n",
    "            cats = pd.Categorical(\n",
    "                pd.concat([train_df['건물유형'].astype(str),\n",
    "                           X_test['건물유형'].astype(str)], ignore_index=True)\n",
    "            ).categories\n",
    "            cat2id = {c:i for i,c in enumerate(cats)}\n",
    "            mapped = X_test['건물유형'].astype(str).map(cat2id)\n",
    "\n",
    "    # (대안2) 최후의 수단: 테스트 안에서만 factorize (정확도는 다소 손해)\n",
    "    if mapped is None or mapped.isna().all():\n",
    "        mapped = pd.Series(pd.factorize(X_test['건물유형'].astype(str))[0], index=X_test.index)\n",
    "\n",
    "    X_test['건물유형'] = pd.to_numeric(mapped, errors='coerce').fillna(-1).astype(float)\n",
    "\n",
    "# 2) 혹시 남은 object 컬럼이 있으면 숫자로 강제 변환 (불필요 컬럼은 사전에 제외했을 가능성 큼)\n",
    "for c in X_test.columns:\n",
    "    if X_test[c].dtype == 'object':\n",
    "        X_test[c] = pd.to_numeric(X_test[c], errors='coerce')\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# 3) 예측\n",
    "X_pool = Pool(X_test)  # cat_features 안 넘김 (모델이 숫자 피처로 학습됨)\n",
    "pred = model.predict(X_pool)\n",
    "\n",
    "# 4) 제출 파일 저장\n",
    "id_cols = [\"건물번호\",\"날짜\",\"시간\"] if all(col in test_df.columns for col in [\"건물번호\",\"날짜\",\"시간\"]) \\\n",
    "          else [c for c in [\"건물번호\"] if c in test_df.columns]\n",
    "submit = test_df[id_cols].copy()\n",
    "submit[\"전력소비량(kWh)\"] = pred\n",
    "submit.to_csv(\"submission.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ saved -> submission.csv\")\n",
    "print(submit.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20aa403-144c-4ffc-a126-006cf39402e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a37bda-cbb4-4cef-96cc-d60ac7690ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86397b-0abc-41e8-aadb-214364d9acca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f58370-1107-4ebf-8a08-7eb65e34e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336cd93-91ee-4c78-919b-a2fddd6060e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7666f-9cb4-4913-8b44-f4ca38367375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95083ac0-0380-4132-a0ea-7e0d0087dca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4756793-a2ba-4d16-8bc3-91f89239e8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff8fd2-4a58-447a-b620-2d6aa0c09d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b96340-e246-44f8-a3b4-86717f2fcd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfe8e4-b323-483a-9ab0-20c594d01411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd119b4-8bc7-4606-95bf-18b99447e980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab054c-c929-4c1e-87d7-abcb876f9139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90f11b-d460-4bc3-917a-a4808865b17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a894c-b589-4323-8c9a-dfbb0624e09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b891cc7-b846-45bb-87b2-460d8726f7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694ae0b-3a01-45b7-9a7e-7096eef2ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f96069-a4b9-4cfe-ab82-e783d72e4f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec376e55-5750-46c8-9512-b16e9aa92279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ad073-deda-4d21-b869-3da771a8d535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21fa7d-b790-4777-b8a2-3c06df00bbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89696f-e7e0-46bc-9fdb-748d86c7ac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27901a1-9b7d-460d-bc67-5c339d6bf830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c2c43-48ad-4b33-93ff-087563111779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb8d4e-8b90-49b4-aa52-9efb9bf42e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66430db1-371f-4f97-8bb0-c971b12316c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a33289-90b4-46f6-8c3c-61be23eb892d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9d839-2b44-493f-8ad6-c923b748a7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8041f2-3e2a-41f1-989c-095646de9a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa605a-4336-4d8f-b11b-b78405048012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9fce5-0e59-4bd3-b9ab-81c035168b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae8f70-25ae-4ace-8daf-196a8ddfb73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37776b-bbda-474c-ace4-884c47606b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84920142-ca42-4150-b426-13f7e72fd7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fb314-3101-4bd0-96f6-4ad4bfd210cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7aac67-e287-4ec7-af2e-b8a1cad7ac07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08361b5e-6a9c-4c53-ac09-41bcc28dbe69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12846b-5afe-4b09-a0eb-8d209ff21b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae95fd0-7a25-4f32-8bfa-0141214e3eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1848e-85ef-475d-b423-359f5e3706db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96b4a0-9547-4926-ae36-e5d4133da7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92177b-49f6-4d6d-9ac2-dcb0c7010742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b307be3-fdaf-4753-98dd-033f1979130d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "784b5a5e-2d98-4946-bb7e-71f8dfd960e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "df.to_csv(r\"C:\\Users\\user\\Downloads\\open (1)\\merged_train.csv\", index=False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0dcff9-f863-479e-bd76-10ef2b46fa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b04e89-5b47-4b60-afc8-ba3c93d26af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
